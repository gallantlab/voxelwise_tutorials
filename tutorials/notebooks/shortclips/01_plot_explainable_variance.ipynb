{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Compute the explainable variance\n\nBefore fitting any voxelwise model to fMRI responses, it is good practice to\nquantify the amount of signal in the test set that can be predicted by an\nencoding model. This quantity is called the *explainable variance*.\n\nThe measured signal can be decomposed into a sum of two components: the\nstimulus-dependent signal and noise. If we present the same stimulus multiple\ntimes and we record brain activity for each repetition, the stimulus-dependent\nsignal will be the same across repetitions while the noise will vary across\nrepetitions. In voxelwise modeling, the features used to model brain activity\nare the same for each repetition of the stimulus. Thus, encoding models will\npredict only the repeatable stimulus-dependent signal.\n\nThe stimulus-dependent signal can be estimated by taking the mean of brain\nresponses over repeats of the same stimulus or experiment. The variance of the\nestimated stimulus-dependent signal, which we call the explainable variance, is\nproportional to the maximum prediction accuracy that can be obtained by a\nvoxelwise encoding model in the test set.\n\nMathematically, let $y_i, i = 1 \\dots N$ be the measured signal in a\nvoxel for each of the $N$ repetitions of the same stimulus and\n$\\bar{y} = \\frac{1}{N}\\sum_{i=1}^Ny_i$ the average brain response\nacross repetitions. For each repeat, we define the residual timeseries between\nbrain response and average brain response as $r_i = y_i - \\bar{y}$. The\nexplainable variance (EV) is estimated as\n\n\\begin{align}\\text{EV} = \\frac{1}{N}\\sum_{i=1}^N\\text{Var}(y_i) - \\frac{N}{N-1}\\sum_{i=1}^N\\text{Var}(r_i)\\end{align}\n\n\nIn the literature, the explainable variance is also known as the *signal\npower*. For more information, see these references [1]_ [2]_ [3]_.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Path of the data directory\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from voxelwise_tutorials.io import get_data_home\n\ndirectory = get_data_home(dataset=\"shortclips\")\nprint(directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# modify to use another subject\nsubject = \"S01\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compute the explainable variance\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nfrom voxelwise_tutorials.io import load_hdf5_array"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, we load the fMRI responses on the test set, which contains brain\nresponses to ten (10) repeats of the same stimulus.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\n\nfile_name = os.path.join(directory, 'responses', f'{subject}_responses.hdf')\nY_test = load_hdf5_array(file_name, key=\"Y_test\")\nprint(\"(n_repeats, n_samples_test, n_voxels) =\", Y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, we compute the explainable variance for each voxel.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from voxelwise_tutorials.utils import explainable_variance\n\nev = explainable_variance(Y_test)\nprint(\"(n_voxels,) =\", ev.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To better understand the concept of explainable variance, we can plot the\nmeasured signal in a voxel with high explainable variance...\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n\nvoxel_1 = np.argmax(ev)\ntime = np.arange(Y_test.shape[1]) * 2  # one time point every 2 seconds\nplt.figure(figsize=(10, 3))\nplt.plot(time, Y_test[:, :, voxel_1].T, color='C0', alpha=0.5)\nplt.plot(time, Y_test[:, :, voxel_1].mean(0), color='C1', label='average')\nplt.xlabel(\"Time (sec)\")\nplt.title(\"Voxel with large explainable variance (%.2f)\" % ev[voxel_1])\nplt.yticks([])\nplt.legend()\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "... and in a voxel with low explainable variance.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "voxel_2 = np.argmin(ev)\nplt.figure(figsize=(10, 3))\nplt.plot(time, Y_test[:, :, voxel_2].T, color='C0', alpha=0.5)\nplt.plot(time, Y_test[:, :, voxel_2].mean(0), color='C1', label='average')\nplt.xlabel(\"Time (sec)\")\nplt.title(\"Voxel with low explainable variance (%.2f)\" % ev[voxel_2])\nplt.yticks([])\nplt.legend()\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also plot the distribution of explainable variance over voxels.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.hist(ev, bins=np.linspace(0, 1, 100), log=True, histtype='step')\nplt.xlabel(\"Explainable variance\")\nplt.ylabel(\"Number of voxels\")\nplt.title('Histogram of explainable variance')\nplt.grid('on')\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that many voxels have low explainable variance. This is\nexpected, since many voxels are not driven by a visual stimulus, and their\nresponse changes over repeats of the same stimulus.\nWe also see that some voxels have high explainable variance (around 0.7). The\nresponses in these voxels are highly consistent across repetitions of the\nsame stimulus. Thus, they are good targets for encoding models.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Map to subject flatmap\n\nTo better understand the distribution of explainable variance, we map the\nvalues to the subject brain. This can be done with [pycortex](https://gallantlab.github.io/pycortex/), which can create interactive 3D\nviewers to be displayed in any modern browser. ``pycortex`` can also display\nflattened maps of the cortical surface to visualize the entire cortical\nsurface at once.\n\nHere, we do not share the anatomical information of the subjects for privacy\nconcerns. Instead, we provide two mappers:\n\n- to map the voxels to a (subject-specific) flatmap\n- to map the voxels to the Freesurfer average cortical surface (\"fsaverage\")\n\nThe first mapper is 2D matrix of shape (n_pixels, n_voxels) that maps each\nvoxel to a set of pixel in a flatmap. The matrix is efficiently stored in a\n``scipy`` sparse CSR matrix. The function ``plot_flatmap_from_mapper``\nprovides an example of how to use the mapper and visualize the flatmap.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from voxelwise_tutorials.viz import plot_flatmap_from_mapper\n\nmapper_file = os.path.join(directory, 'mappers', f'{subject}_mappers.hdf')\nplot_flatmap_from_mapper(ev, mapper_file, vmin=0, vmax=0.7)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This figure is a flattened map of the cortical surface. A number of regions\nof interest (ROIs) have been labeled to ease interpretation. If you have\nnever seen such a flatmap, we recommend taking a look at a [pycortex brain\nviewer](https://www.gallantlab.org/brainviewer/Deniz2019), which displays\nthe brain in 3D. In this viewer, press \"I\" to inflate the brain, \"F\" to\nflatten the surface, and \"R\" to reset the view (or use the ``surface/unfold``\ncursor on the right menu). Press \"H\" for a list of all keyboard shortcuts.\nThis viewer should help you understand the correspondence between the flatten\nand the folded cortical surface of the brain.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On this flatmap, we can see that the explainable variance is mainly located\nin the visual cortex, in early visual regions like V1, V2, V3, or in\nhigher-level regions like EBA, FFA or IPS. This is expected since this\ndataset contains responses to a visual stimulus.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Map to \"fsaverage\"\n\nThe second mapper we provide maps the voxel data to a Freesurfer\naverage surface (\"fsaverage\"), that can be used in ``pycortex``.\n\nFirst, let's download the \"fsaverage\" surface.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import cortex\n\nsurface = \"fsaverage\"\n\nif not hasattr(cortex.db, surface):\n    cortex.utils.download_subject(subject_id=surface,\n                                  pycortex_store=cortex.db.filestore)\n    cortex.db.reload_subjects()  # force filestore reload\n    assert hasattr(cortex.db, surface)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, we load the \"fsaverage\" mapper. The mapper is a matrix of shape\n(n_vertices, n_voxels), which maps each voxel to some vertices in the\nfsaverage surface. It is stored as a sparse CSR matrix. The mapper is applied\nwith a dot product ``@`` (equivalent to ``np.dot``).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from voxelwise_tutorials.io import load_hdf5_sparse_array\n\nvoxel_to_fsaverage = load_hdf5_sparse_array(mapper_file,\n                                            key='voxel_to_fsaverage')\nev_projected = voxel_to_fsaverage @ ev\nprint(\"(n_vertices,) =\", ev_projected.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can then create a ``Vertex`` object in ``pycortex``, containing the\nprojected data. This object can be used either in a ``pycortex`` interactive\n3D viewer, or in a ``matplotlib`` figure showing only the flatmap.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "vertex = cortex.Vertex(ev_projected, surface, vmin=0, vmax=0.7, cmap='viridis')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To start an interactive 3D viewer in the browser, we can use the ``webshow``\nfunction in pycortex. (Note that this method works only if you are running the\nnotebooks locally.) You can start an interactive 3D viewer by changing\n``run_webshow`` to ``True`` and running the following cell.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "run_webshow = False\nif run_webshow:\n    cortex.webshow(vertex, open_browser=False, port=8050)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Alternatively, to plot a flatmap in a ``matplotlib`` figure, use the\n`quickshow` function.\n\n(This function requires Inkscape to be installed. The rest of the tutorial\ndoes not use this function, so feel free to ignore.)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from cortex.testing_utils import has_installed\n\nfig = cortex.quickshow(vertex, colorbar_location='right',\n                       with_rois=has_installed(\"inkscape\"))\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## References\n\n.. [1] Sahani, M., & Linden, J. F. (2003). How linear are auditory cortical\n   responses?. Advances in neural information processing systems, 125-132.\n\n.. [2] Hsu, A., Borst, A., & Theunissen, F. E. (2004). Quantifying\n   variability in neural responses and its application for the validation of\n   model predictions. Network: Computation in Neural Systems, 15(2), 91-109.\n\n.. [3] Schoppe, O., Harper, N. S., Willmore, B. D., King, A. J., & Schnupp,\n       J. W. (2016). Measuring the performance of neural models. Frontiers in\n       computational neuroscience, 10, 10.\n\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}