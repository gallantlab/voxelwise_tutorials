{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Compute the explainable variance\n\n\nBefore fitting voxelwise models to the fMRI responses, we can estimate the\n*explainable variance*. The explainable variance is the part of the fMRI\nresponses that can be explained by the voxelwise modeling framework.\n\nIndeed, we can decompose the signal into a sum of two components, one component\nthat is repeated if we repeat the same experiment, and one component that\nchanges for each repeat. Because voxelwise modeling would use the same features\nfor each repeat, it can only model the component that is common to all repeats.\nThis shared component can be estimated by taking the mean over repeats of the\nsame experiment. The variance of this shared component, that we call the\nexplainable variance, is the upper bound of the voxelwise modeling\nperformances. The explainable variance is also sometimes called the *noise\nceiling*.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Path of the data directory\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\nfrom voxelwise_tutorials.io import get_data_home\ndirectory = os.path.join(get_data_home(), \"vim-5\")\nprint(directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# modify to use another subject\nsubject = \"S01\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compute the explainable variance\n--------------------------------\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nfrom voxelwise_tutorials.io import load_hdf5_array"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, we load the fMRI responses on the test set, which contains ten (10)\nrepeats.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "file_name = os.path.join(directory, 'responses', f'{subject}_responses.hdf')\nY_test = load_hdf5_array(file_name, key=\"Y_test\")\nprint(\"(n_repeats, n_samples_test, n_voxels) =\", Y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, we compute the explainable variance per voxel.\nThe variance of the signal is estimated by taking the average variance over\nrepeats. The variance of the component shared across repeats is estimated by\ntaking the variance of the average response. Then, we compute the\nexplainable variance by dividing these two quantities.\nFinally, a correction can be applied to account for small numbers of repeat\n(through the parameter ``bias_correction``).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from voxelwise_tutorials.utils import explainable_variance\nev = explainable_variance(Y_test, bias_correction=False)\nprint(\"(n_voxels,) =\", ev.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To better understand the explainable variance, we can plot the time-courses\nof a voxel with large explainable variance...\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n\nvoxel_1 = np.argmax(ev)\ntime = np.arange(Y_test.shape[1]) * 2  # one time point every 2 seconds\nplt.figure(figsize=(10, 3))\nplt.plot(time, Y_test[:, :, voxel_1].T, color='C0', alpha=0.5)\nplt.plot(time, Y_test[:, :, voxel_1].mean(0), color='C1', label='average')\nplt.xlabel(\"Time (sec)\")\nplt.title(\"Voxel with large explainable variance (%.2f)\" % ev[voxel_1])\nplt.yticks([])\nplt.legend()\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "... and of a voxel with low explainable variance.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "voxel_2 = np.argmin(ev)\nplt.figure(figsize=(10, 3))\nplt.plot(time, Y_test[:, :, voxel_2].T, color='C0', alpha=0.5)\nplt.plot(time, Y_test[:, :, voxel_2].mean(0), color='C1', label='average')\nplt.xlabel(\"Time (sec)\")\nplt.title(\"Voxel with low explainable variance (%.2f)\" % ev[voxel_2])\nplt.yticks([])\nplt.legend()\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also plot the distribution of explainable variance over voxels.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.hist(ev, bins=np.linspace(0, 1, 100), log=True, histtype='step')\nplt.xlabel(\"Explainable variance\")\nplt.ylabel(\"Number of voxels\")\nplt.title('Histogram of explainable variance')\nplt.grid('on')\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that most voxels have a rather low explainable variance, around 0.1\n(when not using the bias correction). This is expected, since most voxels are\nnot directly driven by a visual stimulus, and their activity change over\nrepeats. We also see that some voxels reach an explainable variance of 0.7,\nwhich is quite high. It means that these voxels consistently record the same\nactivity across a repeated stimulus, and thus are good targets for encoding\nmodels. Of course, this set of explainable voxels changes from task to\ntask, depending on what you are trying to model.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Map to subject flatmap\n----------------------\n\nTo better understand the distribution of explainable variance, we map the\nvalues to the subject brain. This can be done with `pycortex\n<https://gallantlab.github.io/pycortex/>`_, which can create interactive 3D\nviewers to be displayed in any modern browser. ``pycortex`` can also display\nflattened maps of the cortical surface, to visualize the entire cortical\nsurface at once.\n\nHere, we do not share the anatomical information of the subjects for privacy\nconcerns. Instead, we provide two mappers:\n\n- to map the voxels to a (subject-specific) flatmap\n- to map the voxels to the Freesurfer average cortical surface (\"fsaverage\")\n\nThe first mapper is 2D matrix of shape (n_pixels, n_voxels), that map each\nvoxel to a set of pixel in a flatmap. The matrix is efficient stored using a\n``scipy`` sparse CSR matrix format. The function ``plot_flatmap_from_mapper``\nprovides an example of how to use the mapper and visualize the flatmap.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from voxelwise_tutorials.viz import plot_flatmap_from_mapper\n\nmapper_file = os.path.join(directory, 'mappers', f'{subject}_mappers.hdf')\nplot_flatmap_from_mapper(ev, mapper_file, vmin=0, vmax=0.7)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This figure is a flatten map of the cortical surface. A number of regions of\ninterest (ROIs) have been labeled to ease the interpretation. If you have\nnever seen such a flatmap, we recommend taking a look at a `pycortex brain\nviewer <https://www.gallantlab.org/brainviewer/Deniz2019>`_, which displays\nthe brain in 3D. In this viewer, press \"I\" to inflate the brain, \"F\" to\nflatten the surface, and \"R\" to reset the view (or use the ``surface/unfold``\ncursor on the right menu). Press \"H\" for a list of all keyboard shortcuts.\nThis viewer should help you understand the correspondance between the flatten\nand the folded cortical surface of the brain.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On this flatmap, we can see that the explainable variance is mainly located\nin the visual cortex, in early visual regions like V1, V2, V3, or in\nhigher-level regions like EBA, FFA or IPS. This was expected since this is a\npurely visual experiment.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Map to \"fsaverage\"\n------------------\n\nThe second mapper we provide maps the voxel data to a Freesurfer\naverage surface (\"fsaverage\"), that can be used in ``pycortex``.\nFirst, let's download the \"fsaverage\" surface.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import cortex\n\nsurface = \"fsaverage\"\n\nif not hasattr(cortex.db, surface):\n    cortex.utils.download_subject(subject_id=surface)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you are running the notebook on Colab, you might need to update the\npycortex filestore as following:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "try:\n    import google.colab  # noqa\n    in_colab = True\nexcept ImportError:\n    in_colab = False\nprint(in_colab)\n\nif in_colab:\n    filestore = cortex.options.config['basic']['filestore']\n    cortex.database.db = cortex.database.Database(filestore)\n    cortex.db = cortex.database.db\n    cortex.utils.db = cortex.database.db\n    cortex.dataset.braindata.db = cortex.database.db"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, we load the \"fsaverage\" mapper. The mapper is a matrix of shape\n(n_vertices, n_voxels), which maps each voxel to some vertices in the\nfsaverage surface. It is stored as a sparse CSR matrix. The mapper is applied\nwith a dot product ``@`` (equivalent to ``np.dot``).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from voxelwise_tutorials.io import load_hdf5_sparse_array\nvoxel_to_fsaverage = load_hdf5_sparse_array(mapper_file,\n                                            key='voxel_to_fsaverage')\nev_projected = voxel_to_fsaverage @ ev\nprint(\"(n_vertices,) =\", ev_projected.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can then create a ``Vertex`` object in ``pycortex``, containing the\nprojected data. This object can be used either in a ``pycortex`` interactive\n3D viewer, or in a ``matplotlib`` figure showing only the flatmap.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "vertex = cortex.Vertex(ev_projected, surface, vmin=0, vmax=0.7, cmap='inferno')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To start an interactive 3D viewer in the browser, use the following function:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if False:\n    cortex.webshow(vertex, open_browser=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Alternatively, to plot a flatmap in a ``matplotlib`` figure, use the\n`quickshow` function.\n\n(This function requires Inkscape to be installed. The rest of the tutorial\ndoes not use this function, so feel free to ignore.)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from cortex.testing_utils import has_installed\n\nif has_installed(\"inkscape\"):\n    fig = cortex.quickshow(vertex, colorbar_location='right')\n    plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}