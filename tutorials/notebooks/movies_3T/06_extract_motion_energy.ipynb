{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Extract motion energy features from the stimuli\n\n\nThis script describes how to extract motion-energy features from the stimuli.\n\n.. Note:: This public data set already contains precomputed motion-energy.\n    Therefore, you do not need to run this script to fit motion-energy models\n    in other part of this tutorial.\n\n*Motion-energy features:* Motion-energy features result from filtering a video\nstimulus with spatio-temporal Gabor filters. A pyramid of filters is used to\ncompute the motion-energy features at multiple spatial and temporal scales.\nMotion-energy features were introduced in [1]_.\n\nThe motion-energy extraction is performed by the package `pymoten\n<https://github.com/gallantlab/pymoten>`_. Check the pymoten `gallery of\nexamples <https://gallantlab.github.io/pymoten/auto_examples/index.html>`_ for\nvisualizing motion-energy filters, and for pymoten API usage examples.\n\nRunning time\n------------\nExtracting motion energy is a bit longer than the other examples. It typically\ntakes a couple hours to run.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# path of the data directory\nimport os\nfrom voxelwise_tutorials.io import get_data_home\ndirectory = os.path.join(get_data_home(), \"vim-4\")\nprint(directory)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load the stimuli images\n-----------------------\n\nHere the data is not loaded in memory, we only take a peak at the data shape.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import h5py\n\nfirst_file_name = os.path.join(directory, 'stimuli', 'train_00.hdf')\nprint(f\"Content of {first_file_name}:\")\nwith h5py.File(first_file_name, 'r') as f:\n    for key in f.keys():\n        print(f[key])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compute the luminance\n---------------------\n\nThe motion energy is typically not computed on RGB (color) images,\nbut on the luminance channel of the LAB color space.\nTo avoid loading the entire simulus array in memory, we use batches of data.\nThese batches can be arbitray, since the luminance is computed independently\non each image.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nfrom moten.io import imagearray2luminance\n\nfrom voxelwise_tutorials.progress_bar import bar\nfrom voxelwise_tutorials.io import load_hdf5_array\n\n\ndef compute_luminance(run_name, size=(96, 96), batch_size=100):\n\n    stimuli_file = os.path.join(directory, 'stimuli', run_name)\n\n    # get the number of images in the stimuli file\n    with h5py.File(stimuli_file, 'r') as f:\n        n_images = f['stimuli'].shape[0]\n\n    # compute the luminance on each batch\n    luminance = np.zeros((n_images, *size))\n    for start in bar(range(0, n_images, batch_size),\n                     title=f'compute_luminance({run_name})'):\n        # load the batch of images\n        batch = slice(start, start + batch_size)\n        images = load_hdf5_array(stimuli_file, key='stimuli', slice=batch)\n\n        # ``imagearray2luminance`` uses uint8 arrays\n        if images.dtype != 'uint8':\n            images = np.int_(np.clip(images, 0, 1) * 255).astype(np.uint8)\n\n        # convert RGB images to a single luminance channel\n        luminance[batch] = imagearray2luminance(images, size=size)\n\n    return luminance\n\n\nluminance_train = np.concatenate(\n    [compute_luminance(f\"train_{ii:02d}.hdf\") for ii in range(12)])\nluminance_test = compute_luminance(\"test.hdf\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compute the motion energy\n-------------------------\n\nThis is done with a ``MotionEnergyPyramid`` object of the ``pymoten``\npackage. The parameters used are the one described in [1]_.\n\nHere we use batches corresponding to run lengths. Indeed, motion energy is\ncomputed over multiple images, since the filters have a temporal component.\nTherefore, motion-energy is not independent of other images, and we cannot\narbitrarily split the images.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from scipy.signal import decimate\nfrom moten.pyramids import MotionEnergyPyramid\n\n# fixed experiment settings\nN_FRAMES_PER_SEC = 15\nN_FRAMES_PER_TR = 30\nN_TRS_PER_RUN = 300\n\n\ndef compute_motion_energy(luminance,\n                          batch_size=N_TRS_PER_RUN * N_FRAMES_PER_TR,\n                          noise=0.1):\n\n    n_frames, height, width = luminance.shape\n\n    # We create a pyramid instance, with the main motion-energy parameters.\n    pyramid = MotionEnergyPyramid(stimulus_vhsize=(height, width),\n                                  stimulus_fps=N_FRAMES_PER_SEC,\n                                  spatial_frequencies=[0, 2, 4, 8, 16, 32])\n\n    # We batch images run by run.\n    motion_energy = np.zeros((n_frames, pyramid.nfilters))\n    for ii, start in enumerate(range(0, n_frames, batch_size)):\n        batch = slice(start, start + batch_size)\n        print(\"run %d\" % ii)\n\n        # add some noise to deal with constant black areas\n        luminance_batch = luminance[batch].copy()\n        luminance_batch += np.random.randn(*luminance_batch.shape) * noise\n        luminance_batch = np.clip(luminance_batch, 0, 100)\n\n        motion_energy[batch] = pyramid.project_stimulus(luminance_batch)\n\n    # decimate to the sampling frequency of fMRI responses\n    motion_energy_decimated = decimate(motion_energy, N_FRAMES_PER_TR,\n                                       ftype='fir', axis=0)\n    return motion_energy_decimated\n\n\nmotion_energy_train = compute_motion_energy(luminance_train)\nmotion_energy_test = compute_motion_energy(luminance_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We end this script with saving the features. These features should be\napproximately equal to the \"motion-energy\" features already precomputed in\nthe public data set.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from voxelwise_tutorials.io import save_hdf5_dataset\n\nfeatures_directory = os.path.join(directory, \"features\")\nif not os.path.exists(features_directory):\n    os.makedirs(features_directory)\n\nsave_hdf5_dataset(\n    os.path.join(features_directory, \"motion_energy_recomputed.hdf\"),\n    dataset=dict(X_train=motion_energy_train, X_test=motion_energy_test,\n                 run_onsets=np.arange(0, 3600, 300)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "References\n----------\n\n.. [1] Nishimoto, S., Vu, A. T., Naselaris, T., Benjamini, Y., Yu,\n    B., & Gallant, J. L. (2011). Reconstructing visual experiences from brain\n    activity evoked by natural movies. Current Biology, 21(19), 1641-1646.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}