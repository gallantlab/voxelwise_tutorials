{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Fit a ridge model with wordnet features\n\n\nIn this example, we model the fMRI responses with semantic \"wordnet\" features,\nmanually annotated on each frame of the movie stimulus. The model is a\nregularized linear regression model, known as ridge regression. Since this\nmodel is used to predict brain activity from the stimulus, it is called a\n(voxelwise) encoding model.\n\nThis example reproduces part of the analysis described in Huth et al (2012)\n[1]_. See this publication for more details about the experiment, the wordnet\nfeatures, along with more results and more discussions.\n\n*Wordnet features:* The features used in this example are semantic labels\nmanually annotated on each frame of the movie stimulus. The semantic labels\ninclude nouns (such as \"woman\", \"car\", or \"building\") and verbs (such as\n\"talking\", \"touching\", or \"walking\"), for a total of 1705 distinct category\nlabels. To interpret our model, labels can be organized in a graph of semantic\nrelashionship based on the `Wordnet <https://wordnet.princeton.edu/>`_ dataset.\n\n*Summary:* We first concatenate the features with multiple delays, to account\nfor the slow hemodynamic response. We then fit a predictive model of BOLD\nactivity, using a  linear regression that weights differently each delayed\nfeature. The linear regression is regularized to improve robustness to\ncorrelated features and to improve generalization. The optimal regularization\nhyperparameter is selected over a grid-search with cross-validation. Finally,\nthe model generalization performance is evaluated on a held-out test set,\ncomparing the model predictions with the corresponding ground-truth fMRI\nresponses.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Path of the data directory\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\nfrom voxelwise_tutorials.io import get_data_home\ndirectory = os.path.join(get_data_home(), \"vim-4\")\nprint(directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# modify to use another subject\nsubject = \"S01\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load the data\n-------------\n\nWe first load the fMRI responses.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nfrom voxelwise_tutorials.io import load_hdf5_array\n\nfile_name = os.path.join(directory, \"responses\", f\"{subject}_responses.hdf\")\nY_train = load_hdf5_array(file_name, key=\"Y_train\")\nY_test = load_hdf5_array(file_name, key=\"Y_test\")\n\nprint(\"(n_samples_train, n_voxels) =\", Y_train.shape)\nprint(\"(n_repeats, n_samples_test, n_voxels) =\", Y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we repeat an experiment multiple times, part of the fMRI responses might\nchange. However the modeling features do not change over the repeats, so the\nvoxelwise encoding model predicts the same signal for each repeat. To have an\nupper bound of the model performances, we keep only the repeatable part of\nthe signal by averaging the test repeats. It means that the prediction\n$R^2$ scores will be relative to the explainable variance (cf. previous\nexample).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "Y_test = Y_test.mean(0)\n\nprint(\"(n_samples_test, n_voxels) =\", Y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We fill potential NaN (not-a-number) values with zeros.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "Y_train = np.nan_to_num(Y_train)\nY_test = np.nan_to_num(Y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, we load the semantic \"wordnet\" features.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "feature_space = \"wordnet\"\n\nfile_name = os.path.join(directory, \"features\", f\"{feature_space}.hdf\")\nX_train = load_hdf5_array(file_name, key=\"X_train\")\nX_test = load_hdf5_array(file_name, key=\"X_test\")\n\nprint(\"(n_samples_train, n_features) =\", X_train.shape)\nprint(\"(n_samples_test, n_features) =\", X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define the cross-validation scheme\n----------------------------------\n\nTo select the best hyperparameter through cross-validation, we must define a\ntrain-validation splitting scheme. Since fMRI time-series are autocorrelated\nin time, we should preserve as much as possible the time blocks.\nIn other words, since consecutive time samples are correlated, we should not\nput one time sample in the training set and the immediately following time\nsample in the validation set. Thus, we define here a leave-one-run-out\ncross-validation split, which preserves each recording run.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import check_cv\nfrom voxelwise_tutorials.utils import generate_leave_one_run_out\n\n# indice of first sample of each run\nrun_onsets = load_hdf5_array(file_name, key=\"run_onsets\")\nprint(run_onsets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We define a cross-validation splitter, compatible with ``scikit-learn`` API.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_samples_train = X_train.shape[0]\ncv = generate_leave_one_run_out(n_samples_train, run_onsets)\ncv = check_cv(cv)  # copy the cross-validation splitter into a reusable list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define the model\n----------------\n\nNow, let's define the model pipeline.\n\nWe first center the features, since we will not use an intercept. Indeed, the\nmean value in fMRI recording is non-informative, so each run is detrended and\ndemeaned independently, and we do not need to predict an intercept value in\nthe linear model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler(with_mean=True, with_std=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then we concatenate the features with multiple delays to account for the\nhemodynamic response. Indeed, the BOLD signal recorded in fMRI experiments is\ndelayed in time with respect to the stimulus. With different delayed versions\nof the features, the linear regression model will weight each\ndelayed feature with a different weight, to maximize the predictions.\nWith a sample every 2 seconds, we typically use 4 delays [1, 2, 3, 4] to\ncover the most part of the hemodynamic response peak.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from voxelwise_tutorials.delayer import Delayer\ndelayer = Delayer(delays=[1, 2, 3, 4])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we use a ridge regression model. Ridge regression is a linear\nregression with a L2 regularization. The L2 regularizatin improves robustness\nto correlated features and improves generalization. However, the L2\nregularization is controled by a hyperparameter ``alpha`` that needs to be\ntuned. This regularization hyperparameter is usually selected over a grid\nsearch with cross-validation, selecting the hyperparameter that maximizes the\npredictive performances on the validation set. More details about\ncross-validation can be found in the `scikit-learn documentation\n<https://scikit-learn.org/stable/modules/cross_validation.html>`_.\n\nFor computational reasons, when the number of features is larger than the\nnumber of samples, it is more efficient to solve a ridge regression using the\n(equivalent) dual formulation [2]_. This dual formulation is equivalent to\nkernel ridge regression with a linear kernel. Here, we have 3600 training\nsamples, and 1705 * 4 = 6820 features (we multiply by 4 since we use 4 time\ndelays), therefore it is more efficient to use kernel ridge regression.\n\nWith one target, we could directly use the pipeline in ``scikit-learn``'s\n``GridSearchCV``, to select the optimal regularization hyperparameter\n(``alpha``) over cross-validation. However, ``GridSearchCV`` can only\noptimize one score. Thus, in the multiple-target case, ``GridSearchCV`` can\nonly optimize (for example) the mean score over targets. Here, we want to\nfind a different optimal hyperparameter per target/voxel, so we use the\npackage `himalaya <https://github.com/gallantlab/himalaya>`_ which implements\na ``scikit-learn`` compatible estimator ``KernelRidgeCV``, with\nhyperparameter selection independently on each target.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from himalaya.kernel_ridge import KernelRidgeCV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Interestingly, ``himalaya`` implements different computational backends,\nincluding two backends that use GPU for faster computations. The two\navailable GPU backends are \"torch_cuda\" and \"cupy\". (Each backend is only\navailable if you installed the corresponding package with CUDA enabled. Check\nthe ``pytorch``/``cupy`` documentation for install instructions.)\n\nHere we use the \"torch_cuda\" backend, but if the import fails we continue\nwith the default \"numpy\" backend. The \"numpy\" backend is expected to be\nslower since it only uses the CPU.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from himalaya.backend import set_backend\nbackend = set_backend(\"torch_cuda\", on_error=\"warn\")\nprint(backend)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To speed up model fitting on GPU, we use single precision float numbers.\n(This step probably does not change significantly the performances on non-GPU\nbackends.)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X_train = X_train.astype(\"float32\")\nX_test = X_test.astype(\"float32\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since the scale of the regularization hyperparameter ``alpha`` is unknown, we\nuse a large logarithmic range, and we will check after the fit that best\nhyperparameters are not all on one range edge.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "alphas = np.logspace(1, 20, 20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We also indicate some batch sizes to limit the GPU memory.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "kernel_ridge_cv = KernelRidgeCV(\n    alphas=alphas, cv=cv,\n    solver_params=dict(n_targets_batch=500, n_alphas_batch=5,\n                       n_targets_batch_refit=100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we use a ``scikit-learn`` ``Pipeline`` to link the different steps\ntogether. A ``Pipeline`` can be used as a regular estimator, calling\n``pipeline.fit``, ``pipeline.predict``, etc. Using a ``Pipeline`` can be\nuseful to clarify the different steps, avoid cross-validation mistakes, or\nautomatically cache intermediate results. See the ``scikit-learn``\n`documentation <https://scikit-learn.org/stable/modules/compose.html>`_ for\nmore information.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import make_pipeline\npipeline = make_pipeline(\n    scaler,\n    delayer,\n    kernel_ridge_cv,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can display the ``scikit-learn`` pipeline with an HTML diagram.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from sklearn import set_config\nset_config(display='diagram')\npipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fit the model\n-------------\n\nWe fit on the train set..\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "_ = pipeline.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "..and score on the test set. Here the scores are the $R^2$ scores, with\nvalues in $]-\\infty, 1]$. A value of $1$ means the predictions\nare perfect.\n\nNote that since ``himalaya`` is specifically implementinf multiple targets\nmodels, the ``score`` method differs from ``scikit-learn`` API and returns\none score per target/voxel.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "scores = pipeline.score(X_test, Y_test)\nprint(\"(n_voxels,) =\", scores.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we fit the model on GPU, scores are returned on GPU using an array object\nspecfic to the backend we used (such as a ``torch.Tensor``). Thus, we need to\nmove them into ``numpy`` arrays on CPU, to be able to use them for example in\na ``matplotlib`` figure.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "scores = backend.to_numpy(scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot the model performances\n---------------------------\n\nTo visualize the model performances, we can plot them on a flatten\nsurface of the brain, using a mapper that is specific to the subject brain.\n(Check previous example to see how to use the mapper to Freesurfer average\nsurface.)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nfrom voxelwise_tutorials.viz import plot_flatmap_from_mapper\n\nmapper_file = os.path.join(directory, \"mappers\", f\"{subject}_mappers.hdf\")\nax = plot_flatmap_from_mapper(scores, mapper_file, vmin=0, vmax=0.4)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that the \"wordnet\" features successfully predict a part of the\nbrain activity, with $R^2$ scores as high as 0.4. Note that these\nscores are generalization scores, since they aere computed on a test set not\nseen during the mode fitting. Since we fitted a model independently on each\nvoxel, we can show the generalization performances at the maximal resolution,\nthe voxel.\n\nThe best performances are located in visual semantic areas like EBA, or FFA.\nThis is expected since the wordnet features encode semantic information about\nthe visual stimulus. For more discussions about these results, we refer the\nreader to the original publication [1]_.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot the selected hyperparameters\n---------------------------------\n\nSince the scale of alphas is unknown, we plot the optimal alphas selected by\nthe solver over cross-validation. This plot is helpful to refine the alpha\ngrid if the range is too small or too large.\n\nNote that some voxels are at the maximum regularization of the grid. These\nare voxels where the model has no predictive power, and where the optimal\nregularization is large to lead to a prediction equal to zero.\nWe do not need to extend the alpha range for these voxels.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from himalaya.viz import plot_alphas_diagnostic\nbest_alphas = backend.to_numpy(pipeline[-1].best_alphas_)\nplot_alphas_diagnostic(best_alphas=best_alphas, alphas=alphas)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compare with a model without delays\n-----------------------------------\n\nTo present an example of model comparison, we define here another model,\nwithout feature delays (i.e. no ``Delayer``). This model is unlikely to\nperform well, since fMRI responses are delayed in time with respect to\nthe stimulus.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pipeline_nodelay = make_pipeline(\n    StandardScaler(with_mean=True, with_std=False),\n    KernelRidgeCV(\n        alphas=alphas, cv=cv,\n        solver_params=dict(n_targets_batch=500, n_alphas_batch=5,\n                           n_targets_batch_refit=100)),\n)\npipeline_nodelay"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We fit and score the model as the previous one.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pipeline_nodelay.fit(X_train, Y_train)\nscores_nodelay = pipeline_nodelay.score(X_test, Y_test)\nscores_nodelay = backend.to_numpy(scores_nodelay)\nprint(\"(n_voxels,) =\", scores_nodelay.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, we plot the comparison of model performances with a 2D histogram.\nAll ~70k voxels are represented in this histogram, where the diagonal\ncorresponds to identical performance for both models. A distibution deviating\nfrom the diagonal means that one model has better predictive performances\nthan the other.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from voxelwise_tutorials.viz import plot_hist2d\n\nax = plot_hist2d(scores_nodelay, scores)\nax.set(\n    title='Generalization R2 scores',\n    xlabel='model without delays',\n    ylabel='model with delays',\n)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that the model with delays performs much better than the model without\ndelays. This can be seen in voxels with scores above 0. The distribution\nof scores below zero is not very informative, since it corresponds to voxels\nwith poor predictive performances anyway, and it only shows which model is\noverfitting the most.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Visualize the HRF\n-----------------\n\nWe just saw that delays are necessary to model the BOLD response in such\nfMRI recordings. Here we show how to visualize the hemodynamic response\nfunction (HRF), as captured in the ridge regression weights.\n\nFitting a kernel ridge regression results in a set of coefficients called the\n\"dual\" coefficients $w$. These coefficients are different from the\n\"primal\" coefficients $\\beta$ obtained with a ridge regression,\nbut the primal coefficients can be computed from the dual coefficients\nusing the training features $X$:\n\n\\begin{align}\\beta = X^\\top w\\end{align}\n\nTo better visualize the HRF, we will refit a model with more delays, but only\non a selection of voxels to speed up the computations.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# pick the 10 best voxels\nvoxel_selection = np.argsort(scores)[-10:]\n\n# define a pipeline with more delays\npipeline_many_delays = make_pipeline(\n    StandardScaler(with_mean=True, with_std=False),\n    Delayer(delays=[0, 1, 2, 3, 4, 5, 6]),\n    KernelRidgeCV(\n        alphas=alphas, cv=cv,\n        solver_params=dict(n_targets_batch=500, n_alphas_batch=5,\n                           n_targets_batch_refit=100)),\n)\n\npipeline_many_delays.fit(X_train, Y_train[:, voxel_selection])\n\n# get the (primal) ridge regression coefficients\nprimal_coef = pipeline_many_delays[-1].get_primal_coef()\nprimal_coef = backend.to_numpy(primal_coef)\n\n# get the delays\ndelays = pipeline_many_delays.named_steps['delayer'].delays\n# split the ridge coefficients per delays\nprimal_coef_per_delay = np.stack(np.split(primal_coef, len(delays), axis=0))\n\n# select the feature with the largest coefficients for each voxel\nfeature_selection = np.argmax(np.sum(np.abs(primal_coef_per_delay), axis=0),\n                              axis=0)\nprimal_coef_selection = primal_coef_per_delay[:, feature_selection,\n                                              np.arange(len(voxel_selection))]\n\nplt.plot(delays, primal_coef_selection)\nplt.xlabel('Delays')\nplt.xticks(delays)\nplt.ylabel('Ridge coefficients')\nplt.title(f'Largest feature for the {len(voxel_selection)} best voxels')\nplt.axhline(0, color='k', linewidth=0.5)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that the hemodynamic response function (HRF) is captured in the model\nweights. In practice, we can limit the number of features by using only\nthe most informative delays, for example [1, 2, 3, 4].\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "References\n----------\n\n.. [1] Huth, A. G., Nishimoto, S., Vu, A. T., & Gallant, J. L. (2012).\n   A continuous semantic space describes the representation of thousands of\n   object and action categories across the human brain. Neuron, 76(6),\n   1210-1224.\n\n.. [2] Saunders, C., Gammerman, A., & Vovk, V. (1998).\n   Ridge regression learning algorithm in dual variables.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}