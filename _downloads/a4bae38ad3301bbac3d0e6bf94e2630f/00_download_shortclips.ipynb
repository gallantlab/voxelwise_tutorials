{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Download the data set\n\nIn this script, we download the data set from Wasabi or GIN. No account is\nrequired.\n\n## Cite this data set\n\nThis tutorial is based on publicly available data [published on GIN](https://gin.g-node.org/gallantlab/shortclips). If you publish any work using\nthis data set, please cite the original publication [1]_, and the data set\n[2]_.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Download\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# path of the data directory\nfrom voxelwise_tutorials.io import get_data_home\ndirectory = get_data_home(dataset=\"shortclips\")\nprint(directory)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will only use the first subject in this tutorial, but you can run the same\nanalysis on the four other subjects. Uncomment the lines in ``DATAFILES`` to\ndownload more subjects.\n\nWe also skip the stimuli files, since the dataset provides two preprocessed\nfeature spaces to perform voxelwise modeling without requiring the original\nstimuli.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from voxelwise_tutorials.io import download_datalad\n\nDATAFILES = [\n    \"features/motion_energy.hdf\",\n    \"features/wordnet.hdf\",\n    \"mappers/S01_mappers.hdf\",\n    # \"mappers/S02_mappers.hdf\",\n    # \"mappers/S03_mappers.hdf\",\n    # \"mappers/S04_mappers.hdf\",\n    # \"mappers/S05_mappers.hdf\",\n    \"responses/S01_responses.hdf\",\n    # \"responses/S02_responses.hdf\",\n    # \"responses/S03_responses.hdf\",\n    # \"responses/S04_responses.hdf\",\n    # \"responses/S05_responses.hdf\",\n    # \"stimuli/test.hdf\",\n    # \"stimuli/train_00.hdf\",\n    # \"stimuli/train_01.hdf\",\n    # \"stimuli/train_02.hdf\",\n    # \"stimuli/train_03.hdf\",\n    # \"stimuli/train_04.hdf\",\n    # \"stimuli/train_05.hdf\",\n    # \"stimuli/train_06.hdf\",\n    # \"stimuli/train_07.hdf\",\n    # \"stimuli/train_08.hdf\",\n    # \"stimuli/train_09.hdf\",\n    # \"stimuli/train_10.hdf\",\n    # \"stimuli/train_11.hdf\",\n]\n\nsource = \"https://gin.g-node.org/gallantlab/shortclips\"\n\nfor datafile in DATAFILES:\n    local_filename = download_datalad(datafile, destination=directory,\n                                      source=source)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## References\n\n.. [1] Huth, A. G., Nishimoto, S., Vu, A. T., & Gallant, J. L. (2012). A\n    continuous semantic space describes the representation of thousands of\n    object and action categories across the human brain. Neuron, 76(6),\n    1210-1224.\n\n.. [2] Huth, A. G., Nishimoto, S., Vu, A. T., Dupr\u00e9 la Tour, T., & Gallant, J. L. (2022).\n    Gallant Lab Natural Short Clips 3T fMRI Data. http://dx.doi.org/10.12751/g-node.vy1zjd\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}