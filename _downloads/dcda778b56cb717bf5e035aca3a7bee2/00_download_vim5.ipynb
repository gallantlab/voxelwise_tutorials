{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Download the data set from CRCNS\n\n\nIn this script, we download the data set from CRCNS. A (free) account is\nrequired.\n\n.. Warning:: The data has not been publicly released yet on CRCNS, so this\n    notebook will not work ! You can download the data manually from `Google\n    Drive\n    <https://drive.google.com/drive/folders/1NuxO5_GHgDvjrL2FX5ohzAsvWpZuepIA?usp=sharing>`_,\n    or run the tutorials from `Colab\n    <https://colab.research.google.com/github/gallantlab/voxelwise_tutorials/blob/main/tutorials/notebooks/movies_3T/merged_for_colab.ipynb>`_\n\nCite this data set\n------------------\n\nThis tutorial is based on publicly available data `published on CRCNS\n<https://crcns.org/data-sets/vc/TBD>`_. If you publish any work using this data\nset, please cite the original publication [1]_, and the data set [2]_.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "raise RuntimeError(\"The data has not been publicly released yet, so \"\n                   \"this script/notebook will not work !\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Download\n--------\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# path of the data directory\nimport os\nfrom voxelwise_tutorials.io import get_data_home\ndirectory = os.path.join(get_data_home(), \"vim-5\")\nprint(directory)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will only use the first subject in this tutorial, but you can run the same\nanalysis on the four other subjects. Uncomment the lines in ``DATAFILES`` to\ndownload more subjects.\n\nWe also skip the stimuli files, since the dataset provides two preprocessed\nfeature spaces to perform voxelwise modeling without requiring the original\nstimuli.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import getpass\n\nfrom voxelwise_tutorials.io import download_crcns\n\nDATAFILES = [\n    \"TBD/features/motion_energy.hdf\",\n    \"TBD/features/wordnet.hdf\",\n    \"TBD/mappers/S01_mappers.hdf\",\n    # \"TBD/mappers/S02_mappers.hdf\",\n    # \"TBD/mappers/S03_mappers.hdf\",\n    # \"TBD/mappers/S04_mappers.hdf\",\n    # \"TBD/mappers/S05_mappers.hdf\",\n    \"TBD/responses/S01_responses.hdf\",\n    # \"TBD/responses/S02_responses.hdf\",\n    # \"TBD/responses/S03_responses.hdf\",\n    # \"TBD/responses/S04_responses.hdf\",\n    # \"TBD/responses/S05_responses.hdf\",\n    # \"TBD/stimuli/test.hdf\",\n    # \"TBD/stimuli/train_00.hdf\",\n    # \"TBD/stimuli/train_01.hdf\",\n    # \"TBD/stimuli/train_02.hdf\",\n    # \"TBD/stimuli/train_03.hdf\",\n    # \"TBD/stimuli/train_04.hdf\",\n    # \"TBD/stimuli/train_05.hdf\",\n    # \"TBD/stimuli/train_06.hdf\",\n    # \"TBD/stimuli/train_07.hdf\",\n    # \"TBD/stimuli/train_08.hdf\",\n    # \"TBD/stimuli/train_09.hdf\",\n    # \"TBD/stimuli/train_10.hdf\",\n    # \"TBD/stimuli/train_11.hdf\",\n    \"TBD/utils/wordnet_categories.txt\",\n    \"TBD/utils/wordnet_graph.dot\",\n]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "username = input(\"CRCNS username: \")\npassword = getpass.getpass(\"CRCNS password: \")\n\nfor datafile in DATAFILES:\n    local_filename = download_crcns(datafile, username, password,\n                                    destination=directory)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "References\n----------\n\n.. [1] Huth, A. G., Nishimoto, S., Vu, A. T., & Gallant, J. L. (2012). A\n    continuous semantic space describes the representation of thousands of\n    object and action categories across the human brain. Neuron, 76(6),\n    1210-1224.\n\n.. [2] Huth, A. G., Nishimoto, S., Vu, A. T., & Gallant, J. L. (2020):\n    Gallant Lab Natural Movie 3T fMRI Data. CRCNS.org.\n    http://dx.doi.org/10.6080/TBD\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}