:orphan:



.. _sphx_glr__auto_examples:

(If you are looking for some Jupyter notebooks, check the `notebooks
<https://github.com/gallantlab/voxelwise_tutorials/tree/main/tutorials/notebooks>`_
directory.)


.. raw:: html

    <div class="sphx-glr-clear"></div>



.. _sphx_glr__auto_examples_movies:

Movies tutorial
===============

This tutorial describes how to perform voxelwise modeling on a visual
imaging experiment.

**Data set:**
This tutorial is based on publicly available data
`published on CRCNS <TBD>`_ [4]_.
The data is briefly described in the dataset `description PDF <TBD>`_,
and in more details in the original publication [1]_.
If you publish work using this data set, please cite the original
publication [1]_, and the CRCNS data set [4]_.

**Models:**
This tutorial implements different voxelwise encoding models:

- a ridge model with wordnet semantic features as described in [1]_.
- a ridge model with motion-energy features as described in [2]_.
- a banded-ridge model with both feature spaces as described in [3]_.

**Scikit-learn API:** These tutorials use `scikit-learn
<https://github.com/scikit-learn/scikit-learn>`_ to define the preprocessing
steps, the modeling pipeline, and the cross-validation scheme. If you are not
familiar with the scikit-learn API, we recommend the `getting started guide
<https://scikit-learn.org/stable/getting_started.html>`_. We also use a lot of
the scikit-learn terminology, which is explained in great details in the
`glossary of common terms and API elements
<https://scikit-learn.org/stable/glossary.html#glossary>`_.

**Running time:** Most of these tutorials can be run in a reasonable time
(under 1 minute for most examples, ~7 minutes for the banded ridge example)
with a GPU backend in `himalaya <https://github.com/gallantlab/himalaya>`_.
Using a CPU backend is slower (typically 10 times slower).

**Requirements:**
This tutorial requires the following Python packages:

- voxelwise_tutorials  (this repository) and its dependencies
- cupy or pytorch  (optional, to use a GPU backend in himalaya)

**References:**

.. [1] Huth, A. G., Nishimoto, S., Vu, A. T., & Gallant, J. L. (2012).
    A continuous semantic space describes the representation of thousands of
    object and action categories across the human brain. Neuron, 76(6),
    1210-1224.

.. [2] Nishimoto, S., Vu, A. T., Naselaris, T., Benjamini, Y., Yu,
    B., & Gallant, J. L. (2011). Reconstructing visual experiences from brain
    activity evoked by natural movies. Current Biology, 21(19), 1641-1646.

.. [3] Nunez-Elizalde, A. O., Huth, A. G., & Gallant, J. L. (2019).
    Voxelwise encoding models with non-spherical multivariate normal priors.
    Neuroimage, 197, 482-492.

.. [4] Huth, A. G., Nishimoto, S., Vu, A. T., & Gallant, J. L. (2020):
    Gallant Lab Natural Movie 3T fMRI Data. CRCNS.org.
    http://dx.doi.org/10.6080/TBD



.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="In this script, we download the data set from CRCNS. A (free) account is required.">

.. only:: html

 .. figure:: /_auto_examples/movies/images/thumb/sphx_glr_00_download_vim5_thumb.png
     :alt: Download the data set from CRCNS

     :ref:`sphx_glr__auto_examples_movies_00_download_vim5.py`

.. raw:: html

    </div>


.. toctree::
   :hidden:

   /_auto_examples/movies/00_download_vim5

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="In this script, we setup a Google Colab environment. This script will only work when run from `...">

.. only:: html

 .. figure:: /_auto_examples/movies/images/thumb/sphx_glr_00_setup_colab_thumb.png
     :alt: Setup Google Colab

     :ref:`sphx_glr__auto_examples_movies_00_setup_colab.py`

.. raw:: html

    </div>


.. toctree::
   :hidden:

   /_auto_examples/movies/00_setup_colab

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="Before fitting any voxelwise model to fMRI responses, it is good practice to quantify the amoun...">

.. only:: html

 .. figure:: /_auto_examples/movies/images/thumb/sphx_glr_01_plot_explainable_variance_thumb.png
     :alt: Compute the explainable variance

     :ref:`sphx_glr__auto_examples_movies_01_plot_explainable_variance.py`

.. raw:: html

    </div>


.. toctree::
   :hidden:

   /_auto_examples/movies/01_plot_explainable_variance

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="In this example, we model the fMRI responses with semantic &quot;wordnet&quot; features, manually annotat...">

.. only:: html

 .. figure:: /_auto_examples/movies/images/thumb/sphx_glr_02_plot_wordnet_model_thumb.png
     :alt: Fit a ridge model with wordnet features

     :ref:`sphx_glr__auto_examples_movies_02_plot_wordnet_model.py`

.. raw:: html

    </div>


.. toctree::
   :hidden:

   /_auto_examples/movies/02_plot_wordnet_model

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="In this example, we describe how the hemodynamic response function was estimated in the previou...">

.. only:: html

 .. figure:: /_auto_examples/movies/images/thumb/sphx_glr_03_plot_hemodynamic_response_thumb.png
     :alt: Visualize the hemodynamic response

     :ref:`sphx_glr__auto_examples_movies_03_plot_hemodynamic_response.py`

.. raw:: html

    </div>


.. toctree::
   :hidden:

   /_auto_examples/movies/03_plot_hemodynamic_response

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="In this example, we model the fMRI responses with motion-energy features extracted from the mov...">

.. only:: html

 .. figure:: /_auto_examples/movies/images/thumb/sphx_glr_04_plot_motion_energy_model_thumb.png
     :alt: Fit a ridge model with motion energy features

     :ref:`sphx_glr__auto_examples_movies_04_plot_motion_energy_model.py`

.. raw:: html

    </div>


.. toctree::
   :hidden:

   /_auto_examples/movies/04_plot_motion_energy_model

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="In this example, we model the fMRI responses with a banded ridge regression, with two different...">

.. only:: html

 .. figure:: /_auto_examples/movies/images/thumb/sphx_glr_05_plot_banded_ridge_model_thumb.png
     :alt: Fit a banded ridge model with both wordnet and motion energy features

     :ref:`sphx_glr__auto_examples_movies_05_plot_banded_ridge_model.py`

.. raw:: html

    </div>


.. toctree::
   :hidden:

   /_auto_examples/movies/05_plot_banded_ridge_model

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This script describes how to extract motion-energy features from the stimuli.">

.. only:: html

 .. figure:: /_auto_examples/movies/images/thumb/sphx_glr_06_extract_motion_energy_thumb.png
     :alt: Extract motion energy features from the stimuli

     :ref:`sphx_glr__auto_examples_movies_06_extract_motion_energy.py`

.. raw:: html

    </div>


.. toctree::
   :hidden:

   /_auto_examples/movies/06_extract_motion_energy
.. raw:: html

    <div class="sphx-glr-clear"></div>



.. _sphx_glr__auto_examples_movies_deprecated:

|
|

Movies tutorial (deprecated)
============================

.. Note::
    This tutorial is redundant with the "Movies tutorial". It uses a
    different data set with brain responses limited to the occipital lobe,
    and with no mappers to plot the data on flatmaps.
    Using the "Movies tutorial" with full brain responses is recommended.

This tutorial describes how to perform voxelwise modeling on a visual
imaging experiment.

**Data set:**
This tutorial is based on publicly available data published on
`CRCNS <https://crcns.org/data-sets/vc/vim-2/about-vim-2>`_ [6]_.
The data is briefly described in the dataset description
`PDF <https://crcns.org/files/data/vim-2/crcns-vim-2-data-description.pdf>`_,
and in more details in the original publication [5]_.
If you publish work using this data set, please cite the original
publication [5]_, and the CRCNS data set [6]_.


**Requirements:**
This tutorial requires the following Python packages:

- voxelwise_tutorials  (this repository) and its dependencies
- cupy or pytorch  (optional, to use a GPU backend in himalaya)

**References:**

.. [5] Nishimoto, S., Vu, A. T., Naselaris, T., Benjamini, Y., Yu,
    B., & Gallant, J. L. (2011). Reconstructing visual experiences from brain
    activity evoked by natural movies. Current Biology, 21(19), 1641-1646.

.. [6] Nishimoto, S., Vu, A. T., Naselaris, T., Benjamini, Y., Yu,
    B., & Gallant, J. L. (2014): Gallant Lab Natural Movie 4T fMRI Data.
    CRCNS.org. http://dx.doi.org/10.6080/K00Z715X



.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="In this script, we download the data set from CRCNS. A (free) account is required.">

.. only:: html

 .. figure:: /_auto_examples/movies_deprecated/images/thumb/sphx_glr_00_download_vim2_thumb.png
     :alt: Download the data set from CRCNS

     :ref:`sphx_glr__auto_examples_movies_deprecated_00_download_vim2.py`

.. raw:: html

    </div>


.. toctree::
   :hidden:

   /_auto_examples/movies_deprecated/00_download_vim2

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="This script describes how to extract motion-energy features from the stimuli.">

.. only:: html

 .. figure:: /_auto_examples/movies_deprecated/images/thumb/sphx_glr_01_extract_motion_energy_thumb.png
     :alt: Extract motion energy features from the stimuli

     :ref:`sphx_glr__auto_examples_movies_deprecated_01_extract_motion_energy.py`

.. raw:: html

    </div>


.. toctree::
   :hidden:

   /_auto_examples/movies_deprecated/01_extract_motion_energy

.. raw:: html

    <div class="sphx-glr-thumbcontainer" tooltip="In this example, we model the fMRI responses with motion-energy features extracted from the mov...">

.. only:: html

 .. figure:: /_auto_examples/movies_deprecated/images/thumb/sphx_glr_02_plot_ridge_model_thumb.png
     :alt: Fit a ridge model with motion energy features

     :ref:`sphx_glr__auto_examples_movies_deprecated_02_plot_ridge_model.py`

.. raw:: html

    </div>


.. toctree::
   :hidden:

   /_auto_examples/movies_deprecated/02_plot_ridge_model
.. raw:: html

    <div class="sphx-glr-clear"></div>



.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-gallery


  .. container:: sphx-glr-download sphx-glr-download-python

    :download:`Download all examples in Python source code: _auto_examples_python.zip </_auto_examples/_auto_examples_python.zip>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

    :download:`Download all examples in Jupyter notebooks: _auto_examples_jupyter.zip </_auto_examples/_auto_examples_jupyter.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
