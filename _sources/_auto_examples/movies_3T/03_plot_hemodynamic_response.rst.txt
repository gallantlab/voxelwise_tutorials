.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download__auto_examples_movies_3T_03_plot_hemodynamic_response.py>`     to download the full example code
    .. rst-class:: sphx-glr-example-title

    .. _sphx_glr__auto_examples_movies_3T_03_plot_hemodynamic_response.py:


==================================
Visualize the hemodynamic response
==================================

In this example, we describe how the hemodynamic response is estimated in the
previous model. We fit the same ridge model as in the previous example, and
further describe the need to delay the features in time.

As explained in previous example, the BOLD signal recorded in fMRI experiments
is delayed in time with respect to the stimulus. With different delayed
versions of the features, the linear regression model weight each delayed
feature with a different weight, to maximize the predictions. With a sample
every 2 seconds, we typically use 4 delays [1, 2, 3, 4] to cover the most part
of the hemodynamic response peak.

In this example, we show the descrease in prediction performances when using no
delays. We also show how to visualize the estimated hemodynamic response
function (HRF) using more delays.


.. code-block:: default








Path of the data directory


.. code-block:: default

    import os
    from voxelwise_tutorials.io import get_data_home
    directory = os.path.join(get_data_home(), "vim-5")
    print(directory)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    /home/jlg/tomdlt/voxelwise_tutorials_data/vim-5





.. code-block:: default


    # modify to use another subject
    subject = "S01"








Load the data
-------------

We first load the fMRI responses.


.. code-block:: default

    import numpy as np
    from voxelwise_tutorials.io import load_hdf5_array

    file_name = os.path.join(directory, "responses", f"{subject}_responses.hdf")
    Y_train = load_hdf5_array(file_name, key="Y_train")
    Y_test = load_hdf5_array(file_name, key="Y_test")

    print("(n_samples_train, n_voxels) =", Y_train.shape)
    print("(n_repeats, n_samples_test, n_voxels) =", Y_test.shape)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    (n_samples_train, n_voxels) = (3600, 84038)
    (n_repeats, n_samples_test, n_voxels) = (10, 270, 84038)




We average the test repeats, to remove the non-repeatable part of fMRI
responses.


.. code-block:: default

    Y_test = Y_test.mean(0)

    print("(n_samples_test, n_voxels) =", Y_test.shape)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    (n_samples_test, n_voxels) = (270, 84038)




We fill potential NaN (not-a-number) values with zeros.


.. code-block:: default

    Y_train = np.nan_to_num(Y_train)
    Y_test = np.nan_to_num(Y_test)








Then, we load the semantic "wordnet" features.


.. code-block:: default

    feature_space = "wordnet"

    file_name = os.path.join(directory, "features", f"{feature_space}.hdf")
    X_train = load_hdf5_array(file_name, key="X_train")
    X_test = load_hdf5_array(file_name, key="X_test")

    print("(n_samples_train, n_features) =", X_train.shape)
    print("(n_samples_test, n_features) =", X_test.shape)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    (n_samples_train, n_features) = (3600, 1705)
    (n_samples_test, n_features) = (270, 1705)




Define the cross-validation scheme
----------------------------------

We define the same leave-one-run-out cross-validation split as in the
previous example.


.. code-block:: default


    from sklearn.model_selection import check_cv
    from voxelwise_tutorials.utils import generate_leave_one_run_out

    # indice of first sample of each run
    run_onsets = load_hdf5_array(file_name, key="run_onsets")
    print(run_onsets)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    [   0  300  600  900 1200 1500 1800 2100 2400 2700 3000 3300]




We define a cross-validation splitter, compatible with ``scikit-learn`` API.


.. code-block:: default

    n_samples_train = X_train.shape[0]
    cv = generate_leave_one_run_out(n_samples_train, run_onsets)
    cv = check_cv(cv)  # copy the cross-validation splitter into a reusable list








Define the model
----------------

We define the same model as in the previous example. See the previous
example for more details about the model definition.


.. code-block:: default


    from sklearn.pipeline import make_pipeline
    from sklearn.preprocessing import StandardScaler
    from voxelwise_tutorials.delayer import Delayer
    from himalaya.kernel_ridge import KernelRidgeCV
    from himalaya.backend import set_backend
    backend = set_backend("torch_cuda", on_error="warn")

    X_train = X_train.astype("float32")
    X_test = X_test.astype("float32")

    alphas = np.logspace(1, 20, 20)

    pipeline = make_pipeline(
        StandardScaler(with_mean=True, with_std=False),
        Delayer(delays=[1, 2, 3, 4]),
        KernelRidgeCV(
            alphas=alphas, cv=cv,
            solver_params=dict(n_targets_batch=500, n_alphas_batch=5,
                               n_targets_batch_refit=100)),
    )









.. code-block:: default

    from sklearn import set_config
    set_config(display='diagram')  # requires scikit-learn 0.23
    pipeline






.. only:: builder_html

    .. raw:: html

        <style>#sk-8ec9895b-3f64-4a34-9f53-f0a6cac5f5a2 {color: black;background-color: white;}#sk-8ec9895b-3f64-4a34-9f53-f0a6cac5f5a2 pre{padding: 0;}#sk-8ec9895b-3f64-4a34-9f53-f0a6cac5f5a2 div.sk-toggleable {background-color: white;}#sk-8ec9895b-3f64-4a34-9f53-f0a6cac5f5a2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-8ec9895b-3f64-4a34-9f53-f0a6cac5f5a2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-8ec9895b-3f64-4a34-9f53-f0a6cac5f5a2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-8ec9895b-3f64-4a34-9f53-f0a6cac5f5a2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-8ec9895b-3f64-4a34-9f53-f0a6cac5f5a2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-8ec9895b-3f64-4a34-9f53-f0a6cac5f5a2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-8ec9895b-3f64-4a34-9f53-f0a6cac5f5a2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-8ec9895b-3f64-4a34-9f53-f0a6cac5f5a2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-8ec9895b-3f64-4a34-9f53-f0a6cac5f5a2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-8ec9895b-3f64-4a34-9f53-f0a6cac5f5a2 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-8ec9895b-3f64-4a34-9f53-f0a6cac5f5a2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-8ec9895b-3f64-4a34-9f53-f0a6cac5f5a2 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-8ec9895b-3f64-4a34-9f53-f0a6cac5f5a2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-8ec9895b-3f64-4a34-9f53-f0a6cac5f5a2 div.sk-item {z-index: 1;}#sk-8ec9895b-3f64-4a34-9f53-f0a6cac5f5a2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-8ec9895b-3f64-4a34-9f53-f0a6cac5f5a2 div.sk-parallel::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-8ec9895b-3f64-4a34-9f53-f0a6cac5f5a2 div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-8ec9895b-3f64-4a34-9f53-f0a6cac5f5a2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-8ec9895b-3f64-4a34-9f53-f0a6cac5f5a2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-8ec9895b-3f64-4a34-9f53-f0a6cac5f5a2 div.sk-parallel-item:only-child::after {width: 0;}#sk-8ec9895b-3f64-4a34-9f53-f0a6cac5f5a2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-8ec9895b-3f64-4a34-9f53-f0a6cac5f5a2 div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-8ec9895b-3f64-4a34-9f53-f0a6cac5f5a2 div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-8ec9895b-3f64-4a34-9f53-f0a6cac5f5a2 div.sk-container {display: inline-block;position: relative;}</style><div id="sk-8ec9895b-3f64-4a34-9f53-f0a6cac5f5a2" class"sk-top-container"><div class="sk-container"><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="fad70aa3-8f33-4d21-9dbe-1eaf3e5e7d42" type="checkbox" ><label class="sk-toggleable__label" for="fad70aa3-8f33-4d21-9dbe-1eaf3e5e7d42">Pipeline</label><div class="sk-toggleable__content"><pre>Pipeline(steps=[('standardscaler', StandardScaler(with_std=False)),
                        ('delayer', Delayer(delays=[1, 2, 3, 4])),
                        ('kernelridgecv',
                         KernelRidgeCV(alphas=array([1.e+01, 1.e+02, 1.e+03, 1.e+04, 1.e+05, 1.e+06, 1.e+07, 1.e+08,
               1.e+09, 1.e+10, 1.e+11, 1.e+12, 1.e+13, 1.e+14, 1.e+15, 1.e+16,
               1.e+17, 1.e+18, 1.e+19, 1.e+20]),
                                       cv=_CVIterableWrapper(cv=[(array([   0,    1, ..., 3598, 3599]), array...99])), (array([   0,    1, ..., 3598, 3599]), array([1800, 1801, ..., 2098, 2099])), (array([   0,    1, ..., 3598, 3599]), array([ 900,  901, ..., 1198, 1199])), (array([   0,    1, ..., 3598, 3599]), array([300, 301, ..., 5...1, ..., 2698, 2699])), (array([   0,    1, ..., 3598, 3599]), array([1500, 1501, ..., 1798, 1799]))]),
                                       solver_params={'n_alphas_batch': 5,
                                                      'n_targets_batch': 500,
                                                      'n_targets_batch_refit': 100}))])</pre></div></div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="169b2428-12c8-45df-962a-6719ca2de772" type="checkbox" ><label class="sk-toggleable__label" for="169b2428-12c8-45df-962a-6719ca2de772">StandardScaler</label><div class="sk-toggleable__content"><pre>StandardScaler(with_std=False)</pre></div></div></div><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="4c21ddca-a875-4490-8ea6-3e34e91f4ae3" type="checkbox" ><label class="sk-toggleable__label" for="4c21ddca-a875-4490-8ea6-3e34e91f4ae3">Delayer</label><div class="sk-toggleable__content"><pre>Delayer(delays=[1, 2, 3, 4])</pre></div></div></div><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="d5abe442-ae56-4ff1-9d6e-39ed67c91f82" type="checkbox" ><label class="sk-toggleable__label" for="d5abe442-ae56-4ff1-9d6e-39ed67c91f82">KernelRidgeCV</label><div class="sk-toggleable__content"><pre>KernelRidgeCV(alphas=array([1.e+01, 1.e+02, 1.e+03, 1.e+04, 1.e+05, 1.e+06, 1.e+07, 1.e+08,
               1.e+09, 1.e+10, 1.e+11, 1.e+12, 1.e+13, 1.e+14, 1.e+15, 1.e+16,
               1.e+17, 1.e+18, 1.e+19, 1.e+20]),
                      cv=_CVIterableWrapper(cv=[(array([   0,    1, ..., 3598, 3599]), array([1200, 1201, ..., 1498, 1499])), (array([   0,    1, ..., 3598, 3599]), array([1800, 1801, ..., 2098, 2099])), (array([   0,    1, ..., 3598, 3599]), array([ 900,  901, ..., 1198, 1199])), (array([   0,    1, ..., 3598, 3599]), array([300, 301, ..., 5...1, ..., 2698, 2699])), (array([   0,    1, ..., 3598, 3599]), array([1500, 1501, ..., 1798, 1799]))]),
                      solver_params={'n_alphas_batch': 5, 'n_targets_batch': 500,
                                     'n_targets_batch_refit': 100})</pre></div></div></div></div></div></div></div>
        <br />
        <br />

Fit the model
-------------

We fit on the train set, and score on the test set.


.. code-block:: default


    pipeline.fit(X_train, Y_train)

    scores = pipeline.score(X_test, Y_test)
    scores = backend.to_numpy(scores)
    print("(n_voxels,) =", scores.shape)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    (n_voxels,) = (84038,)




Compare with a model without delays
-----------------------------------

We define here another model without feature delays (i.e. no ``Delayer``).
Because the BOLD signal is inherently slow due to the dynamics of
neuro-vascular coupling, this model is unlikely to perform well.


.. code-block:: default


    pipeline_no_delay = make_pipeline(
        StandardScaler(with_mean=True, with_std=False),
        KernelRidgeCV(
            alphas=alphas, cv=cv,
            solver_params=dict(n_targets_batch=500, n_alphas_batch=5,
                               n_targets_batch_refit=100)),
    )
    pipeline_no_delay






.. only:: builder_html

    .. raw:: html

        <style>#sk-9a2ae0bf-d5e5-42c0-819b-01a6dd0d5bc8 {color: black;background-color: white;}#sk-9a2ae0bf-d5e5-42c0-819b-01a6dd0d5bc8 pre{padding: 0;}#sk-9a2ae0bf-d5e5-42c0-819b-01a6dd0d5bc8 div.sk-toggleable {background-color: white;}#sk-9a2ae0bf-d5e5-42c0-819b-01a6dd0d5bc8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-9a2ae0bf-d5e5-42c0-819b-01a6dd0d5bc8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-9a2ae0bf-d5e5-42c0-819b-01a6dd0d5bc8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-9a2ae0bf-d5e5-42c0-819b-01a6dd0d5bc8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-9a2ae0bf-d5e5-42c0-819b-01a6dd0d5bc8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-9a2ae0bf-d5e5-42c0-819b-01a6dd0d5bc8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-9a2ae0bf-d5e5-42c0-819b-01a6dd0d5bc8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-9a2ae0bf-d5e5-42c0-819b-01a6dd0d5bc8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-9a2ae0bf-d5e5-42c0-819b-01a6dd0d5bc8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-9a2ae0bf-d5e5-42c0-819b-01a6dd0d5bc8 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-9a2ae0bf-d5e5-42c0-819b-01a6dd0d5bc8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-9a2ae0bf-d5e5-42c0-819b-01a6dd0d5bc8 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-9a2ae0bf-d5e5-42c0-819b-01a6dd0d5bc8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-9a2ae0bf-d5e5-42c0-819b-01a6dd0d5bc8 div.sk-item {z-index: 1;}#sk-9a2ae0bf-d5e5-42c0-819b-01a6dd0d5bc8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-9a2ae0bf-d5e5-42c0-819b-01a6dd0d5bc8 div.sk-parallel::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-9a2ae0bf-d5e5-42c0-819b-01a6dd0d5bc8 div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-9a2ae0bf-d5e5-42c0-819b-01a6dd0d5bc8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-9a2ae0bf-d5e5-42c0-819b-01a6dd0d5bc8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-9a2ae0bf-d5e5-42c0-819b-01a6dd0d5bc8 div.sk-parallel-item:only-child::after {width: 0;}#sk-9a2ae0bf-d5e5-42c0-819b-01a6dd0d5bc8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-9a2ae0bf-d5e5-42c0-819b-01a6dd0d5bc8 div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-9a2ae0bf-d5e5-42c0-819b-01a6dd0d5bc8 div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-9a2ae0bf-d5e5-42c0-819b-01a6dd0d5bc8 div.sk-container {display: inline-block;position: relative;}</style><div id="sk-9a2ae0bf-d5e5-42c0-819b-01a6dd0d5bc8" class"sk-top-container"><div class="sk-container"><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="40e51a2c-c180-40c6-b100-7f77dcb002f6" type="checkbox" ><label class="sk-toggleable__label" for="40e51a2c-c180-40c6-b100-7f77dcb002f6">Pipeline</label><div class="sk-toggleable__content"><pre>Pipeline(steps=[('standardscaler', StandardScaler(with_std=False)),
                        ('kernelridgecv',
                         KernelRidgeCV(alphas=array([1.e+01, 1.e+02, 1.e+03, 1.e+04, 1.e+05, 1.e+06, 1.e+07, 1.e+08,
               1.e+09, 1.e+10, 1.e+11, 1.e+12, 1.e+13, 1.e+14, 1.e+15, 1.e+16,
               1.e+17, 1.e+18, 1.e+19, 1.e+20]),
                                       cv=_CVIterableWrapper(cv=[(array([   0,    1, ..., 3598, 3599]), array([1200, 1201, ..., 1498, 1499])), (array([   0,    1, ..., 3598, 3599]), array([1800, 1801, ..., 2098, 2099])), (array([   0,    1, ..., 3598, 3599]), array([ 900,  901, ..., 1198, 1199])), (array([   0,    1, ..., 3598, 3599]), array([300, 301, ..., 5...1, ..., 2698, 2699])), (array([   0,    1, ..., 3598, 3599]), array([1500, 1501, ..., 1798, 1799]))]),
                                       solver_params={'n_alphas_batch': 5,
                                                      'n_targets_batch': 500,
                                                      'n_targets_batch_refit': 100}))])</pre></div></div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="b1811614-54e2-486e-bf94-2170877c04ca" type="checkbox" ><label class="sk-toggleable__label" for="b1811614-54e2-486e-bf94-2170877c04ca">StandardScaler</label><div class="sk-toggleable__content"><pre>StandardScaler(with_std=False)</pre></div></div></div><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="f13adc73-286e-40bb-8794-5e184789c819" type="checkbox" ><label class="sk-toggleable__label" for="f13adc73-286e-40bb-8794-5e184789c819">KernelRidgeCV</label><div class="sk-toggleable__content"><pre>KernelRidgeCV(alphas=array([1.e+01, 1.e+02, 1.e+03, 1.e+04, 1.e+05, 1.e+06, 1.e+07, 1.e+08,
               1.e+09, 1.e+10, 1.e+11, 1.e+12, 1.e+13, 1.e+14, 1.e+15, 1.e+16,
               1.e+17, 1.e+18, 1.e+19, 1.e+20]),
                      cv=_CVIterableWrapper(cv=[(array([   0,    1, ..., 3598, 3599]), array([1200, 1201, ..., 1498, 1499])), (array([   0,    1, ..., 3598, 3599]), array([1800, 1801, ..., 2098, 2099])), (array([   0,    1, ..., 3598, 3599]), array([ 900,  901, ..., 1198, 1199])), (array([   0,    1, ..., 3598, 3599]), array([300, 301, ..., 5...1, ..., 2698, 2699])), (array([   0,    1, ..., 3598, 3599]), array([1500, 1501, ..., 1798, 1799]))]),
                      solver_params={'n_alphas_batch': 5, 'n_targets_batch': 500,
                                     'n_targets_batch_refit': 100})</pre></div></div></div></div></div></div></div>
        <br />
        <br />

We fit and score the model as the previous one.


.. code-block:: default

    pipeline_no_delay.fit(X_train, Y_train)
    scores_nodelay = pipeline_no_delay.score(X_test, Y_test)
    scores_nodelay = backend.to_numpy(scores_nodelay)
    print("(n_voxels,) =", scores_nodelay.shape)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    (n_voxels,) = (84038,)




Then, we plot the comparison of model performances with a 2D histogram.
All ~70k voxels are represented in this histogram, where the diagonal
corresponds to identical performance for both models. A distibution deviating
from the diagonal means that one model has better predictive performances
than the other.


.. code-block:: default

    import matplotlib.pyplot as plt
    from voxelwise_tutorials.viz import plot_hist2d

    ax = plot_hist2d(scores_nodelay, scores)
    ax.set(
        title='Generalization R2 scores',
        xlabel='model without delays',
        ylabel='model with delays',
    )
    plt.show()




.. image:: /_auto_examples/movies_3T/images/sphx_glr_03_plot_hemodynamic_response_001.png
    :alt: Generalization R2 scores
    :class: sphx-glr-single-img





We see that the model with delays performs much better than the model without
delays. This can be seen in voxels with scores above 0. The distribution
of scores below zero is not very informative, since it corresponds to voxels
with poor predictive performances anyway, and it only shows which model is
overfitting the most.

Visualize the HRF
-----------------

We just saw that delays are necessary to model BOLD responses. Here we show
how the fitted ridge regression weights follow the hemodynamic response
function (HRF).

Fitting a kernel ridge regression results in a set of coefficients called the
"dual" coefficients :math:`w`. These coefficients differ from the "primal"
coefficients :math:`\beta` obtained with a ridge regression, but the primal
coefficients can be computed from the dual coefficients using the training
features :math:`X`:

.. math::

    \beta = X^\top w

To better visualize the HRF, we will refit a model with more delays, but only
on a selection of voxels to speed up the computations.


.. code-block:: default


    # pick the 10 best voxels
    voxel_selection = np.argsort(scores)[-10:]

    # define a pipeline with more delays
    pipeline_more_delays = make_pipeline(
        StandardScaler(with_mean=True, with_std=False),
        Delayer(delays=[0, 1, 2, 3, 4, 5, 6]),
        KernelRidgeCV(
            alphas=alphas, cv=cv,
            solver_params=dict(n_targets_batch=500, n_alphas_batch=5,
                               n_targets_batch_refit=100)),
    )

    pipeline_more_delays.fit(X_train, Y_train[:, voxel_selection])

    # get the (primal) ridge regression coefficients
    primal_coef = pipeline_more_delays[-1].get_primal_coef()
    primal_coef = backend.to_numpy(primal_coef)

    # split the ridge coefficients per delays
    delayer = pipeline_more_delays.named_steps['delayer']
    primal_coef_per_delay = delayer.reshape_by_delays(primal_coef, axis=0)
    print("(n_delays, n_features, n_voxels) =", primal_coef_per_delay.shape)

    # select the feature with the largest coefficients for each voxel
    feature_selection = np.argmax(np.sum(np.abs(primal_coef_per_delay), axis=0),
                                  axis=0)
    primal_coef_selection = primal_coef_per_delay[:, feature_selection,
                                                  np.arange(len(voxel_selection))]

    plt.plot(delayer.delays, primal_coef_selection)
    plt.xlabel('Delays')
    plt.xticks(delayer.delays)
    plt.ylabel('Ridge coefficients')
    plt.title(f'Largest feature for the {len(voxel_selection)} best voxels')
    plt.axhline(0, color='k', linewidth=0.5)
    plt.show()




.. image:: /_auto_examples/movies_3T/images/sphx_glr_03_plot_hemodynamic_response_002.png
    :alt: Largest feature for the 10 best voxels
    :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    (n_delays, n_features, n_voxels) = (7, 1705, 10)




We see that the hemodynamic response function (HRF) is captured in the model
weights. Note that in this dataset, the brain responses are recorded every
two seconds.


.. code-block:: default


    del pipeline








.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  59.977 seconds)


.. _sphx_glr_download__auto_examples_movies_3T_03_plot_hemodynamic_response.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: 03_plot_hemodynamic_response.py <03_plot_hemodynamic_response.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: 03_plot_hemodynamic_response.ipynb <03_plot_hemodynamic_response.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
