{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Extract motion-energy features from the stimuli\n",
        "\n",
        "This example shows how to extract motion-energy features from the stimuli.\n",
        "\n",
        ":::{admonition} Long running time!\n",
        ":class: warning\n",
        "Running this example takes a couple of hours.\n",
        ":::\n",
        "\n",
        "Motion-energy features result from filtering a video\n",
        "stimulus with spatio-temporal Gabor filters. A pyramid of filters is used to\n",
        "compute the motion-energy features at multiple spatial and temporal scales.\n",
        "Motion-energy features were introduced in {cite:t}`nishimoto2011`.\n",
        "\n",
        "The motion-energy extraction is performed by the package \n",
        "[pymoten](https://github.com/gallantlab/pymoten) {cite}`nunez2021software`.\n",
        "\n",
        "Check the pymoten [gallery of examples](https://gallantlab.github.io/pymoten/auto_examples/index.html) for\n",
        "visualizing motion-energy filters, and for pymoten API usage examples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load the stimuli images\n",
        "(We downloaded the files in the previous script.)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# path of the data directory\n",
        "from voxelwise_tutorials.io import get_data_home\n",
        "directory = get_data_home(dataset=\"vim-2\")\n",
        "print(directory)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here the data is not loaded in memory, we only take a peak at the data shape.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import h5py\n",
        "\n",
        "with h5py.File(os.path.join(directory, 'Stimuli.mat'), 'r') as f:\n",
        "    print(f.keys())  # Show all variables\n",
        "\n",
        "    for key in f.keys():\n",
        "        print(f[key])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compute the luminance\n",
        "\n",
        "The motion energy is typically not computed on RGB (color) images,\n",
        "but on the luminance channel of the LAB color space.\n",
        "To avoid loading the entire simulus array in memory, we use batches of data.\n",
        "These batches can be arbitrary, since the luminance is computed independently\n",
        "on each image.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from moten.io import imagearray2luminance\n",
        "from himalaya.progress_bar import bar\n",
        "\n",
        "\n",
        "def compute_luminance(train_or_test, batch_size=1024):\n",
        "\n",
        "    with h5py.File(os.path.join(directory, 'Stimuli.mat'), 'r') as f:\n",
        "\n",
        "        if train_or_test == 'train':\n",
        "            data = f['st']\n",
        "        elif train_or_test == 'test':\n",
        "            data = f['sv']\n",
        "        else:\n",
        "            raise ValueError('Unknown parameter train_or_test=%r.' %\n",
        "                             train_or_test)\n",
        "\n",
        "        title = \"compute_luminance(%s)\" % train_or_test\n",
        "        luminance = np.zeros((data.shape[0], data.shape[2], data.shape[3]))\n",
        "        for start in bar(range(0, data.shape[0], batch_size), title):\n",
        "            batch = slice(start, start + batch_size)\n",
        "\n",
        "            # transpose to corresponds to rgb2lab inputs\n",
        "            rgb_batch = np.transpose(data[batch], [0, 2, 3, 1])\n",
        "\n",
        "            # make sure we use uint8\n",
        "            if rgb_batch.dtype != 'uint8':\n",
        "                rgb_batch = np.int_(np.clip(rgb_batch, 0, 1) * 255).astype(\n",
        "                    np.uint8)\n",
        "\n",
        "            # convert RGB images to a single luminance channel\n",
        "            luminance[batch] = imagearray2luminance(rgb_batch)\n",
        "\n",
        "    return luminance\n",
        "\n",
        "\n",
        "luminance_train = compute_luminance(\"train\")\n",
        "luminance_test = compute_luminance(\"test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compute the motion energy\n",
        "\n",
        "This is done with a ``MotionEnergyPyramid`` object of the ``pymoten``\n",
        "package. The parameters used are the one described in {cite:t}`nishimoto2011`.\n",
        "\n",
        "Here we use batches corresponding to run lengths. Indeed, motion energy is\n",
        "computed over multiple images, since the filters have a temporal component.\n",
        "Therefore, motion-energy is not independent of other images, and we cannot\n",
        "arbitrarily split the images.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from scipy.signal import decimate\n",
        "from moten.pyramids import MotionEnergyPyramid\n",
        "\n",
        "# fixed experiment settings\n",
        "N_FRAMES_PER_SEC = 15\n",
        "N_FRAMES_PER_TR = 15\n",
        "N_TRS_PER_RUN = 600\n",
        "\n",
        "\n",
        "def compute_motion_energy(luminance,\n",
        "                          batch_size=N_TRS_PER_RUN * N_FRAMES_PER_TR,\n",
        "                          noise=0.1):\n",
        "\n",
        "    n_frames, height, width = luminance.shape\n",
        "\n",
        "    # We create a pyramid instance, with the main motion-energy parameters.\n",
        "    pyramid = MotionEnergyPyramid(stimulus_vhsize=(height, width),\n",
        "                                  stimulus_fps=N_FRAMES_PER_SEC,\n",
        "                                  spatial_frequencies=[0, 2, 4, 8, 16, 32])\n",
        "\n",
        "    # We batch images run by run.\n",
        "    motion_energy = np.zeros((n_frames, pyramid.nfilters))\n",
        "    for ii, start in enumerate(range(0, n_frames, batch_size)):\n",
        "        batch = slice(start, start + batch_size)\n",
        "        print(\"run %d\" % ii)\n",
        "\n",
        "        # add some noise to deal with constant black areas\n",
        "        luminance_batch = luminance[batch].copy()\n",
        "        luminance_batch += np.random.randn(*luminance_batch.shape) * noise\n",
        "        luminance_batch = np.clip(luminance_batch, 0, 100)\n",
        "\n",
        "        motion_energy[batch] = pyramid.project_stimulus(luminance_batch)\n",
        "\n",
        "    # decimate to the sampling frequency of fMRI responses\n",
        "    motion_energy_decimated = decimate(motion_energy, N_FRAMES_PER_TR,\n",
        "                                       ftype='fir', axis=0)\n",
        "    return motion_energy_decimated\n",
        "\n",
        "\n",
        "motion_energy_train = compute_motion_energy(luminance_train)\n",
        "motion_energy_test = compute_motion_energy(luminance_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We end this script with saving the features, to use them in voxelwise\n",
        "modeling in the following example.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from voxelwise_tutorials.io import save_hdf5_dataset\n",
        "\n",
        "features_directory = os.path.join(directory, \"features\")\n",
        "if not os.path.exists(features_directory):\n",
        "    os.makedirs(features_directory)\n",
        "\n",
        "save_hdf5_dataset(\n",
        "    os.path.join(features_directory, \"motion_energy.hdf\"),\n",
        "    dataset=dict(X_train=motion_energy_train, X_test=motion_energy_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## References\n",
        "\n",
        "```{bibliography}\n",
        ":filter: docname in docnames\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
