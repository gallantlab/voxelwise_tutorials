
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Movies tutorial &#8212; Voxelwise modeling tutorials 0.1 documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/alabaster.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-rendered-html.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Download the data set from CRCNS" href="movies/00_download_vim5.html" />
    <link rel="prev" title="Voxelwise modeling tutorials" href="../index.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  <div class="document">
    
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<p class="logo">
  <a href="../index.html">
    <img class="logo" src="../_static/flatmap.png" alt="Logo"/>
    
  </a>
</p>



<p class="blurb">Voxelwise modeling tutorials</p>




<p>
<iframe src="https://ghbtns.com/github-btn.html?user=gallantlab&repo=voxelwise_tutorials&type=star&count=true&size=large&v=2"
  allowtransparency="true" frameborder="0" scrolling="0" width="200px" height="35px"></iframe>
</p>





<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
      <li>Previous: <a href="../index.html" title="previous chapter">Voxelwise modeling tutorials</a></li>
      <li>Next: <a href="movies/00_download_vim5.html" title="next chapter">Download the data set from CRCNS</a></li>
  </ul></li>
</ul>
</div><h3>Navigation</h3>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Movies tutorial</a><ul>
<li class="toctree-l2"><a class="reference internal" href="movies/00_download_vim5.html">Download the data set from CRCNS</a></li>
<li class="toctree-l2"><a class="reference internal" href="movies/00_setup_colab.html">Setup Google Colab</a></li>
<li class="toctree-l2"><a class="reference internal" href="movies/01_plot_explainable_variance.html">Compute the explainable variance</a></li>
<li class="toctree-l2"><a class="reference internal" href="movies/02_plot_wordnet_model.html">Fit a ridge model with wordnet features</a></li>
<li class="toctree-l2"><a class="reference internal" href="movies/03_plot_hemodynamic_response.html">Visualize the hemodynamic response</a></li>
<li class="toctree-l2"><a class="reference internal" href="movies/04_plot_motion_energy_model.html">Fit a ridge model with motion energy features</a></li>
<li class="toctree-l2"><a class="reference internal" href="movies/05_plot_banded_ridge_model.html">Fit a banded ridge model with both wordnet and motion energy features</a></li>
<li class="toctree-l2"><a class="reference internal" href="movies/06_extract_motion_energy.html">Extract motion energy features from the stimuli</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#movies-tutorial-deprecated">Movies tutorial (deprecated)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="movies_deprecated/00_download_vim2.html">Download the data set from CRCNS</a></li>
<li class="toctree-l2"><a class="reference internal" href="movies_deprecated/01_extract_motion_energy.html">Extract motion energy features from the stimuli</a></li>
<li class="toctree-l2"><a class="reference internal" href="movies_deprecated/02_plot_ridge_model.html">Fit a ridge model with motion energy features</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../voxelwise_modeling.html">The voxelwise modeling framework</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../voxelwise_package.html">Helper Python package</a></li>
</ul>


<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <p id="sphx-glr-auto-examples">(If you are looking for some Jupyter notebooks, check the <a class="reference external" href="https://github.com/gallantlab/voxelwise_tutorials/tree/main/tutorials/notebooks">notebooks</a>
directory.)</p>
<div class="sphx-glr-clear"></div><div class="section" id="movies-tutorial">
<span id="sphx-glr-auto-examples-movies"></span><h1>Movies tutorial<a class="headerlink" href="#movies-tutorial" title="Permalink to this headline">¶</a></h1>
<p>This tutorial describes how to perform voxelwise modeling on a visual
imaging experiment.</p>
<p><strong>Data set:</strong>
This tutorial is based on publicly available data
<a class="reference external" href="TBD">published on CRCNS</a> <a class="footnote-reference brackets" href="#id11" id="id1">4</a>.
The data is briefly described in the dataset <a class="reference external" href="TBD">description PDF</a>,
and in more details in the original publication <a class="footnote-reference brackets" href="#id8" id="id2">1</a>.
If you publish work using this data set, please cite the original
publication <a class="footnote-reference brackets" href="#id8" id="id3">1</a>, and the CRCNS data set <a class="footnote-reference brackets" href="#id11" id="id4">4</a>.</p>
<p><strong>Models:</strong>
This tutorial implements different voxelwise encoding models:</p>
<ul class="simple">
<li><p>a ridge model with wordnet semantic features as described in <a class="footnote-reference brackets" href="#id8" id="id5">1</a>.</p></li>
<li><p>a ridge model with motion-energy features as described in <a class="footnote-reference brackets" href="#id9" id="id6">2</a>.</p></li>
<li><p>a banded-ridge model with both feature spaces as described in <a class="footnote-reference brackets" href="#id10" id="id7">3</a>.</p></li>
</ul>
<p><strong>Scikit-learn API:</strong> These tutorials use <a class="reference external" href="https://github.com/scikit-learn/scikit-learn">scikit-learn</a> to define the preprocessing
steps, the modeling pipeline, and the cross-validation scheme. If you are not
familiar with the scikit-learn API, we recommend the <a class="reference external" href="https://scikit-learn.org/stable/getting_started.html">getting started guide</a>. We also use a lot of
the scikit-learn terminology, which is explained in great details in the
<a class="reference external" href="https://scikit-learn.org/stable/glossary.html#glossary">glossary of common terms and API elements</a>.</p>
<p><strong>Running time:</strong> Most of these tutorials can be run in a reasonable time
(under 1 minute for most examples, ~7 minutes for the banded ridge example)
with a GPU backend in <a class="reference external" href="https://github.com/gallantlab/himalaya">himalaya</a>.
Using a CPU backend is slower (typically 10 times slower).</p>
<p><strong>Requirements:</strong>
This tutorial requires the following Python packages:</p>
<ul class="simple">
<li><p>voxelwise_tutorials  (this repository) and its dependencies</p></li>
<li><p>cupy or pytorch  (optional, to use a GPU backend in himalaya)</p></li>
</ul>
<p><strong>References:</strong></p>
<dl class="footnote brackets">
<dt class="label" id="id8"><span class="brackets">1</span><span class="fn-backref">(<a href="#id2">1</a>,<a href="#id3">2</a>,<a href="#id5">3</a>)</span></dt>
<dd><p>Huth, A. G., Nishimoto, S., Vu, A. T., &amp; Gallant, J. L. (2012).
A continuous semantic space describes the representation of thousands of
object and action categories across the human brain. Neuron, 76(6),
1210-1224.</p>
</dd>
<dt class="label" id="id9"><span class="brackets"><a class="fn-backref" href="#id6">2</a></span></dt>
<dd><p>Nishimoto, S., Vu, A. T., Naselaris, T., Benjamini, Y., Yu,
B., &amp; Gallant, J. L. (2011). Reconstructing visual experiences from brain
activity evoked by natural movies. Current Biology, 21(19), 1641-1646.</p>
</dd>
<dt class="label" id="id10"><span class="brackets"><a class="fn-backref" href="#id7">3</a></span></dt>
<dd><p>Nunez-Elizalde, A. O., Huth, A. G., &amp; Gallant, J. L. (2019).
Voxelwise encoding models with non-spherical multivariate normal priors.
Neuroimage, 197, 482-492.</p>
</dd>
<dt class="label" id="id11"><span class="brackets">4</span><span class="fn-backref">(<a href="#id1">1</a>,<a href="#id4">2</a>)</span></dt>
<dd><p>Huth, A. G., Nishimoto, S., Vu, A. T., &amp; Gallant, J. L. (2020):
Gallant Lab Natural Movie 3T fMRI Data. CRCNS.org.
<a class="reference external" href="http://dx.doi.org/10.6080/TBD">http://dx.doi.org/10.6080/TBD</a></p>
</dd>
</dl>
<div class="sphx-glr-thumbcontainer" tooltip="In this script, we download the data set from CRCNS. A (free) account is required."><div class="figure align-default" id="id18">
<img alt="Download the data set from CRCNS" src="../_images/sphx_glr_00_download_vim5_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="movies/00_download_vim5.html#sphx-glr-auto-examples-movies-00-download-vim5-py"><span class="std std-ref">Download the data set from CRCNS</span></a></span><a class="headerlink" href="#id18" title="Permalink to this image">¶</a></p>
</div>
</div><div class="toctree-wrapper compound">
</div>
<div class="sphx-glr-thumbcontainer" tooltip="In this script, we setup a Google Colab environment. This script will only work when run from `..."><div class="figure align-default" id="id19">
<img alt="Setup Google Colab" src="../_images/sphx_glr_00_setup_colab_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="movies/00_setup_colab.html#sphx-glr-auto-examples-movies-00-setup-colab-py"><span class="std std-ref">Setup Google Colab</span></a></span><a class="headerlink" href="#id19" title="Permalink to this image">¶</a></p>
</div>
</div><div class="toctree-wrapper compound">
</div>
<div class="sphx-glr-thumbcontainer" tooltip="Before fitting any voxelwise model to fMRI responses, it is good practice to quantify the amoun..."><div class="figure align-default" id="id20">
<img alt="Compute the explainable variance" src="../_images/sphx_glr_01_plot_explainable_variance_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="movies/01_plot_explainable_variance.html#sphx-glr-auto-examples-movies-01-plot-explainable-variance-py"><span class="std std-ref">Compute the explainable variance</span></a></span><a class="headerlink" href="#id20" title="Permalink to this image">¶</a></p>
</div>
</div><div class="toctree-wrapper compound">
</div>
<div class="sphx-glr-thumbcontainer" tooltip="In this example, we model the fMRI responses with semantic &quot;wordnet&quot; features, manually annotat..."><div class="figure align-default" id="id21">
<img alt="Fit a ridge model with wordnet features" src="../_images/sphx_glr_02_plot_wordnet_model_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="movies/02_plot_wordnet_model.html#sphx-glr-auto-examples-movies-02-plot-wordnet-model-py"><span class="std std-ref">Fit a ridge model with wordnet features</span></a></span><a class="headerlink" href="#id21" title="Permalink to this image">¶</a></p>
</div>
</div><div class="toctree-wrapper compound">
</div>
<div class="sphx-glr-thumbcontainer" tooltip="In this example, we describe how the hemodynamic response function was estimated in the previou..."><div class="figure align-default" id="id22">
<img alt="Visualize the hemodynamic response" src="../_images/sphx_glr_03_plot_hemodynamic_response_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="movies/03_plot_hemodynamic_response.html#sphx-glr-auto-examples-movies-03-plot-hemodynamic-response-py"><span class="std std-ref">Visualize the hemodynamic response</span></a></span><a class="headerlink" href="#id22" title="Permalink to this image">¶</a></p>
</div>
</div><div class="toctree-wrapper compound">
</div>
<div class="sphx-glr-thumbcontainer" tooltip="In this example, we model the fMRI responses with motion-energy features extracted from the mov..."><div class="figure align-default" id="id23">
<img alt="Fit a ridge model with motion energy features" src="../_images/sphx_glr_04_plot_motion_energy_model_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="movies/04_plot_motion_energy_model.html#sphx-glr-auto-examples-movies-04-plot-motion-energy-model-py"><span class="std std-ref">Fit a ridge model with motion energy features</span></a></span><a class="headerlink" href="#id23" title="Permalink to this image">¶</a></p>
</div>
</div><div class="toctree-wrapper compound">
</div>
<div class="sphx-glr-thumbcontainer" tooltip="In this example, we model the fMRI responses with a banded ridge regression, with two different..."><div class="figure align-default" id="id24">
<img alt="Fit a banded ridge model with both wordnet and motion energy features" src="../_images/sphx_glr_05_plot_banded_ridge_model_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="movies/05_plot_banded_ridge_model.html#sphx-glr-auto-examples-movies-05-plot-banded-ridge-model-py"><span class="std std-ref">Fit a banded ridge model with both wordnet and motion energy features</span></a></span><a class="headerlink" href="#id24" title="Permalink to this image">¶</a></p>
</div>
</div><div class="toctree-wrapper compound">
</div>
<div class="sphx-glr-thumbcontainer" tooltip="This script describes how to extract motion-energy features from the stimuli."><div class="figure align-default" id="id25">
<img alt="Extract motion energy features from the stimuli" src="../_images/sphx_glr_06_extract_motion_energy_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="movies/06_extract_motion_energy.html#sphx-glr-auto-examples-movies-06-extract-motion-energy-py"><span class="std std-ref">Extract motion energy features from the stimuli</span></a></span><a class="headerlink" href="#id25" title="Permalink to this image">¶</a></p>
</div>
</div><div class="toctree-wrapper compound">
</div>
<div class="sphx-glr-clear"></div><div class="line-block" id="sphx-glr-auto-examples-movies-deprecated">
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</div>
<div class="section" id="movies-tutorial-deprecated">
<h1>Movies tutorial (deprecated)<a class="headerlink" href="#movies-tutorial-deprecated" title="Permalink to this headline">¶</a></h1>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This tutorial is redundant with the “Movies tutorial”. It uses a
different data set with brain responses limited to the occipital lobe,
and with no mappers to plot the data on flatmaps.
Using the “Movies tutorial” with full brain responses is recommended.</p>
</div>
<p>This tutorial describes how to perform voxelwise modeling on a visual
imaging experiment.</p>
<p><strong>Data set:</strong>
This tutorial is based on publicly available data published on
<a class="reference external" href="https://crcns.org/data-sets/vc/vim-2/about-vim-2">CRCNS</a> <a class="footnote-reference brackets" href="#id17" id="id12">6</a>.
The data is briefly described in the dataset description
<a class="reference external" href="https://crcns.org/files/data/vim-2/crcns-vim-2-data-description.pdf">PDF</a>,
and in more details in the original publication <a class="footnote-reference brackets" href="#id16" id="id13">5</a>.
If you publish work using this data set, please cite the original
publication <a class="footnote-reference brackets" href="#id16" id="id14">5</a>, and the CRCNS data set <a class="footnote-reference brackets" href="#id17" id="id15">6</a>.</p>
<p><strong>Requirements:</strong>
This tutorial requires the following Python packages:</p>
<ul class="simple">
<li><p>voxelwise_tutorials  (this repository) and its dependencies</p></li>
<li><p>cupy or pytorch  (optional, to use a GPU backend in himalaya)</p></li>
</ul>
<p><strong>References:</strong></p>
<dl class="footnote brackets">
<dt class="label" id="id16"><span class="brackets">5</span><span class="fn-backref">(<a href="#id13">1</a>,<a href="#id14">2</a>)</span></dt>
<dd><p>Nishimoto, S., Vu, A. T., Naselaris, T., Benjamini, Y., Yu,
B., &amp; Gallant, J. L. (2011). Reconstructing visual experiences from brain
activity evoked by natural movies. Current Biology, 21(19), 1641-1646.</p>
</dd>
<dt class="label" id="id17"><span class="brackets">6</span><span class="fn-backref">(<a href="#id12">1</a>,<a href="#id15">2</a>)</span></dt>
<dd><p>Nishimoto, S., Vu, A. T., Naselaris, T., Benjamini, Y., Yu,
B., &amp; Gallant, J. L. (2014): Gallant Lab Natural Movie 4T fMRI Data.
CRCNS.org. <a class="reference external" href="http://dx.doi.org/10.6080/K00Z715X">http://dx.doi.org/10.6080/K00Z715X</a></p>
</dd>
</dl>
<div class="sphx-glr-thumbcontainer" tooltip="In this script, we download the data set from CRCNS. A (free) account is required."><div class="figure align-default" id="id26">
<img alt="Download the data set from CRCNS" src="../_images/sphx_glr_00_download_vim2_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="movies_deprecated/00_download_vim2.html#sphx-glr-auto-examples-movies-deprecated-00-download-vim2-py"><span class="std std-ref">Download the data set from CRCNS</span></a></span><a class="headerlink" href="#id26" title="Permalink to this image">¶</a></p>
</div>
</div><div class="toctree-wrapper compound">
</div>
<div class="sphx-glr-thumbcontainer" tooltip="This script describes how to extract motion-energy features from the stimuli."><div class="figure align-default" id="id27">
<img alt="Extract motion energy features from the stimuli" src="../_images/sphx_glr_01_extract_motion_energy_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="movies_deprecated/01_extract_motion_energy.html#sphx-glr-auto-examples-movies-deprecated-01-extract-motion-energy-py"><span class="std std-ref">Extract motion energy features from the stimuli</span></a></span><a class="headerlink" href="#id27" title="Permalink to this image">¶</a></p>
</div>
</div><div class="toctree-wrapper compound">
</div>
<div class="sphx-glr-thumbcontainer" tooltip="In this example, we model the fMRI responses with motion-energy features extracted from the mov..."><div class="figure align-default" id="id28">
<img alt="Fit a ridge model with motion energy features" src="../_images/sphx_glr_02_plot_ridge_model_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="movies_deprecated/02_plot_ridge_model.html#sphx-glr-auto-examples-movies-deprecated-02-plot-ridge-model-py"><span class="std std-ref">Fit a ridge model with motion energy features</span></a></span><a class="headerlink" href="#id28" title="Permalink to this image">¶</a></p>
</div>
</div><div class="toctree-wrapper compound">
</div>
<div class="sphx-glr-clear"></div><div class="sphx-glr-footer class sphx-glr-footer-gallery docutils container">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/8845d11ecb15bc8f327918febd001c4d/_auto_examples_python.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">all</span> <span class="pre">examples</span> <span class="pre">in</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">_auto_examples_python.zip</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/225d151ea821367300a1321f418806af/_auto_examples_jupyter.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">all</span> <span class="pre">examples</span> <span class="pre">in</span> <span class="pre">Jupyter</span> <span class="pre">notebooks:</span> <span class="pre">_auto_examples_jupyter.zip</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>


          </div>
          
        </div>
      </div>
    <div class="clearer"></div>
  </div>
    <div class="footer">
      &copy;2020, Gallant lab.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 4.1.2</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="../_sources/_auto_examples/index.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>