
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Movies tutorial &#8212; Voxelwise modeling tutorials 0.1 documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/alabaster.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-rendered-html.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Download the data set from CRCNS" href="movies/00_download_vim5.html" />
    <link rel="prev" title="Voxelwise modeling tutorials" href="../index.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  <div class="document">
    
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<p class="logo">
  <a href="../index.html">
    <img class="logo" src="../_static/flatmap.png" alt="Logo"/>
    
  </a>
</p>



<p class="blurb">Voxelwise modeling tutorials</p>




<p>
<iframe src="https://ghbtns.com/github-btn.html?user=gallantlab&repo=voxelwise_tutorials&type=star&count=true&size=large&v=2"
  allowtransparency="true" frameborder="0" scrolling="0" width="200px" height="35px"></iframe>
</p>





<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
      <li>Previous: <a href="../index.html" title="previous chapter">Voxelwise modeling tutorials</a></li>
      <li>Next: <a href="movies/00_download_vim5.html" title="next chapter">Download the data set from CRCNS</a></li>
  </ul></li>
</ul>
</div><h3>Navigation</h3>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Movies tutorial</a><ul>
<li class="toctree-l2"><a class="reference internal" href="movies/00_download_vim5.html">Download the data set from CRCNS</a></li>
<li class="toctree-l2"><a class="reference internal" href="movies/00_setup_colab.html">Setup Google Colab</a></li>
<li class="toctree-l2"><a class="reference internal" href="movies/01_plot_explainable_variance.html">Compute the explainable variance</a></li>
<li class="toctree-l2"><a class="reference internal" href="movies/02_plot_wordnet_model.html">Fit a ridge model with wordnet features</a></li>
<li class="toctree-l2"><a class="reference internal" href="movies/03_plot_hemodynamic_response.html">Visualize the hemodynamic response</a></li>
<li class="toctree-l2"><a class="reference internal" href="movies/04_plot_motion_energy_model.html">Fit a ridge model with motion energy features</a></li>
<li class="toctree-l2"><a class="reference internal" href="movies/05_plot_banded_ridge_model.html">Fit a banded ridge model with both wordnet and motion energy features</a></li>
<li class="toctree-l2"><a class="reference internal" href="movies/06_extract_motion_energy.html">Extract motion energy features from the stimuli</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="#movies-tutorial-deprecated">Movies tutorial (deprecated)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="movies_deprecated/00_download_vim2.html">Download the data set from CRCNS</a></li>
<li class="toctree-l2"><a class="reference internal" href="movies_deprecated/01_extract_motion_energy.html">Extract motion energy features from the stimuli</a></li>
<li class="toctree-l2"><a class="reference internal" href="movies_deprecated/02_plot_ridge_model.html">Fit a ridge model with motion energy features</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../voxelwise_modeling.html">The voxelwise modeling framework</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../voxelwise_package.html">Helper Python package</a></li>
</ul>


<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <p id="sphx-glr-auto-examples">(If you are looking for some Jupyter notebooks, check the <a class="reference external" href="https://github.com/gallantlab/voxelwise_tutorials/tree/main/tutorials/notebooks">notebooks</a>
directory.)</p>
<div class="sphx-glr-clear"></div><div class="section" id="movies-tutorial">
<span id="sphx-glr-auto-examples-movies"></span><h1>Movies tutorial<a class="headerlink" href="#movies-tutorial" title="Permalink to this headline">Â¶</a></h1>
<p>This tutorial describes how to perform voxelwise modeling on a visual
imaging experiment.</p>
<p><strong>Data set:</strong>
This tutorial is based on publicly available data
<a class="reference external" href="TBD">published on CRCNS</a> <a class="footnote-reference brackets" href="#id11" id="id1">4</a>.
The data is briefly described in the dataset <a class="reference external" href="TBD">description PDF</a>,
and in more details in the original publication <a class="footnote-reference brackets" href="#id8" id="id2">1</a>.
If you publish work using this data set, please cite the original
publication <a class="footnote-reference brackets" href="#id8" id="id3">1</a>, and the CRCNS data set <a class="footnote-reference brackets" href="#id11" id="id4">4</a>.</p>
<p><strong>Models:</strong>
This tutorial implements different voxelwise encoding models:</p>
<ul class="simple">
<li><p>a ridge model with wordnet semantic features as described in <a class="footnote-reference brackets" href="#id8" id="id5">1</a>.</p></li>
<li><p>a ridge model with motion-energy features as described in <a class="footnote-reference brackets" href="#id9" id="id6">2</a>.</p></li>
<li><p>a banded-ridge model with both feature spaces as described in <a class="footnote-reference brackets" href="#id10" id="id7">3</a>.</p></li>
</ul>
<p><strong>Scikit-learn API:</strong> These tutorials use <a class="reference external" href="https://github.com/scikit-learn/scikit-learn">scikit-learn</a> to define the preprocessing
steps, the modeling pipeline, and the cross-validation scheme. If you are not
familiar with the scikit-learn API, we recommend the <a class="reference external" href="https://scikit-learn.org/stable/getting_started.html">getting started guide</a>. We also use a lot of
the scikit-learn terminology, which is explained in great details in the
<a class="reference external" href="https://scikit-learn.org/stable/glossary.html#glossary">glossary of common terms and API elements</a>.</p>
<p><strong>Running time:</strong> Most of these tutorials can be run in a reasonable time
(under 1 minute for most examples, ~7 minutes for the banded ridge example)
with a GPU backend in <a class="reference external" href="https://github.com/gallantlab/himalaya">himalaya</a>.
Using a CPU backend is slower (typically 10 times slower).</p>
<p><strong>Requirements:</strong>
This tutorial requires the following Python packages:</p>
<ul class="simple">
<li><p>voxelwise_tutorials  (this repository) and its dependencies</p></li>
<li><p>cupy or pytorch  (optional, to use a GPU backend in himalaya)</p></li>
</ul>
<p><strong>References:</strong></p>
<dl class="footnote brackets">
<dt class="label" id="id8"><span class="brackets">1</span><span class="fn-backref">(<a href="#id2">1</a>,<a href="#id3">2</a>,<a href="#id5">3</a>)</span></dt>
<dd><p>Huth, A. G., Nishimoto, S., Vu, A. T., &amp; Gallant, J. L. (2012).
A continuous semantic space describes the representation of thousands of
object and action categories across the human brain. Neuron, 76(6),
1210-1224.</p>
</dd>
<dt class="label" id="id9"><span class="brackets"><a class="fn-backref" href="#id6">2</a></span></dt>
<dd><p>Nishimoto, S., Vu, A. T., Naselaris, T., Benjamini, Y., Yu,
B., &amp; Gallant, J. L. (2011). Reconstructing visual experiences from brain
activity evoked by natural movies. Current Biology, 21(19), 1641-1646.</p>
</dd>
<dt class="label" id="id10"><span class="brackets"><a class="fn-backref" href="#id7">3</a></span></dt>
<dd><p>Nunez-Elizalde, A. O., Huth, A. G., &amp; Gallant, J. L. (2019).
Voxelwise encoding models with non-spherical multivariate normal priors.
Neuroimage, 197, 482-492.</p>
</dd>
<dt class="label" id="id11"><span class="brackets">4</span><span class="fn-backref">(<a href="#id1">1</a>,<a href="#id4">2</a>)</span></dt>
<dd><p>Huth, A. G., Nishimoto, S., Vu, A. T., &amp; Gallant, J. L. (2020):
Gallant Lab Natural Movie 3T fMRI Data. CRCNS.org.
<a class="reference external" href="http://dx.doi.org/10.6080/TBD">http://dx.doi.org/10.6080/TBD</a></p>
</dd>
</dl>
<div class="sphx-glr-thumbcontainer" tooltip="In this script, we download the data set from CRCNS. A (free) account is required."><div class="figure align-default" id="id18">
<img alt="Download the data set from CRCNS" src="../_images/sphx_glr_00_download_vim5_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="movies/00_download_vim5.html#sphx-glr-auto-examples-movies-00-download-vim5-py"><span class="std std-ref">Download the data set from CRCNS</span></a></span><a class="headerlink" href="#id18" title="Permalink to this image">Â¶</a></p>
</div>
</div><div class="toctree-wrapper compound">
</div>
<div class="sphx-glr-thumbcontainer" tooltip="In this script, we setup a Google Colab environment. This script will only work when run from `..."><div class="figure align-default" id="id19">
<img alt="Setup Google Colab" src="../_images/sphx_glr_00_setup_colab_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="movies/00_setup_colab.html#sphx-glr-auto-examples-movies-00-setup-colab-py"><span class="std std-ref">Setup Google Colab</span></a></span><a class="headerlink" href="#id19" title="Permalink to this image">Â¶</a></p>
</div>
</div><div class="toctree-wrapper compound">
</div>
<div class="sphx-glr-thumbcontainer" tooltip="Before fitting any voxelwise model to fMRI responses, it is good practice to quantify the amoun..."><div class="figure align-default" id="id20">
<img alt="Compute the explainable variance" src="../_images/sphx_glr_01_plot_explainable_variance_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="movies/01_plot_explainable_variance.html#sphx-glr-auto-examples-movies-01-plot-explainable-variance-py"><span class="std std-ref">Compute the explainable variance</span></a></span><a class="headerlink" href="#id20" title="Permalink to this image">Â¶</a></p>
</div>
</div><div class="toctree-wrapper compound">
</div>
<div class="sphx-glr-thumbcontainer" tooltip="In this example, we model the fMRI responses with semantic &quot;wordnet&quot; features, manually annotat..."><div class="figure align-default" id="id21">
<img alt="Fit a ridge model with wordnet features" src="../_images/sphx_glr_02_plot_wordnet_model_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="movies/02_plot_wordnet_model.html#sphx-glr-auto-examples-movies-02-plot-wordnet-model-py"><span class="std std-ref">Fit a ridge model with wordnet features</span></a></span><a class="headerlink" href="#id21" title="Permalink to this image">Â¶</a></p>
</div>
</div><div class="toctree-wrapper compound">
</div>
<div class="sphx-glr-thumbcontainer" tooltip="In this example, we describe how the hemodynamic response function was estimated in the previou..."><div class="figure align-default" id="id22">
<img alt="Visualize the hemodynamic response" src="../_images/sphx_glr_03_plot_hemodynamic_response_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="movies/03_plot_hemodynamic_response.html#sphx-glr-auto-examples-movies-03-plot-hemodynamic-response-py"><span class="std std-ref">Visualize the hemodynamic response</span></a></span><a class="headerlink" href="#id22" title="Permalink to this image">Â¶</a></p>
</div>
</div><div class="toctree-wrapper compound">
</div>
<div class="sphx-glr-thumbcontainer" tooltip="In this example, we model the fMRI responses with motion-energy features extracted from the mov..."><div class="figure align-default" id="id23">
<img alt="Fit a ridge model with motion energy features" src="../_images/sphx_glr_04_plot_motion_energy_model_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="movies/04_plot_motion_energy_model.html#sphx-glr-auto-examples-movies-04-plot-motion-energy-model-py"><span class="std std-ref">Fit a ridge model with motion energy features</span></a></span><a class="headerlink" href="#id23" title="Permalink to this image">Â¶</a></p>
</div>
</div><div class="toctree-wrapper compound">
</div>
<div class="sphx-glr-thumbcontainer" tooltip="In this example, we model the fMRI responses with a banded ridge regression, with two different..."><div class="figure align-default" id="id24">
<img alt="Fit a banded ridge model with both wordnet and motion energy features" src="../_images/sphx_glr_05_plot_banded_ridge_model_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="movies/05_plot_banded_ridge_model.html#sphx-glr-auto-examples-movies-05-plot-banded-ridge-model-py"><span class="std std-ref">Fit a banded ridge model with both wordnet and motion energy features</span></a></span><a class="headerlink" href="#id24" title="Permalink to this image">Â¶</a></p>
</div>
</div><div class="toctree-wrapper compound">
</div>
<div class="sphx-glr-thumbcontainer" tooltip="This script describes how to extract motion-energy features from the stimuli."><div class="figure align-default" id="id25">
<img alt="Extract motion energy features from the stimuli" src="../_images/sphx_glr_06_extract_motion_energy_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="movies/06_extract_motion_energy.html#sphx-glr-auto-examples-movies-06-extract-motion-energy-py"><span class="std std-ref">Extract motion energy features from the stimuli</span></a></span><a class="headerlink" href="#id25" title="Permalink to this image">Â¶</a></p>
</div>
</div><div class="toctree-wrapper compound">
</div>
<div class="sphx-glr-clear"></div><div class="line-block" id="sphx-glr-auto-examples-movies-deprecated">
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</div>
<div class="section" id="movies-tutorial-deprecated">
<h1>Movies tutorial (deprecated)<a class="headerlink" href="#movies-tutorial-deprecated" title="Permalink to this headline">Â¶</a></h1>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This tutorial is redundant with the âMovies tutorialâ. It uses a
different data set with brain responses limited to the occipital lobe,
and with no mappers to plot the data on flatmaps.
Using the âMovies tutorialâ with full brain responses is recommended.</p>
</div>
<p>This tutorial describes how to perform voxelwise modeling on a visual
imaging experiment.</p>
<p><strong>Data set:</strong>
This tutorial is based on publicly available data published on
<a class="reference external" href="https://crcns.org/data-sets/vc/vim-2/about-vim-2">CRCNS</a> <a class="footnote-reference brackets" href="#id17" id="id12">6</a>.
The data is briefly described in the dataset description
<a class="reference external" href="https://crcns.org/files/data/vim-2/crcns-vim-2-data-description.pdf">PDF</a>,
and in more details in the original publication <a class="footnote-reference brackets" href="#id16" id="id13">5</a>.
If you publish work using this data set, please cite the original
publication <a class="footnote-reference brackets" href="#id16" id="id14">5</a>, and the CRCNS data set <a class="footnote-reference brackets" href="#id17" id="id15">6</a>.</p>
<p><strong>Requirements:</strong>
This tutorial requires the following Python packages:</p>
<ul class="simple">
<li><p>voxelwise_tutorials  (this repository) and its dependencies</p></li>
<li><p>cupy or pytorch  (optional, to use a GPU backend in himalaya)</p></li>
</ul>
<p><strong>References:</strong></p>
<dl class="footnote brackets">
<dt class="label" id="id16"><span class="brackets">5</span><span class="fn-backref">(<a href="#id13">1</a>,<a href="#id14">2</a>)</span></dt>
<dd><p>Nishimoto, S., Vu, A. T., Naselaris, T., Benjamini, Y., Yu,
B., &amp; Gallant, J. L. (2011). Reconstructing visual experiences from brain
activity evoked by natural movies. Current Biology, 21(19), 1641-1646.</p>
</dd>
<dt class="label" id="id17"><span class="brackets">6</span><span class="fn-backref">(<a href="#id12">1</a>,<a href="#id15">2</a>)</span></dt>
<dd><p>Nishimoto, S., Vu, A. T., Naselaris, T., Benjamini, Y., Yu,
B., &amp; Gallant, J. L. (2014): Gallant Lab Natural Movie 4T fMRI Data.
CRCNS.org. <a class="reference external" href="http://dx.doi.org/10.6080/K00Z715X">http://dx.doi.org/10.6080/K00Z715X</a></p>
</dd>
</dl>
<div class="sphx-glr-thumbcontainer" tooltip="In this script, we download the data set from CRCNS. A (free) account is required."><div class="figure align-default" id="id26">
<img alt="Download the data set from CRCNS" src="../_images/sphx_glr_00_download_vim2_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="movies_deprecated/00_download_vim2.html#sphx-glr-auto-examples-movies-deprecated-00-download-vim2-py"><span class="std std-ref">Download the data set from CRCNS</span></a></span><a class="headerlink" href="#id26" title="Permalink to this image">Â¶</a></p>
</div>
</div><div class="toctree-wrapper compound">
</div>
<div class="sphx-glr-thumbcontainer" tooltip="This script describes how to extract motion-energy features from the stimuli."><div class="figure align-default" id="id27">
<img alt="Extract motion energy features from the stimuli" src="../_images/sphx_glr_01_extract_motion_energy_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="movies_deprecated/01_extract_motion_energy.html#sphx-glr-auto-examples-movies-deprecated-01-extract-motion-energy-py"><span class="std std-ref">Extract motion energy features from the stimuli</span></a></span><a class="headerlink" href="#id27" title="Permalink to this image">Â¶</a></p>
</div>
</div><div class="toctree-wrapper compound">
</div>
<div class="sphx-glr-thumbcontainer" tooltip="In this example, we model the fMRI responses with motion-energy features extracted from the mov..."><div class="figure align-default" id="id28">
<img alt="Fit a ridge model with motion energy features" src="../_images/sphx_glr_02_plot_ridge_model_thumb.png" />
<p class="caption"><span class="caption-text"><a class="reference internal" href="movies_deprecated/02_plot_ridge_model.html#sphx-glr-auto-examples-movies-deprecated-02-plot-ridge-model-py"><span class="std std-ref">Fit a ridge model with motion energy features</span></a></span><a class="headerlink" href="#id28" title="Permalink to this image">Â¶</a></p>
</div>
</div><div class="toctree-wrapper compound">
</div>
<div class="sphx-glr-clear"></div><div class="sphx-glr-footer class sphx-glr-footer-gallery docutils container">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/8845d11ecb15bc8f327918febd001c4d/_auto_examples_python.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">all</span> <span class="pre">examples</span> <span class="pre">in</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">_auto_examples_python.zip</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/225d151ea821367300a1321f418806af/_auto_examples_jupyter.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">all</span> <span class="pre">examples</span> <span class="pre">in</span> <span class="pre">Jupyter</span> <span class="pre">notebooks:</span> <span class="pre">_auto_examples_jupyter.zip</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>


          </div>
          
        </div>
      </div>
    <div class="clearer"></div>
  </div>
    <div class="footer">
      &copy;2020, Gallant lab.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 4.1.2</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="../_sources/_auto_examples/index.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>