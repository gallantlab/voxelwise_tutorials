
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Fit a ridge model with motion energy features &#8212; Voxelwise modeling tutorials 0.1 documentation</title>
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/alabaster.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/gallery-rendered-html.css" />
    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Fit a banded ridge model with both wordnet and motion energy features" href="05_plot_banded_ridge_model.html" />
    <link rel="prev" title="Visualize the hemodynamic response" href="03_plot_hemodynamic_response.html" />
   
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  <div class="document">
    
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<p class="logo">
  <a href="../../index.html">
    <img class="logo" src="../../_static/flatmap.png" alt="Logo"/>
    
  </a>
</p>



<p class="blurb">Voxelwise modeling tutorials</p>




<p>
<iframe src="https://ghbtns.com/github-btn.html?user=gallantlab&repo=voxelwise_tutorials&type=star&count=true&size=large&v=2"
  allowtransparency="true" frameborder="0" scrolling="0" width="200px" height="35px"></iframe>
</p>





<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../index.html">Documentation overview</a><ul>
  <li><a href="../index.html">Movies 3T tutorial</a><ul>
      <li>Previous: <a href="03_plot_hemodynamic_response.html" title="previous chapter">Visualize the hemodynamic response</a></li>
      <li>Next: <a href="05_plot_banded_ridge_model.html" title="next chapter">Fit a banded ridge model with both wordnet and motion energy features</a></li>
  </ul></li>
  </ul></li>
</ul>
</div><h3>Navigation</h3>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">Movies 3T tutorial</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="00_download_vim5.html">Download the data set from CRCNS</a></li>
<li class="toctree-l2"><a class="reference internal" href="00_setup_colab.html">Setup Google Colab</a></li>
<li class="toctree-l2"><a class="reference internal" href="01_plot_explainable_variance.html">Compute the explainable variance</a></li>
<li class="toctree-l2"><a class="reference internal" href="02_plot_wordnet_model.html">Fit a ridge model with wordnet features</a></li>
<li class="toctree-l2"><a class="reference internal" href="03_plot_hemodynamic_response.html">Visualize the hemodynamic response</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Fit a ridge model with motion energy features</a></li>
<li class="toctree-l2"><a class="reference internal" href="05_plot_banded_ridge_model.html">Fit a banded ridge model with both wordnet and motion energy features</a></li>
<li class="toctree-l2"><a class="reference internal" href="06_extract_motion_energy.html">Extract motion energy features from the stimuli</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../index.html#movies-4t-tutorial">Movies 4T tutorial</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../voxelwise_modeling.html">The voxelwise modeling framework</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../voxelwise_package.html">Helper Python package</a></li>
</ul>


<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-auto-examples-movies-3t-04-plot-motion-energy-model-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<section class="sphx-glr-example-title" id="fit-a-ridge-model-with-motion-energy-features">
<span id="sphx-glr-auto-examples-movies-3t-04-plot-motion-energy-model-py"></span><h1>Fit a ridge model with motion energy features<a class="headerlink" href="#fit-a-ridge-model-with-motion-energy-features" title="Permalink to this headline">¶</a></h1>
<p>In this example, we model the fMRI responses with motion-energy features
extracted from the movie stimulus. The model is a regularized linear regression
model.</p>
<p>This tutorial reproduces part of the analysis described in Nishimoto et al
(2011) <a class="footnote-reference brackets" href="#id5" id="id1">1</a>. See this publication for more details about the experiment, the
motion-energy features, along with more results and more discussions.</p>
<p><em>Motion-energy features:</em> Motion-energy features result from filtering a video
stimulus with spatio-temporal Gabor filters. A pyramid of filters is used to
compute the motion-energy features at multiple spatial and temporal scales.
Motion-energy features were introduced in <a class="footnote-reference brackets" href="#id5" id="id2">1</a>.</p>
<p><em>Summary:</em> As in the previous example, we first concatenate the features with
multiple delays, to account for the slow hemodynamic response. A linear
regression model then weights each delayed feature with a different weight, to
build a predictive model of BOLD activity. Again, the linear regression is
regularized to improve robustness to correlated features and to improve
generalization. The optimal regularization hyperparameter is selected
independently on each voxel over a grid-search with cross-validation. Finally,
the model generalization performance is evaluated on a held-out test set,
comparing the model predictions with the ground-truth fMRI responses.</p>
<section id="path-of-the-data-directory">
<h2>Path of the data directory<a class="headerlink" href="#path-of-the-data-directory" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">voxelwise_tutorials.io</span> <span class="kn">import</span> <span class="n">get_data_home</span>
<span class="n">directory</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">get_data_home</span><span class="p">(),</span> <span class="s2">&quot;vim-5&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">directory</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>/home/jlg/mvdoc/voxelwise_tutorials_data/vim-5
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># modify to use another subject</span>
<span class="n">subject</span> <span class="o">=</span> <span class="s2">&quot;S01&quot;</span>
</pre></div>
</div>
</section>
<section id="load-the-data">
<h2>Load the data<a class="headerlink" href="#load-the-data" title="Permalink to this headline">¶</a></h2>
<p>We first load the fMRI responses.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">voxelwise_tutorials.io</span> <span class="kn">import</span> <span class="n">load_hdf5_array</span>

<span class="n">file_name</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">directory</span><span class="p">,</span> <span class="s2">&quot;responses&quot;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">subject</span><span class="si">}</span><span class="s2">_responses.hdf&quot;</span><span class="p">)</span>
<span class="n">Y_train</span> <span class="o">=</span> <span class="n">load_hdf5_array</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="s2">&quot;Y_train&quot;</span><span class="p">)</span>
<span class="n">Y_test</span> <span class="o">=</span> <span class="n">load_hdf5_array</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="s2">&quot;Y_test&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;(n_samples_train, n_voxels) =&quot;</span><span class="p">,</span> <span class="n">Y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;(n_repeats, n_samples_test, n_voxels) =&quot;</span><span class="p">,</span> <span class="n">Y_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>(n_samples_train, n_voxels) = (3600, 84038)
(n_repeats, n_samples_test, n_voxels) = (10, 270, 84038)
</pre></div>
</div>
<p>We average the test repeats, to remove the non-repeatable part of fMRI
responses.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Y_test</span> <span class="o">=</span> <span class="n">Y_test</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;(n_samples_test, n_voxels) =&quot;</span><span class="p">,</span> <span class="n">Y_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>(n_samples_test, n_voxels) = (270, 84038)
</pre></div>
</div>
<p>We fill potential NaN (not-a-number) values with zeros.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Y_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan_to_num</span><span class="p">(</span><span class="n">Y_train</span><span class="p">)</span>
<span class="n">Y_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan_to_num</span><span class="p">(</span><span class="n">Y_test</span><span class="p">)</span>
</pre></div>
</div>
<p>Then we load the precomputed “motion-energy” features.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">feature_space</span> <span class="o">=</span> <span class="s2">&quot;motion_energy&quot;</span>
<span class="n">file_name</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">directory</span><span class="p">,</span> <span class="s2">&quot;features&quot;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">feature_space</span><span class="si">}</span><span class="s2">.hdf&quot;</span><span class="p">)</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">load_hdf5_array</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="s2">&quot;X_train&quot;</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">load_hdf5_array</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="s2">&quot;X_test&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;(n_samples_train, n_features) =&quot;</span><span class="p">,</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;(n_samples_test, n_features) =&quot;</span><span class="p">,</span> <span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>(n_samples_train, n_features) = (3600, 6555)
(n_samples_test, n_features) = (270, 6555)
</pre></div>
</div>
</section>
<section id="define-the-cross-validation-scheme">
<h2>Define the cross-validation scheme<a class="headerlink" href="#define-the-cross-validation-scheme" title="Permalink to this headline">¶</a></h2>
<p>We define the same leave-one-run-out cross-validation split as in the
previous example.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">check_cv</span>
<span class="kn">from</span> <span class="nn">voxelwise_tutorials.utils</span> <span class="kn">import</span> <span class="n">generate_leave_one_run_out</span>

<span class="c1"># indice of first sample of each run</span>
<span class="n">run_onsets</span> <span class="o">=</span> <span class="n">load_hdf5_array</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="s2">&quot;run_onsets&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">run_onsets</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>[   0  300  600  900 1200 1500 1800 2100 2400 2700 3000 3300]
</pre></div>
</div>
<p>We define a cross-validation splitter, compatible with <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> API.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">n_samples_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">cv</span> <span class="o">=</span> <span class="n">generate_leave_one_run_out</span><span class="p">(</span><span class="n">n_samples_train</span><span class="p">,</span> <span class="n">run_onsets</span><span class="p">)</span>
<span class="n">cv</span> <span class="o">=</span> <span class="n">check_cv</span><span class="p">(</span><span class="n">cv</span><span class="p">)</span>  <span class="c1"># copy the cross-validation splitter into a reusable list</span>
</pre></div>
</div>
</section>
<section id="define-the-model">
<h2>Define the model<a class="headerlink" href="#define-the-model" title="Permalink to this headline">¶</a></h2>
<p>We define the same model as in the previous example. See the previous
example for more details about the model definition.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">voxelwise_tutorials.delayer</span> <span class="kn">import</span> <span class="n">Delayer</span>
<span class="kn">from</span> <span class="nn">himalaya.kernel_ridge</span> <span class="kn">import</span> <span class="n">KernelRidgeCV</span>
<span class="kn">from</span> <span class="nn">himalaya.backend</span> <span class="kn">import</span> <span class="n">set_backend</span>
<span class="n">backend</span> <span class="o">=</span> <span class="n">set_backend</span><span class="p">(</span><span class="s2">&quot;torch_cuda&quot;</span><span class="p">,</span> <span class="n">on_error</span><span class="o">=</span><span class="s2">&quot;warn&quot;</span><span class="p">)</span>

<span class="n">X_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>

<span class="n">alphas</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
    <span class="n">StandardScaler</span><span class="p">(</span><span class="n">with_mean</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">with_std</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
    <span class="n">Delayer</span><span class="p">(</span><span class="n">delays</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]),</span>
    <span class="n">KernelRidgeCV</span><span class="p">(</span>
        <span class="n">alphas</span><span class="o">=</span><span class="n">alphas</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span>
        <span class="n">solver_params</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">n_targets_batch</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">n_alphas_batch</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                           <span class="n">n_targets_batch_refit</span><span class="o">=</span><span class="mi">100</span><span class="p">)),</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">set_config</span>
<span class="n">set_config</span><span class="p">(</span><span class="n">display</span><span class="o">=</span><span class="s1">&#39;diagram&#39;</span><span class="p">)</span>  <span class="c1"># requires scikit-learn 0.23</span>
<span class="n">pipeline</span>
</pre></div>
</div>
<div class="output_subarea output_html rendered_html output_result">
<style>#sk-63ef0ffe-d165-4b79-ac4d-ab4d6893cb61 {color: black;background-color: white;}#sk-63ef0ffe-d165-4b79-ac4d-ab4d6893cb61 pre{padding: 0;}#sk-63ef0ffe-d165-4b79-ac4d-ab4d6893cb61 div.sk-toggleable {background-color: white;}#sk-63ef0ffe-d165-4b79-ac4d-ab4d6893cb61 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.2em 0.3em;box-sizing: border-box;text-align: center;}#sk-63ef0ffe-d165-4b79-ac4d-ab4d6893cb61 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-63ef0ffe-d165-4b79-ac4d-ab4d6893cb61 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-63ef0ffe-d165-4b79-ac4d-ab4d6893cb61 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-63ef0ffe-d165-4b79-ac4d-ab4d6893cb61 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-63ef0ffe-d165-4b79-ac4d-ab4d6893cb61 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-63ef0ffe-d165-4b79-ac4d-ab4d6893cb61 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-63ef0ffe-d165-4b79-ac4d-ab4d6893cb61 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;margin: 0.25em 0.25em;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;}#sk-63ef0ffe-d165-4b79-ac4d-ab4d6893cb61 div.sk-estimator:hover {background-color: #d4ebff;}#sk-63ef0ffe-d165-4b79-ac4d-ab4d6893cb61 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-63ef0ffe-d165-4b79-ac4d-ab4d6893cb61 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-63ef0ffe-d165-4b79-ac4d-ab4d6893cb61 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-63ef0ffe-d165-4b79-ac4d-ab4d6893cb61 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;}#sk-63ef0ffe-d165-4b79-ac4d-ab4d6893cb61 div.sk-item {z-index: 1;}#sk-63ef0ffe-d165-4b79-ac4d-ab4d6893cb61 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-63ef0ffe-d165-4b79-ac4d-ab4d6893cb61 div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-63ef0ffe-d165-4b79-ac4d-ab4d6893cb61 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-63ef0ffe-d165-4b79-ac4d-ab4d6893cb61 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-63ef0ffe-d165-4b79-ac4d-ab4d6893cb61 div.sk-parallel-item:only-child::after {width: 0;}#sk-63ef0ffe-d165-4b79-ac4d-ab4d6893cb61 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0.2em;box-sizing: border-box;padding-bottom: 0.1em;background-color: white;position: relative;}#sk-63ef0ffe-d165-4b79-ac4d-ab4d6893cb61 div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-63ef0ffe-d165-4b79-ac4d-ab4d6893cb61 div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-63ef0ffe-d165-4b79-ac4d-ab4d6893cb61 div.sk-container {display: inline-block;position: relative;}</style><div id="sk-63ef0ffe-d165-4b79-ac4d-ab4d6893cb61" class"sk-top-container"><div class="sk-container"><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="acda4ea8-2ee9-4b37-be96-184b98b151f4" type="checkbox" ><label class="sk-toggleable__label" for="acda4ea8-2ee9-4b37-be96-184b98b151f4">Pipeline</label><div class="sk-toggleable__content"><pre>Pipeline(steps=[('standardscaler', StandardScaler(with_std=False)),
                ('delayer', Delayer(delays=[1, 2, 3, 4])),
                ('kernelridgecv',
                 KernelRidgeCV(alphas=array([1.e+01, 1.e+02, 1.e+03, 1.e+04, 1.e+05, 1.e+06, 1.e+07, 1.e+08,
       1.e+09, 1.e+10, 1.e+11, 1.e+12, 1.e+13, 1.e+14, 1.e+15, 1.e+16,
       1.e+17, 1.e+18, 1.e+19, 1.e+20]),
                               cv=_CVIterableWrapper(cv=[(array([   0,    1, ..., 3298, 3299]), array...599])), (array([   0,    1, ..., 3598, 3599]), array([1800, 1801, ..., 2098, 2099])), (array([   0,    1, ..., 3598, 3599]), array([ 900,  901, ..., 1198, 1199])), (array([   0,    1, ..., 3598, 3599]), array([600, 601, ..., 8... 1201, ..., 1498, 1499])), (array([   0,    1, ..., 3598, 3599]), array([300, 301, ..., 598, 599]))]),
                               solver_params={'n_alphas_batch': 5,
                                              'n_targets_batch': 500,
                                              'n_targets_batch_refit': 100}))])</pre></div></div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="1f723440-2c83-4752-af2c-8a0d36977466" type="checkbox" ><label class="sk-toggleable__label" for="1f723440-2c83-4752-af2c-8a0d36977466">StandardScaler</label><div class="sk-toggleable__content"><pre>StandardScaler(with_std=False)</pre></div></div></div><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="d276522a-0686-4bab-83af-c7d1ee0158d3" type="checkbox" ><label class="sk-toggleable__label" for="d276522a-0686-4bab-83af-c7d1ee0158d3">Delayer</label><div class="sk-toggleable__content"><pre>Delayer(delays=[1, 2, 3, 4])</pre></div></div></div><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="3d4adad0-445b-4145-8fa2-8c93d2ed9cbc" type="checkbox" ><label class="sk-toggleable__label" for="3d4adad0-445b-4145-8fa2-8c93d2ed9cbc">KernelRidgeCV</label><div class="sk-toggleable__content"><pre>KernelRidgeCV(alphas=array([1.e+01, 1.e+02, 1.e+03, 1.e+04, 1.e+05, 1.e+06, 1.e+07, 1.e+08,
       1.e+09, 1.e+10, 1.e+11, 1.e+12, 1.e+13, 1.e+14, 1.e+15, 1.e+16,
       1.e+17, 1.e+18, 1.e+19, 1.e+20]),
              cv=_CVIterableWrapper(cv=[(array([   0,    1, ..., 3298, 3299]), array([3300, 3301, ..., 3598, 3599])), (array([   0,    1, ..., 3598, 3599]), array([1800, 1801, ..., 2098, 2099])), (array([   0,    1, ..., 3598, 3599]), array([ 900,  901, ..., 1198, 1199])), (array([   0,    1, ..., 3598, 3599]), array([600, 601, ..., 8... 1201, ..., 1498, 1499])), (array([   0,    1, ..., 3598, 3599]), array([300, 301, ..., 598, 599]))]),
              solver_params={'n_alphas_batch': 5, 'n_targets_batch': 500,
                             'n_targets_batch_refit': 100})</pre></div></div></div></div></div></div></div>
</div>
<br />
<br /></section>
<section id="fit-the-model">
<h2>Fit the model<a class="headerlink" href="#fit-the-model" title="Permalink to this headline">¶</a></h2>
<p>We fit on the train set, and score on the test set.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>

<span class="n">scores_motion_energy</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">)</span>
<span class="n">scores_motion_energy</span> <span class="o">=</span> <span class="n">backend</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">scores_motion_energy</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;(n_voxels,) =&quot;</span><span class="p">,</span> <span class="n">scores_motion_energy</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>(n_voxels,) = (84038,)
</pre></div>
</div>
</section>
<section id="plot-the-model-performances">
<h2>Plot the model performances<a class="headerlink" href="#plot-the-model-performances" title="Permalink to this headline">¶</a></h2>
<p>The performances are computed using the <span class="math notranslate nohighlight">\(R^2\)</span> scores.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">voxelwise_tutorials.viz</span> <span class="kn">import</span> <span class="n">plot_flatmap_from_mapper</span>

<span class="n">mapper_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">directory</span><span class="p">,</span> <span class="s2">&quot;mappers&quot;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">subject</span><span class="si">}</span><span class="s2">_mappers.hdf&quot;</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">plot_flatmap_from_mapper</span><span class="p">(</span><span class="n">scores_motion_energy</span><span class="p">,</span> <span class="n">mapper_file</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                              <span class="n">vmax</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<img alt="04 plot motion energy model" class="sphx-glr-single-img" src="../../_images/sphx_glr_04_plot_motion_energy_model_001.png" />
<p>The motion-energy features lead to large generalization scores in the
early visual cortex (V1, V2, V3, …). For more discussions about these
results, we refer the reader to the original publication <a class="footnote-reference brackets" href="#id5" id="id3">1</a>.</p>
</section>
<section id="compare-with-the-wordnet-model">
<h2>Compare with the wordnet model<a class="headerlink" href="#compare-with-the-wordnet-model" title="Permalink to this headline">¶</a></h2>
<p>Interestingly, the motion-energy model performs well in different brain
regions than the semantic “wordnet” model fitted in the previous example. To
compare the two models, we first need to fit again the wordnet model.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">feature_space</span> <span class="o">=</span> <span class="s2">&quot;wordnet&quot;</span>
<span class="n">file_name</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">directory</span><span class="p">,</span> <span class="s2">&quot;features&quot;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">feature_space</span><span class="si">}</span><span class="s2">.hdf&quot;</span><span class="p">)</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">load_hdf5_array</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="s2">&quot;X_train&quot;</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">load_hdf5_array</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="s2">&quot;X_test&quot;</span><span class="p">)</span>

<span class="n">X_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>We can create an unfitted copy of the pipeline with the <code class="docutils literal notranslate"><span class="pre">clone</span></code> function,
or simply call fit again if we do not need to reuse the previous model.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="kc">False</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <span class="n">clone</span>
    <span class="n">pipeline_wordnet</span> <span class="o">=</span> <span class="n">clone</span><span class="p">(</span><span class="n">pipeline</span><span class="p">)</span>
    <span class="n">pipeline_wordnet</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>
<span class="n">scores_wordnet</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">)</span>
<span class="n">scores_wordnet</span> <span class="o">=</span> <span class="n">backend</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">scores_wordnet</span><span class="p">)</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">plot_flatmap_from_mapper</span><span class="p">(</span><span class="n">scores_wordnet</span><span class="p">,</span> <span class="n">mapper_file</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                              <span class="n">vmax</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<img alt="04 plot motion energy model" class="sphx-glr-single-img" src="../../_images/sphx_glr_04_plot_motion_energy_model_002.png" />
<p>We can also plot the comparison of model prediction accuracies with a 2D
histogram. All ~70k voxels are represented in this histogram, where the
diagonal corresponds to identical prediction accuracy for both models. A
distibution deviating from the diagonal means that one model has better
predictive performance than the other.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">voxelwise_tutorials.viz</span> <span class="kn">import</span> <span class="n">plot_hist2d</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">plot_hist2d</span><span class="p">(</span><span class="n">scores_wordnet</span><span class="p">,</span> <span class="n">scores_motion_energy</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s1">&#39;Generalization R2 scores&#39;</span><span class="p">,</span> <span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;semantic wordnet model&#39;</span><span class="p">,</span>
       <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;motion energy model&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<img alt="Generalization R2 scores" class="sphx-glr-single-img" src="../../_images/sphx_glr_04_plot_motion_energy_model_003.png" />
<p>Interestingly, the well predicted voxels are different in the two models.
To further describe these differences, we can plot both performances on the
same flatmap, using a 2D colormap.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">voxelwise_tutorials.viz</span> <span class="kn">import</span> <span class="n">plot_2d_flatmap_from_mapper</span>

<span class="n">mapper_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">directory</span><span class="p">,</span> <span class="s2">&quot;mappers&quot;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">subject</span><span class="si">}</span><span class="s2">_mappers.hdf&quot;</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">plot_2d_flatmap_from_mapper</span><span class="p">(</span><span class="n">scores_wordnet</span><span class="p">,</span> <span class="n">scores_motion_energy</span><span class="p">,</span>
                                 <span class="n">mapper_file</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">vmin2</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                                 <span class="n">vmax2</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label_1</span><span class="o">=</span><span class="s2">&quot;wordnet&quot;</span><span class="p">,</span>
                                 <span class="n">label_2</span><span class="o">=</span><span class="s2">&quot;motion energy&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<img alt="04 plot motion energy model" class="sphx-glr-single-img" src="../../_images/sphx_glr_04_plot_motion_energy_model_004.png" />
<p>The blue regions are well predicted by the motion-energy features, the orange
regions are well predicted by the wordnet features, and the white regions are
well predicted by both feature spaces.</p>
<p>A large part of the visual semantic areas are not only well predicted by the
wordnet features, but also by the motion-energy features, as indicated by the
white color. Since these two features spaces encode quite different
information, two interpretations are possible. In the first interpretation,
the two feature spaces encode complementary information, and could be used
jointly to further increase the generalization performance. In the second
interpretation, both feature spaces encode the same information, because of
spurious stimulus correlations. For example, imagine that the visual stimulus
contained faces that appeared consistetly in the same portion of the visual
field. In this case, position in the visual field would be perfectly
correlated with the “face” semantic category. Thus, motion-energy features
could predict responses in face-responsive areas without encoding any
semantic information.</p>
<p>To better disentangle the two feature spaces, we developed a joint model
called <cite>banded ridge regression</cite> <a class="footnote-reference brackets" href="#id6" id="id4">2</a>, which fits multiple feature spaces
simultaneously with optimal regularization for each feature space. This model
is described in the next example.</p>
</section>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<dl class="footnote brackets">
<dt class="label" id="id5"><span class="brackets">1</span><span class="fn-backref">(<a href="#id1">1</a>,<a href="#id2">2</a>,<a href="#id3">3</a>)</span></dt>
<dd><p>Nishimoto, S., Vu, A. T., Naselaris, T., Benjamini, Y., Yu,
B., &amp; Gallant, J. L. (2011). Reconstructing visual experiences from brain
activity evoked by natural movies. Current Biology, 21(19), 1641-1646.</p>
</dd>
<dt class="label" id="id6"><span class="brackets"><a class="fn-backref" href="#id4">2</a></span></dt>
<dd><p>Nunez-Elizalde, A. O., Huth, A. G., &amp; Gallant, J. L. (2019).
Voxelwise encoding models with non-spherical multivariate normal priors.
Neuroimage, 197, 482-492.</p>
</dd>
</dl>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 1 minutes  36.381 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-movies-3t-04-plot-motion-energy-model-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/bedcd9cef2bb77b37d1f37681b20e44b/04_plot_motion_energy_model.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">04_plot_motion_energy_model.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/62593657dc344560491e1a124299ee4a/04_plot_motion_energy_model.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">04_plot_motion_energy_model.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>
</section>


          </div>
          
        </div>
      </div>
    <div class="clearer"></div>
  </div>
    <div class="footer">
      &copy;2020, Gallant lab.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 4.1.2</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="../../_sources/_auto_examples/movies_3T/04_plot_motion_energy_model.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>