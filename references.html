
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>References &#8212; Voxelwise modeling tutorials 0.1 documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/alabaster.css" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery.css" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="_static/sg_gallery-rendered-html.css" />
    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/sphinx_highlight.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Helper Python package" href="voxelwise_package.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  <div class="document">
    
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<p class="logo">
  <a href="index.html">
    <img class="logo" src="_static/flatmap.png" alt="Logo"/>
    
  </a>
</p>



<p class="blurb">Voxelwise modeling tutorials</p>




<p>
<iframe src="https://ghbtns.com/github-btn.html?user=gallantlab&repo=voxelwise_tutorials&type=star&count=true&size=large&v=2"
  allowtransparency="true" frameborder="0" scrolling="0" width="200px" height="35px"></iframe>
</p>





<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
      <li>Previous: <a href="voxelwise_package.html" title="previous chapter">Helper Python package</a></li>
  </ul></li>
</ul>
</div><h3>Navigation</h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="_auto_examples/index.html">Shortclips tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="_auto_examples/index.html#vim-2-tutorial">Vim-2 tutorial</a></li>
</ul>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="voxelwise_modeling.html">Voxelwise modeling framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="voxelwise_package.html">Helper Python package</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">References</a></li>
</ul>


<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>
        </div>
      </div>
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="references">
<h1>References<a class="headerlink" href="#references" title="Permalink to this heading">¶</a></h1>
<p>Voxelwise modeling (VM) is a framework to perform functional magnetic resonance
imaging (fMRI) data analysis. Over the years, VM has led to many high profile
publications <a class="reference internal" href="#kay2008"><span class="std std-ref">[1]</span></a> <a class="reference internal" href="#nas2009"><span class="std std-ref">[2]</span></a> <a class="reference internal" href="#nis2011"><span class="std std-ref">[3]</span></a>
<a class="reference internal" href="#hut2012"><span class="std std-ref">[4]</span></a> <a class="reference internal" href="#cuk2013"><span class="std std-ref">[5]</span></a> <a class="reference internal" href="#cuk2013b"><span class="std std-ref">[6]</span></a>
<a class="reference internal" href="#sta2013"><span class="std std-ref">[7]</span></a> <a class="reference internal" href="#hut2016"><span class="std std-ref">[8]</span></a> <a class="reference internal" href="#deh2017"><span class="std std-ref">[9]</span></a>
<a class="reference internal" href="#les2019"><span class="std std-ref">[10]</span></a> <a class="reference internal" href="#den2019"><span class="std std-ref">[11]</span></a> <a class="reference internal" href="#nun2019"><span class="std std-ref">[12]</span></a>
<a class="reference internal" href="#pop2021"><span class="std std-ref">[13]</span></a> <a class="reference internal" href="#leb2021"><span class="std std-ref">[14]</span></a> <a class="reference internal" href="#dup2022"><span class="std std-ref">[15]</span></a>.</p>
<dl class="simple" id="kay2008">
<dt>[1] Kay, K. N., Naselaris, T., Prenger, R. J., &amp; Gallant, J. L. (2008).</dt><dd><p>Identifying natural images from human brain activity.
Nature, 452(7185), 352-355.</p>
</dd>
</dl>
<dl class="simple" id="nas2009">
<dt>[2] Naselaris, T., Prenger, R. J., Kay, K. N., Oliver, M., &amp; Gallant, J. L. (2009).</dt><dd><p>Bayesian reconstruction of natural images from human brain activity.
Neuron, 63(6), 902-915.</p>
</dd>
</dl>
<dl class="simple" id="nis2011">
<dt>[3] Nishimoto, S., Vu, A. T., Naselaris, T., Benjamini, Y., Yu, B., &amp; Gallant, J. L. (2011).</dt><dd><p>Reconstructing visual experiences from brain activity evoked by natural movies.
Current Biology, 21(19), 1641-1646.</p>
</dd>
</dl>
<dl class="simple" id="hut2012">
<dt>[4] Huth, A. G., Nishimoto, S., Vu, A. T., &amp; Gallant, J. L. (2012).</dt><dd><p>A continuous semantic space describes the representation of thousands of
object and action categories across the human brain.
Neuron, 76(6), 1210-1224.</p>
</dd>
</dl>
<dl class="simple" id="cuk2013">
<dt>[5] Çukur, T., Nishimoto, S., Huth, A. G., &amp; Gallant, J. L. (2013).</dt><dd><p>Attention during natural vision warps semantic representation across the human brain.
Nature neuroscience, 16(6), 763-770.</p>
</dd>
</dl>
<dl class="simple" id="cuk2013b">
<dt>[6] Çukur, T., Huth, A. G., Nishimoto, S., &amp; Gallant, J. L. (2013).</dt><dd><p>Functional subdomains within human FFA.
Journal of Neuroscience, 33(42), 16748-16766.</p>
</dd>
</dl>
<dl class="simple" id="sta2013">
<dt>[7] Stansbury, D. E., Naselaris, T., &amp; Gallant, J. L. (2013).</dt><dd><p>Natural scene statistics account for the representation of scene categories
in human visual cortex.
Neuron, 79(5), 1025-1034</p>
</dd>
</dl>
<dl class="simple" id="hut2016">
<dt>[8] Huth, A. G., De Heer, W. A., Griffiths, T. L., Theunissen, F. E., &amp; Gallant, J. L. (2016).</dt><dd><p>Natural speech reveals the semantic maps that tile human cerebral cortex.
Nature, 532(7600), 453-458.</p>
</dd>
</dl>
<dl class="simple" id="deh2017">
<dt>[9] de Heer, W. A., Huth, A. G., Griffiths, T. L., Gallant, J. L., &amp; Theunissen, F. E. (2017).</dt><dd><p>The hierarchical cortical organization of human speech processing.
Journal of Neuroscience, 37(27), 6539-6557.</p>
</dd>
</dl>
<dl class="simple" id="les2019">
<dt>[10] Lescroart, M. D., &amp; Gallant, J. L. (2019).</dt><dd><p>Human scene-selective areas represent 3D configurations of surfaces.
Neuron, 101(1), 178-192.</p>
</dd>
</dl>
<dl class="simple" id="den2019">
<dt>[11] Deniz, F., Nunez-Elizalde, A. O., Huth, A. G., &amp; Gallant, J. L. (2019).</dt><dd><p>The representation of semantic information across human cerebral cortex
during listening versus reading is invariant to stimulus modality.
Journal of Neuroscience, 39(39), 7722-7736.</p>
</dd>
</dl>
<dl class="simple" id="nun2019">
<dt>[12] Nunez-Elizalde, A. O., Huth, A. G., &amp; Gallant, J. L. (2019).</dt><dd><p>Voxelwise encoding models with non-spherical multivariate normal priors.
Neuroimage, 197, 482-492.</p>
</dd>
</dl>
<dl class="simple" id="pop2021">
<dt>[13] Popham, S. F., Huth, A. G., Bilenko, N. Y., Deniz, F., Gao, J. S.,</dt><dd><p>Nunez-Elizalde, A. O., &amp; Gallant, J. L. (2021).
Visual and linguistic semantic representations are aligned at the border of
human visual cortex.
Nature Neuroscience, 24(11), 1628-1636.</p>
</dd>
</dl>
<dl class="simple" id="leb2021">
<dt>[14] LeBel, A., Jain, S., &amp; Huth, A. G. (2021).</dt><dd><p>Voxelwise encoding models show that cerebellar language representations are
highly conceptual.
Journal of Neuroscience, 41(50), 10341-10355.</p>
</dd>
</dl>
<dl class="simple" id="dup2022">
<dt>[15] Dupré La Tour, T., Eickenberg, M., Nunez-Elizalde, A.O., &amp; Gallant, J. L. (2022).</dt><dd><p>Feature-space selection with banded ridge regression.
NeuroImage. <a class="reference external" href="https://doi.org/10.1016/j.neuroimage.2022.119728">https://doi.org/10.1016/j.neuroimage.2022.119728</a></p>
</dd>
</dl>
<section id="datasets">
<h2>Datasets<a class="headerlink" href="#datasets" title="Permalink to this heading">¶</a></h2>
<dl class="simple" id="nis2011data">
<dt>[3b] Nishimoto, S., Vu, A. T., Naselaris, T., Benjamini, Y., Yu, B., &amp; Gallant, J. L. (2014).</dt><dd><p>Gallant Lab Natural Movie 4T fMRI Data.
CRCNS.org. <a class="reference external" href="http://dx.doi.org/10.6080/K00Z715X">http://dx.doi.org/10.6080/K00Z715X</a></p>
</dd>
</dl>
<dl class="simple" id="hut2012data">
<dt>[4b] Huth, A. G., Nishimoto, S., Vu, A. T., Dupré la Tour, T., &amp; Gallant, J. L. (2022).</dt><dd><p>Gallant Lab Natural Short Clips 3T fMRI Data.
GIN. <a class="reference external" href="http://dx.doi.org/10.12751/g-node.vy1zjd">http://dx.doi.org/10.12751/g-node.vy1zjd</a></p>
</dd>
</dl>
</section>
<section id="packages">
<h2>Packages<a class="headerlink" href="#packages" title="Permalink to this heading">¶</a></h2>
<dl class="simple" id="dup2023">
<dt>[p1] Dupré La Tour, T., Visconti di Oleggio Castello, M., &amp; Gallant, J. L. (2023).</dt><dd><p>Voxelwise modeling tutorials: an encoding model approach to functional MRI analysis.
<em>In preparation</em>.</p>
</dd>
<dt>[p2] Dupré La Tour, T., Eickenberg, M., Nunez-Elizalde, A.O., &amp; Gallant, J. L. (2022).</dt><dd><p>Feature-space selection with banded ridge regression.
NeuroImage. <a class="reference external" href="https://doi.org/10.1016/j.neuroimage.2022.119728">https://doi.org/10.1016/j.neuroimage.2022.119728</a></p>
</dd>
</dl>
<dl class="simple" id="gao2015">
<dt>[p3] Gao, J. S., Huth, A. G., Lescroart, M. D., &amp; Gallant, J. L. (2015).</dt><dd><p>Pycortex: an interactive surface visualizer for fMRI.
Frontiers in Neuroinformatics, 23. <a class="reference external" href="https://doi.org/10.3389/fninf.2015.00023">https://doi.org/10.3389/fninf.2015.00023</a></p>
</dd>
</dl>
<dl class="simple" id="nun2021">
<dt>[p4] Nunez-Elizalde, A.O., Deniz, F., Dupré la Tour, T., Visconti di Oleggio Castello, M., and Gallant, J.L. (2021).</dt><dd><p>pymoten: scientific python package for computing motion energy features from video.
Zenodo. <a class="reference external" href="https://doi.org/10.5281/zenodo.6349625">https://doi.org/10.5281/zenodo.6349625</a></p>
</dd>
</dl>
</section>
</section>


          </div>
          
        </div>
      </div>
    <div class="clearer"></div>
  </div>
    <div class="footer">
      &copy;2023, Gallant lab.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 5.3.0</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.13</a>
      
      |
      <a href="_sources/references.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>