
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Setup Google Colab &#8212; Voxelwise Encoding Model tutorials</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../_static/doctools.js?v=888ff710"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'notebooks/shortclips/vem_tutorials_merged_for_colab';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../pages/index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/flatmap.png" class="logo__image only-light" alt="Voxelwise Encoding Model tutorials - Home"/>
    <script>document.write(`<img src="../../_static/flatmap.png" class="logo__image only-dark" alt="Voxelwise Encoding Model tutorials - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../pages/index.html">
                    Voxelwise Encoding Model (VEM) tutorials
                </a>
            </li>
        </ul>
        <ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../pages/voxelwise_modeling.html">Overview of the VEM framework</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="README.html">Shortclips tutorial</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="02_download_shortclips.html">Download the data set</a></li>
<li class="toctree-l2"><a class="reference internal" href="03_compute_explainable_variance.html">Compute the explainable variance</a></li>
<li class="toctree-l2"><a class="reference internal" href="04_understand_ridge_regression.html">Understand ridge regression and hyperparameter selection</a></li>
<li class="toctree-l2"><a class="reference internal" href="05_fit_wordnet_model.html">Fit a voxelwise encoding model with WordNet features</a></li>
<li class="toctree-l2"><a class="reference internal" href="06_visualize_hemodynamic_response.html">Visualize the hemodynamic response</a></li>
<li class="toctree-l2"><a class="reference internal" href="07_extract_motion_energy.html">Extract motion-energy features from the stimuli</a></li>
<li class="toctree-l2"><a class="reference internal" href="08_fit_motion_energy_model.html">Fit a voxelwise encoding model with motion-energy features</a></li>
<li class="toctree-l2"><a class="reference internal" href="09_fit_banded_ridge_model.html">Fit a voxelwise encoding model with both WordNet and motion-energy features</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../vim2/README.html">Vim-2 tutorial (optional)</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../vim2/00_download_vim2.html">Download the data set from CRCNS</a></li>
<li class="toctree-l2"><a class="reference internal" href="../vim2/01_extract_motion_energy.html">Extract motion-energy features from the stimuli</a></li>
<li class="toctree-l2"><a class="reference internal" href="../vim2/02_plot_ridge_model.html">Fit a ridge model with motion energy features</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../pages/references.html">References</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../pages/voxelwise_package.html"><code class="docutils literal notranslate"><span class="pre">voxelwise_tutorials</span></code> helper package</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/gallantlab/voxelwise_tutorials" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/gallantlab/voxelwise_tutorials/issues/new?title=Issue%20on%20page%20%2Fnotebooks/shortclips/vem_tutorials_merged_for_colab.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/notebooks/shortclips/vem_tutorials_merged_for_colab.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Setup Google Colab</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Setup Google Colab</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#change-runtime-to-use-a-gpu">Change runtime to use a GPU</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#install-all-required-dependencies">Install all required dependencies</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#download-the-data-set">Download the data set</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cite-this-data-set">Cite this data set</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#download">Download</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references">References</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#compute-the-explainable-variance">Compute the explainable variance</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#path-of-the-data-directory">Path of the data directory</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id30">Compute the explainable variance</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#map-to-subject-flatmap">Map to subject flatmap</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#map-to-fsaverage">Map to “fsaverage”</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id31">References</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#understand-ridge-regression-and-hyperparameter-selection">Understand ridge regression and hyperparameter selection</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ordinary-least-squares-ols">Ordinary least squares (OLS)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ridge-regression">Ridge regression</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hyperparameter-selection">Hyperparameter selection</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#fit-a-voxelwise-encoding-model-with-wordnet-features">Fit a voxelwise encoding model with WordNet features</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id59">Path of the data directory</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#load-the-data">Load the data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#define-the-cross-validation-scheme">Define the cross-validation scheme</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#define-the-model">Define the model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fit-the-model">Fit the model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#plot-the-model-prediction-accuracy">Plot the model prediction accuracy</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#plot-the-selected-hyperparameters">Plot the selected hyperparameters</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#visualize-the-regression-coefficients">Visualize the regression coefficients</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id71">References</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#visualize-the-hemodynamic-response">Visualize the hemodynamic response</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id98">Path of the data directory</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id99">Load the data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id100">Define the cross-validation scheme</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id101">Define the model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id102">Fit the model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#understanding-delays">Understanding delays</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#compare-with-a-model-without-delays">Compare with a model without delays</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#visualize-the-hrf">Visualize the HRF</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#fit-a-voxelwise-encoding-model-with-motion-energy-features">Fit a voxelwise encoding model with motion-energy features</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id105">Path of the data directory</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id106">Load the data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id107">Define the cross-validation scheme</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id108">Define the model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id109">Fit the model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#plot-the-model-performances">Plot the model performances</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#compare-with-the-wordnet-model">Compare with the wordnet model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id112">References</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#fit-a-voxelwise-encoding-model-with-both-wordnet-and-motion-energy-features">Fit a voxelwise encoding model with both WordNet and motion-energy features</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id140">Path of the data directory</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id141">Load the data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id142">Define the cross-validation scheme</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id143">Define the model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id144">Fit the model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#compare-with-a-ridge-model">Compare with a ridge model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#plot-the-banded-ridge-split">Plot the banded ridge split</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id146">References</a></li>
</ul>
</li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="setup-google-colab">
<h1>Setup Google Colab<a class="headerlink" href="#setup-google-colab" title="Link to this heading">#</a></h1>
<p>In this script, we setup a Google Colab environment. This script will only work
when run from <a class="reference external" href="https://colab.research.google.com/">Google Colab</a>. You can
skip it if you run the tutorials on your machine.</p>
<blockquote>
<div><p><strong>Note:</strong> This script will install all the required dependencies and download the data.
It will take around 10 minutes to run, but you need to run it only once in your Colab session.
If your Colab session is disconnected, you will need to run this script again.</p>
</div></blockquote>
<section id="change-runtime-to-use-a-gpu">
<h2>Change runtime to use a GPU<a class="headerlink" href="#change-runtime-to-use-a-gpu" title="Link to this heading">#</a></h2>
<p>This tutorial is much faster when a GPU is available to run the computations.
In Google Colab you can request access to a GPU by changing the runtime type.
To do so, click the following menu options in Google Colab:</p>
<blockquote>
<div><p>(Menu) “Runtime” -&gt; “Change runtime type” -&gt; “Hardware accelerator” -&gt; “GPU”.</p>
</div></blockquote>
</section>
<section id="install-all-required-dependencies">
<h2>Install all required dependencies<a class="headerlink" href="#install-all-required-dependencies" title="Link to this heading">#</a></h2>
<p>Uncomment and run the following cell to download the required packages.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!git config --global user.email &quot;you@example.com&quot; &amp;&amp; git config --global user.name &quot;Your Name&quot;</span>
<span class="c1">#!wget -O- http://neuro.debian.net/lists/jammy.us-ca.libre | sudo tee /etc/apt/sources.list.d/neurodebian.sources.list</span>
<span class="c1">#!apt-key adv --recv-keys --keyserver hkps://keyserver.ubuntu.com 0xA5D32F012649A5A9 &gt; /dev/null</span>
<span class="c1">#!apt-get -qq update &gt; /dev/null</span>
<span class="c1">#!apt-get install -qq inkscape git-annex-standalone &gt; /dev/null</span>
<span class="c1">#!pip install -q voxelwise_tutorials</span>
</pre></div>
</div>
</div>
</div>
<p>For the record, here is what each command does:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># - Set up an email and username to use git, git-annex, and datalad (required to download the data)</span>
<span class="c1"># - Add NeuroDebian to the package sources</span>
<span class="c1"># - Update the gpg keys to use NeuroDebian</span>
<span class="c1"># - Update the list of available packages</span>
<span class="c1"># - Install Inkscape to use more features from Pycortex, and install git-annex to download the data</span>
<span class="c1"># - Install the tutorial helper package, and all the required dependencies</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">google.colab</span> <span class="c1"># noqa</span>
    <span class="n">in_colab</span> <span class="o">=</span> <span class="kc">True</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="n">in_colab</span> <span class="o">=</span> <span class="kc">False</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">in_colab</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;This script is only meant to be run from Google &quot;</span>
                       <span class="s2">&quot;Colab. You can skip it if you run the tutorials &quot;</span>
                       <span class="s2">&quot;on your machine.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now run the following cell to set up the environment variables for the
tutorials and pycortex.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;VOXELWISE_TUTORIALS_DATA&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;/content&quot;</span>

<span class="kn">import</span> <span class="nn">sklearn</span>
<span class="n">sklearn</span><span class="o">.</span><span class="n">set_config</span><span class="p">(</span><span class="n">assume_finite</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Your Google Colab environment is now set up for the voxelwise tutorials.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">reset</span> -f
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="download-the-data-set">
<h1>Download the data set<a class="headerlink" href="#download-the-data-set" title="Link to this heading">#</a></h1>
<p>In this script, we download the data set from Wasabi or GIN. No account is required.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This script will download approximately 2GB of data.</p>
</div>
<section id="cite-this-data-set">
<h2>Cite this data set<a class="headerlink" href="#cite-this-data-set" title="Link to this heading">#</a></h2>
<p>This tutorial is based on publicly available data <a class="reference external" href="https://gin.g-node.org/gallantlab/shortclips">published on GIN</a>. If you publish any work using
this data set, please cite the original publication <span id="id1">[<a class="reference internal" href="../../pages/voxelwise_modeling.html#id14" title="A. G. Huth, S. Nishimoto, A. T. Vu, and J. L. Gallant. A continuous semantic space describes the representation of thousands of object and action categories across the human brain. Neuron, 76(6):1210–1224, 2012.">Huth <em>et al.</em>, 2012</a>]</span>, and the data set <span id="id2">[<a class="reference internal" href="../../pages/references.html#id25" title="A. G. Huth, S. Nishimoto, A. T. Vu, T. Dupré la Tour, and J. L. Gallant. Gallant lab natural short clips 3t fMRI data. 2022. doi:10.12751/g-node.vy1zjd.">Huth <em>et al.</em>, 2022</a>]</span>.</p>
</section>
<section id="download">
<h2>Download<a class="headerlink" href="#download" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># path of the data directory</span>
<span class="kn">from</span> <span class="nn">voxelwise_tutorials.io</span> <span class="kn">import</span> <span class="n">get_data_home</span>
<span class="n">directory</span> <span class="o">=</span> <span class="n">get_data_home</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="s2">&quot;shortclips&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">directory</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We will only use the first subject in this tutorial, but you can run the same
analysis on the four other subjects. Uncomment the lines in <code class="docutils literal notranslate"><span class="pre">DATAFILES</span></code> to
download more subjects.</p>
<p>We also skip the stimuli files, since the dataset provides two preprocessed
feature spaces to fit voxelwise encoding models without requiring the original
stimuli.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">voxelwise_tutorials.io</span> <span class="kn">import</span> <span class="n">download_datalad</span>

<span class="n">DATAFILES</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;features/motion_energy.hdf&quot;</span><span class="p">,</span>
    <span class="s2">&quot;features/wordnet.hdf&quot;</span><span class="p">,</span>
    <span class="s2">&quot;mappers/S01_mappers.hdf&quot;</span><span class="p">,</span>
    <span class="c1"># &quot;mappers/S02_mappers.hdf&quot;,</span>
    <span class="c1"># &quot;mappers/S03_mappers.hdf&quot;,</span>
    <span class="c1"># &quot;mappers/S04_mappers.hdf&quot;,</span>
    <span class="c1"># &quot;mappers/S05_mappers.hdf&quot;,</span>
    <span class="s2">&quot;responses/S01_responses.hdf&quot;</span><span class="p">,</span>
    <span class="c1"># &quot;responses/S02_responses.hdf&quot;,</span>
    <span class="c1"># &quot;responses/S03_responses.hdf&quot;,</span>
    <span class="c1"># &quot;responses/S04_responses.hdf&quot;,</span>
    <span class="c1"># &quot;responses/S05_responses.hdf&quot;,</span>
    <span class="c1"># &quot;stimuli/test.hdf&quot;,</span>
    <span class="c1"># &quot;stimuli/train_00.hdf&quot;,</span>
    <span class="c1"># &quot;stimuli/train_01.hdf&quot;,</span>
    <span class="c1"># &quot;stimuli/train_02.hdf&quot;,</span>
    <span class="c1"># &quot;stimuli/train_03.hdf&quot;,</span>
    <span class="c1"># &quot;stimuli/train_04.hdf&quot;,</span>
    <span class="c1"># &quot;stimuli/train_05.hdf&quot;,</span>
    <span class="c1"># &quot;stimuli/train_06.hdf&quot;,</span>
    <span class="c1"># &quot;stimuli/train_07.hdf&quot;,</span>
    <span class="c1"># &quot;stimuli/train_08.hdf&quot;,</span>
    <span class="c1"># &quot;stimuli/train_09.hdf&quot;,</span>
    <span class="c1"># &quot;stimuli/train_10.hdf&quot;,</span>
    <span class="c1"># &quot;stimuli/train_11.hdf&quot;,</span>
<span class="p">]</span>

<span class="n">source</span> <span class="o">=</span> <span class="s2">&quot;https://gin.g-node.org/gallantlab/shortclips&quot;</span>

<span class="k">for</span> <span class="n">datafile</span> <span class="ow">in</span> <span class="n">DATAFILES</span><span class="p">:</span>
    <span class="n">local_filename</span> <span class="o">=</span> <span class="n">download_datalad</span><span class="p">(</span><span class="n">datafile</span><span class="p">,</span> <span class="n">destination</span><span class="o">=</span><span class="n">directory</span><span class="p">,</span>
                                      <span class="n">source</span><span class="o">=</span><span class="n">source</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Link to this heading">#</a></h2>
<div class="docutils container" id="id3">
<div role="list" class="citation-list">
<div class="citation" id="id18" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>DlTENEG22<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id111">1</a>,<a role="doc-backlink" href="#id139">2</a>,<a role="doc-backlink" href="#id145">3</a>)</span>
<p>T. Dupré la Tour, M. Eickenberg, A.O. Nunez-Elizalde, and J. L. Gallant. Feature-space selection with banded ridge regression. <em>NeuroImage</em>, 267:119728, 2022. <a class="reference external" href="https://doi.org/10.1016/j.neuroimage.2022.119728">doi:10.1016/j.neuroimage.2022.119728</a>.</p>
</div>
<div class="citation" id="id28" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>HTF09<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id61">1</a>,<a role="doc-backlink" href="#id62">2</a>)</span>
<p>Trevor Hastie, Robert Tibshirani, and Jerome Friedman. <em>The Elements of Statistical Learning</em>. Springer New York, 2009.</p>
</div>
<div class="citation" id="id25" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id29">HBT04</a><span class="fn-bracket">]</span></span>
<p>A. Hsu, A. Borst, and F. E. Theunissen. Quantifying variability in neural responses and its application for the validation of model predictions. <em>Network</em>, 2004.</p>
</div>
<div class="citation" id="id20" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id2">HNV+22</a><span class="fn-bracket">]</span></span>
<p>A. G. Huth, S. Nishimoto, A. T. Vu, T. Dupré la Tour, and J. L. Gallant. Gallant lab natural short clips 3t fMRI data. 2022. <a class="reference external" href="https://doi.org/10.12751/g-node.vy1zjd">doi:10.12751/g-node.vy1zjd</a>.</p>
</div>
<div class="citation" id="id7" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>HNVG12<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id1">1</a>,<a role="doc-backlink" href="#id58">2</a>,<a role="doc-backlink" href="#id60">3</a>,<a role="doc-backlink" href="#id64">4</a>,<a role="doc-backlink" href="#id65">5</a>,<a role="doc-backlink" href="#id66">6</a>,<a role="doc-backlink" href="#id67">7</a>,<a role="doc-backlink" href="#id68">8</a>,<a role="doc-backlink" href="#id69">9</a>,<a role="doc-backlink" href="#id70">10</a>)</span>
<p>A. G. Huth, S. Nishimoto, A. T. Vu, and J. L. Gallant. A continuous semantic space describes the representation of thousands of object and action categories across the human brain. <em>Neuron</em>, 76(6):1210–1224, 2012.</p>
</div>
<div class="citation" id="id6" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>NVN+11<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id103">1</a>,<a role="doc-backlink" href="#id104">2</a>,<a role="doc-backlink" href="#id110">3</a>)</span>
<p>S. Nishimoto, A. T. Vu, T. Naselaris, Y. Benjamini, B. Yu, and J. L. Gallant. Reconstructing visual experiences from brain activity evoked by natural movies. <em>Current Biology</em>, 21(19):1641–1646, 2011.</p>
</div>
<div class="citation" id="id15" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>NEHG19<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id111">1</a>,<a role="doc-backlink" href="#id139">2</a>,<a role="doc-backlink" href="#id145">3</a>)</span>
<p>A. O. Nunez-Elizalde, A. G. Huth, and J. L. Gallant. Voxelwise encoding models with non-spherical multivariate normal priors. <em>Neuroimage</em>, 197:482–492, 2019.</p>
</div>
<div class="citation" id="id24" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id29">SL02</a><span class="fn-bracket">]</span></span>
<p>M. Sahani and J. Linden. How linear are auditory cortical responses? <em>Adv. Neural Inf. Process. Syst.</em>, 2002.</p>
</div>
<div class="citation" id="id27" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id63">SGV98</a><span class="fn-bracket">]</span></span>
<p>C. Saunders, A. Gammerman, and V. Vovk. Ridge regression learning algorithm in dual variables. 1998.</p>
</div>
<div class="citation" id="id26" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id29">SHW+16</a><span class="fn-bracket">]</span></span>
<p>O. Schoppe, N. S. Harper, B. Willmore, A. King, and J. Schnupp. Measuring the performance of neural models. <em>Front. Comput. Neurosci.</em>, 2016.</p>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">reset</span> -f
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="compute-the-explainable-variance">
<h1>Compute the explainable variance<a class="headerlink" href="#compute-the-explainable-variance" title="Link to this heading">#</a></h1>
<p>Before fitting any voxelwise model to fMRI responses, it is good practice to
quantify the amount of signal in the test set that can be predicted by an
encoding model. This quantity is called the <em>explainable variance</em>.</p>
<p>The measured signal can be decomposed into a sum of two components: the
stimulus-dependent signal and noise. If we present the same stimulus multiple
times and we record brain activity for each repetition, the stimulus-dependent
signal will be the same across repetitions while the noise will vary across
repetitions. In the Voxelwise Encoding Model framework,
the features used to model brain activity are the same for each repetition of the
stimulus. Thus, encoding models will predict only the repeatable stimulus-dependent
signal.</p>
<p>The stimulus-dependent signal can be estimated by taking the mean of brain
responses over repeats of the same stimulus or experiment. The variance of the
estimated stimulus-dependent signal, which we call the explainable variance, is
proportional to the maximum prediction accuracy that can be obtained by a
voxelwise encoding model in the test set.</p>
<p>Mathematically, let <span class="math notranslate nohighlight">\(y_i, i = 1 \dots N\)</span> be the measured signal in a
voxel for each of the <span class="math notranslate nohighlight">\(N\)</span> repetitions of the same stimulus and
<span class="math notranslate nohighlight">\(\bar{y} = \frac{1}{N}\sum_{i=1}^Ny_i\)</span> the average brain response
across repetitions. For each repeat, we define the residual timeseries between
brain response and average brain response as <span class="math notranslate nohighlight">\(r_i = y_i - \bar{y}\)</span>. The
explainable variance (EV) is estimated as</p>
<div class="amsmath math notranslate nohighlight" id="equation-64115708-e9f1-47c8-81fe-0036e336bac3">
<span class="eqno">()<a class="headerlink" href="#equation-64115708-e9f1-47c8-81fe-0036e336bac3" title="Permalink to this equation">#</a></span>\[\begin{align}\text{EV} = \frac{1}{N}\sum_{i=1}^N\text{Var}(y_i) - \frac{N}{N-1}\sum_{i=1}^N\text{Var}(r_i)\end{align}\]</div>
<p>In the literature, the explainable variance is also known as the <em>signal
power</em>.</p>
<p>For more information, see <span id="id29">[<a class="reference internal" href="vem_tutorials_merged_for_colab_model_fitting.html#id164" title="A. Hsu, A. Borst, and F. E. Theunissen. Quantifying variability in neural responses and its application for the validation of model predictions. Network, 2004.">Hsu <em>et al.</em>, 2004</a>, <a class="reference internal" href="vem_tutorials_merged_for_colab_model_fitting.html#id163" title="M. Sahani and J. Linden. How linear are auditory cortical responses? Adv. Neural Inf. Process. Syst., 2002.">Sahani and Linden, 2002</a>, <a class="reference internal" href="vem_tutorials_merged_for_colab_model_fitting.html#id165" title="O. Schoppe, N. S. Harper, B. Willmore, A. King, and J. Schnupp. Measuring the performance of neural models. Front. Comput. Neurosci., 2016.">Schoppe <em>et al.</em>, 2016</a>]</span>.</p>
<section id="path-of-the-data-directory">
<h2>Path of the data directory<a class="headerlink" href="#path-of-the-data-directory" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">voxelwise_tutorials.io</span> <span class="kn">import</span> <span class="n">get_data_home</span>

<span class="n">directory</span> <span class="o">=</span> <span class="n">get_data_home</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="s2">&quot;shortclips&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">directory</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># modify to use another subject</span>
<span class="n">subject</span> <span class="o">=</span> <span class="s2">&quot;S01&quot;</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="id30">
<h2>Compute the explainable variance<a class="headerlink" href="#id30" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">voxelwise_tutorials.io</span> <span class="kn">import</span> <span class="n">load_hdf5_array</span>
</pre></div>
</div>
</div>
</div>
<p>First, we load the fMRI responses on the test set, which contains brain
responses to ten (10) repeats of the same stimulus.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>

<span class="n">file_name</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">directory</span><span class="p">,</span> <span class="s1">&#39;responses&#39;</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">subject</span><span class="si">}</span><span class="s1">_responses.hdf&#39;</span><span class="p">)</span>
<span class="n">Y_test</span> <span class="o">=</span> <span class="n">load_hdf5_array</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="s2">&quot;Y_test&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;(n_repeats, n_samples_test, n_voxels) =&quot;</span><span class="p">,</span> <span class="n">Y_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Then, we compute the explainable variance for each voxel.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">voxelwise_tutorials.utils</span> <span class="kn">import</span> <span class="n">explainable_variance</span>

<span class="n">ev</span> <span class="o">=</span> <span class="n">explainable_variance</span><span class="p">(</span><span class="n">Y_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;(n_voxels,) =&quot;</span><span class="p">,</span> <span class="n">ev</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>To better understand the concept of explainable variance, we can plot the
measured signal in a voxel with high explainable variance…</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">voxel_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">ev</span><span class="p">)</span>
<span class="n">time</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">Y_test</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">*</span> <span class="mi">2</span>  <span class="c1"># one time point every 2 seconds</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">time</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">voxel_1</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;C0&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">time</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">voxel_1</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;C1&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;average&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Time (sec)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Voxel with large explainable variance (</span><span class="si">%.2f</span><span class="s2">)&quot;</span> <span class="o">%</span> <span class="n">ev</span><span class="p">[</span><span class="n">voxel_1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">([])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>… and in a voxel with low explainable variance.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">voxel_2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">ev</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">time</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">voxel_2</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;C0&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">time</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">voxel_2</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;C1&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;average&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Time (sec)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Voxel with low explainable variance (</span><span class="si">%.2f</span><span class="s2">)&quot;</span> <span class="o">%</span> <span class="n">ev</span><span class="p">[</span><span class="n">voxel_2</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">([])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>We can also plot the distribution of explainable variance over voxels.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">ev</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span> <span class="n">log</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">histtype</span><span class="o">=</span><span class="s1">&#39;step&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Explainable variance&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Number of voxels&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Histogram of explainable variance&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="s1">&#39;on&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>We see that many voxels have low explainable variance. This is
expected, since many voxels are not driven by a visual stimulus, and their
response changes over repeats of the same stimulus.
We also see that some voxels have high explainable variance (around 0.7). The
responses in these voxels are highly consistent across repetitions of the
same stimulus. Thus, they are good targets for encoding models.</p>
</section>
<section id="map-to-subject-flatmap">
<h2>Map to subject flatmap<a class="headerlink" href="#map-to-subject-flatmap" title="Link to this heading">#</a></h2>
<p>To better understand the distribution of explainable variance, we map the
values to the subject brain. This can be done with <a class="reference external" href="https://gallantlab.github.io/pycortex/">pycortex</a>, which can create interactive 3D
viewers to be displayed in any modern browser. <code class="docutils literal notranslate"><span class="pre">pycortex</span></code> can also display
flattened maps of the cortical surface to visualize the entire cortical
surface at once.</p>
<p>Here, we do not share the anatomical information of the subjects for privacy
concerns. Instead, we provide two mappers:</p>
<ul class="simple">
<li><p>to map the voxels to a (subject-specific) flatmap</p></li>
<li><p>to map the voxels to the Freesurfer average cortical surface (“fsaverage”)</p></li>
</ul>
<p>The first mapper is 2D matrix of shape (n_pixels, n_voxels) that maps each
voxel to a set of pixel in a flatmap. The matrix is efficiently stored in a
<code class="docutils literal notranslate"><span class="pre">scipy</span></code> sparse CSR matrix. The function <code class="docutils literal notranslate"><span class="pre">plot_flatmap_from_mapper</span></code>
provides an example of how to use the mapper and visualize the flatmap.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">voxelwise_tutorials.viz</span> <span class="kn">import</span> <span class="n">plot_flatmap_from_mapper</span>

<span class="n">mapper_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">directory</span><span class="p">,</span> <span class="s1">&#39;mappers&#39;</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">subject</span><span class="si">}</span><span class="s1">_mappers.hdf&#39;</span><span class="p">)</span>
<span class="n">plot_flatmap_from_mapper</span><span class="p">(</span><span class="n">ev</span><span class="p">,</span> <span class="n">mapper_file</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>This figure is a flattened map of the cortical surface. A number of regions
of interest (ROIs) have been labeled to ease interpretation. If you have
never seen such a flatmap, we recommend taking a look at a <a class="reference external" href="https://www.gallantlab.org/brainviewer/Deniz2019">pycortex brain
viewer</a>, which displays
the brain in 3D. In this viewer, press “I” to inflate the brain, “F” to
flatten the surface, and “R” to reset the view (or use the <code class="docutils literal notranslate"><span class="pre">surface/unfold</span></code>
cursor on the right menu). Press “H” for a list of all keyboard shortcuts.
This viewer should help you understand the correspondence between the flatten
and the folded cortical surface of the brain.</p>
<p>On this flatmap, we can see that the explainable variance is mainly located
in the visual cortex, in early visual regions like V1, V2, V3, or in
higher-level regions like EBA, FFA or IPS. This is expected since this
dataset contains responses to a visual stimulus.</p>
</section>
<section id="map-to-fsaverage">
<h2>Map to “fsaverage”<a class="headerlink" href="#map-to-fsaverage" title="Link to this heading">#</a></h2>
<p>The second mapper we provide maps the voxel data to a Freesurfer
average surface (“fsaverage”), that can be used in <code class="docutils literal notranslate"><span class="pre">pycortex</span></code>.</p>
<p>First, let’s download the “fsaverage” surface.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">cortex</span>

<span class="n">surface</span> <span class="o">=</span> <span class="s2">&quot;fsaverage&quot;</span>

<span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">cortex</span><span class="o">.</span><span class="n">db</span><span class="p">,</span> <span class="n">surface</span><span class="p">):</span>
    <span class="n">cortex</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">download_subject</span><span class="p">(</span><span class="n">subject_id</span><span class="o">=</span><span class="n">surface</span><span class="p">,</span>
                                  <span class="n">pycortex_store</span><span class="o">=</span><span class="n">cortex</span><span class="o">.</span><span class="n">db</span><span class="o">.</span><span class="n">filestore</span><span class="p">)</span>
    <span class="n">cortex</span><span class="o">.</span><span class="n">db</span><span class="o">.</span><span class="n">reload_subjects</span><span class="p">()</span>  <span class="c1"># force filestore reload</span>
    <span class="k">assert</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">cortex</span><span class="o">.</span><span class="n">db</span><span class="p">,</span> <span class="n">surface</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Then, we load the “fsaverage” mapper. The mapper is a matrix of shape
(n_vertices, n_voxels), which maps each voxel to some vertices in the
fsaverage surface. It is stored as a sparse CSR matrix. The mapper is applied
with a dot product <code class="docutils literal notranslate"><span class="pre">&#64;</span></code> (equivalent to <code class="docutils literal notranslate"><span class="pre">np.dot</span></code>).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">voxelwise_tutorials.io</span> <span class="kn">import</span> <span class="n">load_hdf5_sparse_array</span>

<span class="n">voxel_to_fsaverage</span> <span class="o">=</span> <span class="n">load_hdf5_sparse_array</span><span class="p">(</span><span class="n">mapper_file</span><span class="p">,</span>
                                            <span class="n">key</span><span class="o">=</span><span class="s1">&#39;voxel_to_fsaverage&#39;</span><span class="p">)</span>
<span class="n">ev_projected</span> <span class="o">=</span> <span class="n">voxel_to_fsaverage</span> <span class="o">@</span> <span class="n">ev</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;(n_vertices,) =&quot;</span><span class="p">,</span> <span class="n">ev_projected</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We can then create a <code class="docutils literal notranslate"><span class="pre">Vertex</span></code> object in <code class="docutils literal notranslate"><span class="pre">pycortex</span></code>, containing the
projected data. This object can be used either in a <code class="docutils literal notranslate"><span class="pre">pycortex</span></code> interactive
3D viewer, or in a <code class="docutils literal notranslate"><span class="pre">matplotlib</span></code> figure showing only the flatmap.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">vertex</span> <span class="o">=</span> <span class="n">cortex</span><span class="o">.</span><span class="n">Vertex</span><span class="p">(</span><span class="n">ev_projected</span><span class="p">,</span> <span class="n">surface</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;viridis&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>To start an interactive 3D viewer in the browser, we can use the <code class="docutils literal notranslate"><span class="pre">webshow</span></code>
function in pycortex. (Note that this method works only if you are running the
notebooks locally.) You can start an interactive 3D viewer by changing
<code class="docutils literal notranslate"><span class="pre">run_webshow</span></code> to <code class="docutils literal notranslate"><span class="pre">True</span></code> and running the following cell.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">run_webshow</span> <span class="o">=</span> <span class="kc">False</span>
<span class="k">if</span> <span class="n">run_webshow</span><span class="p">:</span>
    <span class="n">cortex</span><span class="o">.</span><span class="n">webshow</span><span class="p">(</span><span class="n">vertex</span><span class="p">,</span> <span class="n">open_browser</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">port</span><span class="o">=</span><span class="mi">8050</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Alternatively, to plot a flatmap in a <code class="docutils literal notranslate"><span class="pre">matplotlib</span></code> figure, use the
<code class="docutils literal notranslate"><span class="pre">quickshow</span></code> function.</p>
<p>(This function requires Inkscape to be installed. The rest of the tutorial
does not use this function, so feel free to ignore.)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">cortex.testing_utils</span> <span class="kn">import</span> <span class="n">has_installed</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">cortex</span><span class="o">.</span><span class="n">quickshow</span><span class="p">(</span><span class="n">vertex</span><span class="p">,</span> <span class="n">colorbar_location</span><span class="o">=</span><span class="s1">&#39;right&#39;</span><span class="p">,</span>
                       <span class="n">with_rois</span><span class="o">=</span><span class="n">has_installed</span><span class="p">(</span><span class="s2">&quot;inkscape&quot;</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="id31">
<h2>References<a class="headerlink" href="#id31" title="Link to this heading">#</a></h2>
<div class="docutils container" id="id32">
<div role="list" class="citation-list">
<div class="citation" id="id47" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>DlTENEG22<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id111">1</a>,<a role="doc-backlink" href="#id139">2</a>,<a role="doc-backlink" href="#id145">3</a>)</span>
<p>T. Dupré la Tour, M. Eickenberg, A.O. Nunez-Elizalde, and J. L. Gallant. Feature-space selection with banded ridge regression. <em>NeuroImage</em>, 267:119728, 2022. <a class="reference external" href="https://doi.org/10.1016/j.neuroimage.2022.119728">doi:10.1016/j.neuroimage.2022.119728</a>.</p>
</div>
<div class="citation" id="id57" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>HTF09<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id61">1</a>,<a role="doc-backlink" href="#id62">2</a>)</span>
<p>Trevor Hastie, Robert Tibshirani, and Jerome Friedman. <em>The Elements of Statistical Learning</em>. Springer New York, 2009.</p>
</div>
<div class="citation" id="id54" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id29">HBT04</a><span class="fn-bracket">]</span></span>
<p>A. Hsu, A. Borst, and F. E. Theunissen. Quantifying variability in neural responses and its application for the validation of model predictions. <em>Network</em>, 2004.</p>
</div>
<div class="citation" id="id49" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id2">HNV+22</a><span class="fn-bracket">]</span></span>
<p>A. G. Huth, S. Nishimoto, A. T. Vu, T. Dupré la Tour, and J. L. Gallant. Gallant lab natural short clips 3t fMRI data. 2022. <a class="reference external" href="https://doi.org/10.12751/g-node.vy1zjd">doi:10.12751/g-node.vy1zjd</a>.</p>
</div>
<div class="citation" id="id36" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>HNVG12<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id1">1</a>,<a role="doc-backlink" href="#id58">2</a>,<a role="doc-backlink" href="#id60">3</a>,<a role="doc-backlink" href="#id64">4</a>,<a role="doc-backlink" href="#id65">5</a>,<a role="doc-backlink" href="#id66">6</a>,<a role="doc-backlink" href="#id67">7</a>,<a role="doc-backlink" href="#id68">8</a>,<a role="doc-backlink" href="#id69">9</a>,<a role="doc-backlink" href="#id70">10</a>)</span>
<p>A. G. Huth, S. Nishimoto, A. T. Vu, and J. L. Gallant. A continuous semantic space describes the representation of thousands of object and action categories across the human brain. <em>Neuron</em>, 76(6):1210–1224, 2012.</p>
</div>
<div class="citation" id="id35" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>NVN+11<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id103">1</a>,<a role="doc-backlink" href="#id104">2</a>,<a role="doc-backlink" href="#id110">3</a>)</span>
<p>S. Nishimoto, A. T. Vu, T. Naselaris, Y. Benjamini, B. Yu, and J. L. Gallant. Reconstructing visual experiences from brain activity evoked by natural movies. <em>Current Biology</em>, 21(19):1641–1646, 2011.</p>
</div>
<div class="citation" id="id44" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>NEHG19<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id111">1</a>,<a role="doc-backlink" href="#id139">2</a>,<a role="doc-backlink" href="#id145">3</a>)</span>
<p>A. O. Nunez-Elizalde, A. G. Huth, and J. L. Gallant. Voxelwise encoding models with non-spherical multivariate normal priors. <em>Neuroimage</em>, 197:482–492, 2019.</p>
</div>
<div class="citation" id="id53" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id29">SL02</a><span class="fn-bracket">]</span></span>
<p>M. Sahani and J. Linden. How linear are auditory cortical responses? <em>Adv. Neural Inf. Process. Syst.</em>, 2002.</p>
</div>
<div class="citation" id="id56" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id63">SGV98</a><span class="fn-bracket">]</span></span>
<p>C. Saunders, A. Gammerman, and V. Vovk. Ridge regression learning algorithm in dual variables. 1998.</p>
</div>
<div class="citation" id="id55" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id29">SHW+16</a><span class="fn-bracket">]</span></span>
<p>O. Schoppe, N. S. Harper, B. Willmore, A. King, and J. Schnupp. Measuring the performance of neural models. <em>Front. Comput. Neurosci.</em>, 2016.</p>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">reset</span> -f
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="understand-ridge-regression-and-hyperparameter-selection">
<h1>Understand ridge regression and hyperparameter selection<a class="headerlink" href="#understand-ridge-regression-and-hyperparameter-selection" title="Link to this heading">#</a></h1>
<p>In future examples, we will model the fMRI responses using a regularized linear
regression known as <em>ridge regression</em>. This example explains why we use ridge
regression, and how to use cross-validation to select the appropriate
regularization hyperparameter.</p>
<p>Linear regression is a method to model the relation between some input
variables <span class="math notranslate nohighlight">\(X \in \mathbb{R}^{(n \times p)}\)</span> (the features) and an output
variable <span class="math notranslate nohighlight">\(y \in \mathbb{R}^{n}\)</span> (the target). Specifically, linear
regression uses a vector of coefficient <span class="math notranslate nohighlight">\(w \in \mathbb{R}^{p}\)</span> to
predict the output</p>
<div class="amsmath math notranslate nohighlight" id="equation-95de89db-3d40-43c7-9563-331d5e92f3ad">
<span class="eqno">()<a class="headerlink" href="#equation-95de89db-3d40-43c7-9563-331d5e92f3ad" title="Permalink to this equation">#</a></span>\[\begin{align}\hat{y} = Xw\end{align}\]</div>
<p>The model is considered accurate if the predictions <span class="math notranslate nohighlight">\(\hat{y}\)</span> are close
to the true output values <span class="math notranslate nohighlight">\(y\)</span>. Therefore,  a good linear regression model
is given by the vector <span class="math notranslate nohighlight">\(w\)</span> that minimizes the sum of squared errors:</p>
<div class="amsmath math notranslate nohighlight" id="equation-3bf0ed20-b586-444b-8a2a-52ab095ed3cf">
<span class="eqno">()<a class="headerlink" href="#equation-3bf0ed20-b586-444b-8a2a-52ab095ed3cf" title="Permalink to this equation">#</a></span>\[\begin{align}w = \arg\min_w ||Xw - y||^2\end{align}\]</div>
<p>This is the simplest model for linear regression, and it is known as <em>ordinary
least squares</em> (OLS).</p>
<section id="ordinary-least-squares-ols">
<h2>Ordinary least squares (OLS)<a class="headerlink" href="#ordinary-least-squares-ols" title="Link to this heading">#</a></h2>
<p>To illustrate OLS, let’s use a toy dataset with a single features <code class="docutils literal notranslate"><span class="pre">X[:,0]</span></code>.
On the plot below (left panel), each dot is a sample <code class="docutils literal notranslate"><span class="pre">(X[i,0],</span> <span class="pre">y[i])</span></code>, and
the linear regression model is the line <code class="docutils literal notranslate"><span class="pre">y</span> <span class="pre">=</span> <span class="pre">X[:,0]</span> <span class="pre">*</span> <span class="pre">w[0]</span></code>. On each
sample, the error between the prediction and the true value is shown by a
gray line. By summing the squared errors over all samples, we get the squared
loss. Plotting the squared loss for every value of <code class="docutils literal notranslate"><span class="pre">w</span></code> leads to a parabola
(right panel).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">voxelwise_tutorials.regression_toy</span> <span class="kn">import</span> <span class="n">create_regression_toy</span>
<span class="kn">from</span> <span class="nn">voxelwise_tutorials.regression_toy</span> <span class="kn">import</span> <span class="n">plot_1d</span>

<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">create_regression_toy</span><span class="p">(</span><span class="n">n_features</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">plot_1d</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">w</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>By varying the linear coefficient <code class="docutils literal notranslate"><span class="pre">w</span></code>, we can change the prediction
accuracy of the model, and thus the squared loss.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_1d</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">w</span><span class="o">=</span><span class="p">[</span><span class="mf">0.2</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_1d</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">w</span><span class="o">=</span><span class="p">[</span><span class="mf">0.7</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>The linear coefficient leading to the minimum squared loss can be found
analytically with the formula:</p>
<div class="amsmath math notranslate nohighlight" id="equation-7bab5d9f-cfa5-41a3-9e22-54c75720deb7">
<span class="eqno">()<a class="headerlink" href="#equation-7bab5d9f-cfa5-41a3-9e22-54c75720deb7" title="Permalink to this equation">#</a></span>\[\begin{align}w = (X^\top X)^{-1}  X^\top y\end{align}\]</div>
<p>This is the OLS solution.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">w_ols</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">X</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">y</span><span class="p">)</span>

<span class="n">plot_1d</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">w</span><span class="o">=</span><span class="n">w_ols</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Linear regression can also be used on more than one feature. On the next toy
dataset, we will use two features <code class="docutils literal notranslate"><span class="pre">X[:,0]</span></code> and <code class="docutils literal notranslate"><span class="pre">X[:,1]</span></code>. The linear
regression model is a now plane. Here again, summing the squared errors over
all samples gives the squared loss.Plotting the squared loss for every value
of <code class="docutils literal notranslate"><span class="pre">w[0]</span></code> and <code class="docutils literal notranslate"><span class="pre">w[1]</span></code> leads to a 2D parabola (right panel).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">voxelwise_tutorials.regression_toy</span> <span class="kn">import</span> <span class="n">create_regression_toy</span>
<span class="kn">from</span> <span class="nn">voxelwise_tutorials.regression_toy</span> <span class="kn">import</span> <span class="n">plot_2d</span>

<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">create_regression_toy</span><span class="p">(</span><span class="n">n_features</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="n">plot_2d</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">w</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">show_noiseless</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_2d</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">w</span><span class="o">=</span><span class="p">[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">show_noiseless</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_2d</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">w</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">],</span> <span class="n">show_noiseless</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Here again, the OLS solution can be found analytically with the same formula.
Note that the OLS solution is not equal to the ground-truth coefficients used
to generate the toy dataset (black cross), because we added some noise to the
target values <code class="docutils literal notranslate"><span class="pre">y</span></code>. We want the solution we find to be as close as possible
to the ground-truth coefficients, because it will allow the regression to
generalize correctly to new data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">w_ols</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">X</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">y</span><span class="p">)</span>
<span class="n">plot_2d</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">w</span><span class="o">=</span><span class="n">w_ols</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The situation becomes more interesting when the features in <code class="docutils literal notranslate"><span class="pre">X</span></code> are
correlated. Here, we add a correlation between the first feature <code class="docutils literal notranslate"><span class="pre">X[:,</span> <span class="pre">0]</span></code>
and the second feature <code class="docutils literal notranslate"><span class="pre">X[:,</span> <span class="pre">1]</span></code>. With this correlation, the squared loss
function is no more isotropic, so the lines of equal loss are now ellipses
instead of circles. Thus, when starting from the OLS solution, moving <code class="docutils literal notranslate"><span class="pre">w</span></code>
toward the top left leads to a small change in the loss, whereas moving it
toward the top right leads to a large change in the loss. This anisotropy
makes the OLS solution less robust to noise in some particular directions
(deviating more from the ground-truth coefficients).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">create_regression_toy</span><span class="p">(</span><span class="n">n_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">correlation</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>

<span class="n">w_ols</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">X</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">y</span><span class="p">)</span>
<span class="n">plot_2d</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">w</span><span class="o">=</span><span class="n">w_ols</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The different robustness to noise can be understood mathematically by the
fact that the OLS solution requires inverting the matrix <span class="math notranslate nohighlight">\((X^T X)\)</span>. The
matrix inversion amounts to inverting the eigenvalues <span class="math notranslate nohighlight">\(\lambda_k\)</span> of
the matrix. When the features are highly correlated, some eigenvalues
<span class="math notranslate nohighlight">\(\lambda_k\)</span> are close to zero, and a small change in the features can
have a large effect on the inverse. Thus, having small eigenvalues reduces
the stability of the inversion. If the correlation is even higher, the
smallest eigenvalues get closer to zero, and the OLS solution becomes even
less stable.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">create_regression_toy</span><span class="p">(</span><span class="n">n_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">correlation</span><span class="o">=</span><span class="mf">0.999</span><span class="p">)</span>

<span class="n">w_ols</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">X</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">y</span><span class="p">)</span>
<span class="n">plot_2d</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">w</span><span class="o">=</span><span class="n">w_ols</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The instability can become even more pronounced with larger number of
features, or with smaller numbers of samples.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">create_regression_toy</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">n_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">correlation</span><span class="o">=</span><span class="mf">0.999</span><span class="p">)</span>

<span class="n">w_ols</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">X</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">y</span><span class="p">)</span>
<span class="n">plot_2d</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">w</span><span class="o">=</span><span class="n">w_ols</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>When the number of features is larger than the number of samples, the linear
system becomes under-determined, which means that the OLS problem has an
infinite number of solutions, most of which do not generalize well to new
data.</p>
</section>
<section id="ridge-regression">
<h2>Ridge regression<a class="headerlink" href="#ridge-regression" title="Link to this heading">#</a></h2>
<p>To solve the instability and under-determinacy issues of OLS, OLS can be
extended to <em>ridge regression</em>. Ridge regression considers a different
optimization problem:</p>
<div class="amsmath math notranslate nohighlight" id="equation-d621041e-3592-4f0d-bf87-0a713814e426">
<span class="eqno">()<a class="headerlink" href="#equation-d621041e-3592-4f0d-bf87-0a713814e426" title="Permalink to this equation">#</a></span>\[\begin{align}w = \arg\min_w ||Xw - y||^2 + \alpha ||w||^2\end{align}\]</div>
<p>This optimization problem contains two terms: (i) a <em>data-fitting term</em>
<span class="math notranslate nohighlight">\(||Xw - y||^2\)</span>, which ensures the regression correctly fits the
training data; and (ii) a regularization term <span class="math notranslate nohighlight">\(\alpha||w||^2\)</span>, which
forces the coefficients <span class="math notranslate nohighlight">\(w\)</span> to be close to zero. The regularization
term increases the stability of the solution, at the cost of a bias toward
zero.</p>
<p>In the regularization term, <code class="docutils literal notranslate"><span class="pre">alpha</span></code> is a positive hyperparameter that
controls the regularization strength. With a smaller <code class="docutils literal notranslate"><span class="pre">alpha</span></code>, the solution
will be closer to the OLS solution, and with a larger <code class="docutils literal notranslate"><span class="pre">alpha</span></code>, the solution
will be further from the OLS solution and closer to the origin.</p>
<p>To illustrate this effect, the following plot shows the ridge solution for a
particular value of <code class="docutils literal notranslate"><span class="pre">alpha</span></code>. The black circle corresponds to the line of
equal regularization, whereas the blue ellipses are the lines of equal
squared loss.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">create_regression_toy</span><span class="p">(</span><span class="n">n_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">correlation</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>

<span class="n">alpha</span> <span class="o">=</span> <span class="mi">23</span>
<span class="n">w_ridge</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">X</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">*</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">y</span><span class="p">)</span>
<span class="n">plot_2d</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">w_ridge</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>To understand why the regularization term makes the solution more robust to
noise, let’s consider the ridge solution. The ridge solution can be found
analytically with the formula:</p>
<div class="amsmath math notranslate nohighlight" id="equation-5a9b9598-6592-4ed5-9685-3d7ed2ec5667">
<span class="eqno">()<a class="headerlink" href="#equation-5a9b9598-6592-4ed5-9685-3d7ed2ec5667" title="Permalink to this equation">#</a></span>\[\begin{align}w = (X^\top X + \alpha I)^{-1}  X^\top y\end{align}\]</div>
<p>where <code class="docutils literal notranslate"><span class="pre">I</span></code> is the identity matrix. In this formula, we can see that the
inverted matrix is now <span class="math notranslate nohighlight">\((X^\top X + \alpha I)\)</span>. Compared to OLS, the
additional term <span class="math notranslate nohighlight">\(\alpha I\)</span> adds a positive value <code class="docutils literal notranslate"><span class="pre">alpha</span></code> to all
eigenvalues <span class="math notranslate nohighlight">\(\lambda_k\)</span> of <span class="math notranslate nohighlight">\((X^\top X)\)</span> before the matrix
inversion. Inverting <span class="math notranslate nohighlight">\((\lambda_k + \alpha)\)</span> instead of
<span class="math notranslate nohighlight">\(\lambda_k\)</span> reduces the instability caused by small eigenvalues. This
explains why the ridge solution is more robust to noise than the OLS
solution.</p>
<p>In the following plots, we can see that even with a stronger correlation, the
ridge solution is still reasonably close to the noiseless ground truth, while
the OLS solution would be far off.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">create_regression_toy</span><span class="p">(</span><span class="n">n_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">correlation</span><span class="o">=</span><span class="mf">0.999</span><span class="p">)</span>

<span class="n">alpha</span> <span class="o">=</span> <span class="mi">23</span>
<span class="n">w_ridge</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">X</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">*</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">y</span><span class="p">)</span>
<span class="n">plot_2d</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">w_ridge</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Changing the regularization hyperparameter <span class="math notranslate nohighlight">\(\alpha\)</span> leads to another
ridge solution.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">create_regression_toy</span><span class="p">(</span><span class="n">n_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">correlation</span><span class="o">=</span><span class="mf">0.999</span><span class="p">)</span>

<span class="n">alpha</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">w_ridge</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">X</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">*</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">y</span><span class="p">)</span>
<span class="n">plot_2d</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">w_ridge</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Side note: For every <span class="math notranslate nohighlight">\(\alpha\)</span>, at the corresponding ridge solution, the
line of equal regularization and the line of equal loss are tangent. If the
two lines were crossing, one could improve the ridge solution by moving along
one line. It would improve one term while keeping the other term constant.</p>
</section>
<section id="hyperparameter-selection">
<h2>Hyperparameter selection<a class="headerlink" href="#hyperparameter-selection" title="Link to this heading">#</a></h2>
<p>One issue with ridge regression is that the hyperparameter <span class="math notranslate nohighlight">\(\alpha\)</span> is
arbitrary. Different choices of hyperparameter lead to different models. To
compare these models, we cannot compare the ability to fit the training data,
because the best model would just be OLS (<span class="math notranslate nohighlight">\(alpha = 0\)</span>). Instead, we
want to compare the ability of each model to generalize to new data. To
estimate a model ability to generalize, we can compute its prediction
accuracy on a separate dataset that was not used during the model fitting
(i.e. not used to find the coefficients <span class="math notranslate nohighlight">\(w\)</span>).</p>
<p>To illustrate this idea, we can split the data into two subsets.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">voxelwise_tutorials.regression_toy</span> <span class="kn">import</span> <span class="n">create_regression_toy</span>
<span class="kn">from</span> <span class="nn">voxelwise_tutorials.regression_toy</span> <span class="kn">import</span> <span class="n">plot_kfold2</span>

<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">create_regression_toy</span><span class="p">(</span><span class="n">n_features</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">plot_kfold2</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">fit</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Then, we can fit a model on each subset.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">plot_kfold2</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">fit</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>And compute the prediction accuracy of each model on the other subset.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_kfold2</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">fit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">flip</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>In this way, we can evaluate the ridge regression (fit with a specific
<span class="math notranslate nohighlight">\(\alpha\)</span>) on its ability to generalize to new data. If we do that for
different hyperparameter candidates <span class="math notranslate nohighlight">\(\alpha\)</span>, we can select the model
leading to the best out-of-set prediction accuracy.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">voxelwise_tutorials.regression_toy</span> <span class="kn">import</span> <span class="n">plot_cv_path</span>

<span class="n">noise</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">create_regression_toy</span><span class="p">(</span><span class="n">n_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="n">noise</span><span class="p">)</span>
<span class="n">plot_cv_path</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>In the example above, the noise level is low, so the best hyperparameter
alpha is close to zero, and ridge regression is not much better than OLS.
However, if the dataset has more noise, a lower number of samples, or more
correlated features, the best hyperparameter can be higher. In this case,
ridge regression is better than OLS.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">noise</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">create_regression_toy</span><span class="p">(</span><span class="n">n_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="n">noise</span><span class="p">)</span>
<span class="n">plot_cv_path</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>When the noise level is too high, the best hyperparameter can be the largest
on the grid. It either means that the grid is too small, or that the
regression does not find a predictive link between the features and the
target. In this case, the model with the lowest generalization error always
predict zero (<span class="math notranslate nohighlight">\(w=0\)</span>).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">noise</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">create_regression_toy</span><span class="p">(</span><span class="n">n_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="n">noise</span><span class="p">)</span>
<span class="n">plot_cv_path</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>To summarize, to select the best hyperparameter <span class="math notranslate nohighlight">\(\alpha\)</span>, the standard
method is to perform a grid search:</p>
<ul class="simple">
<li><p>Split the training set into two subsets: one subset used to fit the
models, and one subset to estimate the prediction accuracy (<em>validation
set</em>)</p></li>
<li><p>Define a number of hyperparameter candidates, for example [0.1, 1, 10,
100].</p></li>
<li><p>Fit a separate ridge model with each hyperparameter candidate
<span class="math notranslate nohighlight">\(\alpha\)</span>.</p></li>
<li><p>Compute the prediction accuracy on the validation set.</p></li>
<li><p>Select the hyperparameter candidate leading to the best validation
accuracy.</p></li>
</ul>
<p>To make the grid search less sensitive to the choice of how the training data
was split, the process can be repeated for multiple splits. Then, the
different prediction accuracies can be averaged over splits before the
hyperparameter selection. Thus, the process is called a <em>cross-validation</em>.</p>
<p>Learn more about hyperparameter selection and cross-validation on the
<a class="reference external" href="https://scikit-learn.org/stable/modules/cross_validation.html">scikit-learn documentation</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">reset</span> -f
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="fit-a-voxelwise-encoding-model-with-wordnet-features">
<h1>Fit a voxelwise encoding model with WordNet features<a class="headerlink" href="#fit-a-voxelwise-encoding-model-with-wordnet-features" title="Link to this heading">#</a></h1>
<p>In this example, we model the fMRI responses with semantic “wordnet” features,
manually annotated on each frame of the movie stimulus. The model is a
regularized linear regression model, known as ridge regression. Since this
model is used to predict brain activity from the stimulus, it is called a
(voxelwise) encoding model.</p>
<p>This example reproduces part of the analysis described in <span id="id58">Huth <em>et al.</em> [<a class="reference internal" href="../../pages/voxelwise_modeling.html#id14" title="A. G. Huth, S. Nishimoto, A. T. Vu, and J. L. Gallant. A continuous semantic space describes the representation of thousands of object and action categories across the human brain. Neuron, 76(6):1210–1224, 2012.">2012</a>]</span>. See the original publication for more details about the experiment, the wordnet
features, along with more results and more discussions.</p>
<p><em>WordNet features:</em> The features used in this example are semantic labels
manually annotated on each frame of the movie stimulus. The semantic labels
include nouns (such as “woman”, “car”, or “building”) and verbs (such as
“talking”, “touching”, or “walking”), for a total of 1705 distinct category
labels. To interpret our model, labels can be organized in a graph of semantic
relationship based on the <a class="reference external" href="https://wordnet.princeton.edu/">WordNet</a> dataset.</p>
<p><em>Summary:</em> We first concatenate the features with multiple temporal delays to
account for the slow hemodynamic response. We then use linear regression to fit
a predictive model of brain activity. The linear regression is regularized to
improve robustness to correlated features and to improve generalization
performance. The optimal regularization hyperparameter is selected over a
grid-search with cross-validation. Finally, the model generalization
performance is evaluated on a held-out test set, comparing the model
predictions to the corresponding ground-truth fMRI responses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>It should take less than 5 minutes to run the model fitting in this tutorial on a GPU. If you are using a CPU, it may take longer.</p>
</div>
<section id="id59">
<h2>Path of the data directory<a class="headerlink" href="#id59" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">voxelwise_tutorials.io</span> <span class="kn">import</span> <span class="n">get_data_home</span>
<span class="n">directory</span> <span class="o">=</span> <span class="n">get_data_home</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="s2">&quot;shortclips&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">directory</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># modify to use another subject</span>
<span class="n">subject</span> <span class="o">=</span> <span class="s2">&quot;S01&quot;</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="load-the-data">
<h2>Load the data<a class="headerlink" href="#load-the-data" title="Link to this heading">#</a></h2>
<p>We first load the fMRI responses. These responses have been preprocessed as
described in <span id="id60">Huth <em>et al.</em> [<a class="reference internal" href="../../pages/voxelwise_modeling.html#id14" title="A. G. Huth, S. Nishimoto, A. T. Vu, and J. L. Gallant. A continuous semantic space describes the representation of thousands of object and action categories across the human brain. Neuron, 76(6):1210–1224, 2012.">2012</a>]</span>. The data is separated into a training set <code class="docutils literal notranslate"><span class="pre">Y_train</span></code> and a
testing set <code class="docutils literal notranslate"><span class="pre">Y_test</span></code>. The training set is used for fitting models, and
selecting the best models and hyperparameters. The test set is later used
to estimate the generalization performance of the selected model. The
test set contains multiple repetitions of the same experiment to estimate
an upper bound of the model prediction accuracy (cf. previous example).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">voxelwise_tutorials.io</span> <span class="kn">import</span> <span class="n">load_hdf5_array</span>

<span class="n">file_name</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">directory</span><span class="p">,</span> <span class="s2">&quot;responses&quot;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">subject</span><span class="si">}</span><span class="s2">_responses.hdf&quot;</span><span class="p">)</span>
<span class="n">Y_train</span> <span class="o">=</span> <span class="n">load_hdf5_array</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="s2">&quot;Y_train&quot;</span><span class="p">)</span>
<span class="n">Y_test</span> <span class="o">=</span> <span class="n">load_hdf5_array</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="s2">&quot;Y_test&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;(n_samples_train, n_voxels) =&quot;</span><span class="p">,</span> <span class="n">Y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;(n_repeats, n_samples_test, n_voxels) =&quot;</span><span class="p">,</span> <span class="n">Y_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Before fitting an encoding model, the fMRI responses are typically z-scored over time. This normalization step is performed for two reasons.
First, the regularized regression methods used to estimate encoding models generally assume the data to be normalized <span id="id61">[<a class="reference internal" href="vem_tutorials_merged_for_colab_model_fitting.html#id167" title="Trevor Hastie, Robert Tibshirani, and Jerome Friedman. The Elements of Statistical Learning. Springer New York, 2009.">Hastie <em>et al.</em>, 2009</a>]</span>.
Second, the temporal mean and standard deviation of a voxel are typically considered uninformative in fMRI because they can vary due to factors unrelated to the task, such as differences in signal-to-noise ratio (SNR).</p>
<p>To preserve each run independent from the others, we z-score each run separately.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">zscore</span>
<span class="kn">from</span> <span class="nn">voxelwise_tutorials.utils</span> <span class="kn">import</span> <span class="n">zscore_runs</span>

<span class="c1"># indice of first sample of each run</span>
<span class="n">run_onsets</span> <span class="o">=</span> <span class="n">load_hdf5_array</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="s2">&quot;run_onsets&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">run_onsets</span><span class="p">)</span>

<span class="c1"># zscore each training run separately</span>
<span class="n">Y_train</span> <span class="o">=</span> <span class="n">zscore_runs</span><span class="p">(</span><span class="n">Y_train</span><span class="p">,</span> <span class="n">run_onsets</span><span class="p">)</span>
<span class="c1"># zscore each test run separately</span>
<span class="n">Y_test</span> <span class="o">=</span> <span class="n">zscore</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>If we repeat an experiment multiple times, part of the fMRI responses might
change. However the modeling features do not change over the repeats, so the
voxelwise encoding model will predict the same signal for each repeat. To
have an upper bound of the model prediction accuracy, we keep only the
repeatable part of the signal by averaging the test repeats.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Y_test</span> <span class="o">=</span> <span class="n">Y_test</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="c1"># We need to zscore the test data again, because we took the mean across repetitions.</span>
<span class="n">Y_test</span> <span class="o">=</span> <span class="n">zscore</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;(n_samples_test, n_voxels) =&quot;</span><span class="p">,</span> <span class="n">Y_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We fill potential NaN (not-a-number) values with zeros.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Y_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan_to_num</span><span class="p">(</span><span class="n">Y_train</span><span class="p">)</span>
<span class="n">Y_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan_to_num</span><span class="p">(</span><span class="n">Y_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Then, we load the semantic “wordnet” features, extracted from the stimulus at
each time point. The features corresponding to the training set are noted
<code class="docutils literal notranslate"><span class="pre">X_train</span></code>, and the features corresponding to the test set are noted
<code class="docutils literal notranslate"><span class="pre">X_test</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">feature_space</span> <span class="o">=</span> <span class="s2">&quot;wordnet&quot;</span>

<span class="n">file_name</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">directory</span><span class="p">,</span> <span class="s2">&quot;features&quot;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">feature_space</span><span class="si">}</span><span class="s2">.hdf&quot;</span><span class="p">)</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">load_hdf5_array</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="s2">&quot;X_train&quot;</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">load_hdf5_array</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="s2">&quot;X_test&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;(n_samples_train, n_features) =&quot;</span><span class="p">,</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;(n_samples_test, n_features) =&quot;</span><span class="p">,</span> <span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="define-the-cross-validation-scheme">
<h2>Define the cross-validation scheme<a class="headerlink" href="#define-the-cross-validation-scheme" title="Link to this heading">#</a></h2>
<p>To select the best hyperparameter through cross-validation, we must define a
cross-validation splitting scheme. Because fMRI time-series are
autocorrelated in time, we should preserve as much as possible the temporal
correlation. In other words, because consecutive time samples are correlated,
we should not put one time sample in the training set and the immediately
following time sample in the validation set. Thus, we define here a
leave-one-run-out cross-validation split that keeps each recording run
intact.</p>
<p>We define a cross-validation splitter, compatible with <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> API.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">check_cv</span>
<span class="kn">from</span> <span class="nn">voxelwise_tutorials.utils</span> <span class="kn">import</span> <span class="n">generate_leave_one_run_out</span>

<span class="n">n_samples_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">cv</span> <span class="o">=</span> <span class="n">generate_leave_one_run_out</span><span class="p">(</span><span class="n">n_samples_train</span><span class="p">,</span> <span class="n">run_onsets</span><span class="p">)</span>
<span class="n">cv</span> <span class="o">=</span> <span class="n">check_cv</span><span class="p">(</span><span class="n">cv</span><span class="p">)</span>  <span class="c1"># copy the cross-validation splitter into a reusable list</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="define-the-model">
<h2>Define the model<a class="headerlink" href="#define-the-model" title="Link to this heading">#</a></h2>
<p>Now, let’s define the model pipeline.</p>
<p>With regularized linear regression models, it is generally recommended to normalize
(z-score) both the responses and the features before fitting the model <span id="id62">[<a class="reference internal" href="vem_tutorials_merged_for_colab_model_fitting.html#id167" title="Trevor Hastie, Robert Tibshirani, and Jerome Friedman. The Elements of Statistical Learning. Springer New York, 2009.">Hastie <em>et al.</em>, 2009</a>]</span>.
Z-scoring corresponds to removing the temporal mean and dividing by the temporal standard deviation.
We already z-scored the fMRI responses after loading them, so now we need to specify
in the model how to deal with the features.</p>
<p>We first center the features, since we will not use an intercept. The mean
value in fMRI recording is non-informative, so each run is detrended and
demeaned independently, and we do not need to predict an intercept value in
the linear model.</p>
<p>For this particular dataset and example, we do not normalize by the standard deviation
of each feature. If the features are extracted in a consistent way from the stimulus,
their relative scale is meaningful. Normalizing them independently from each
other would remove this information. Moreover, the wordnet features are
one-hot-encoded, which means that each feature is either present (1) or not
present (0) in each sample. Normalizing one-hot-encoded features is not
recommended, since it would scale disproportionately the infrequent features.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">(</span><span class="n">with_mean</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">with_std</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Then we concatenate the features with multiple delays to account for the
hemodynamic response. Due to neurovascular coupling, the recorded BOLD signal
is delayed in time with respect to the stimulus onset. With different delayed
versions of the features, the linear regression model will weigh each delayed
feature with a different weight to maximize the predictions. With a sample
every 2 seconds, we typically use 4 delays <code class="docutils literal notranslate"><span class="pre">[1,</span> <span class="pre">2,</span> <span class="pre">3,</span> <span class="pre">4]</span></code> to cover the
hemodynamic response peak. In the next example, we further describe this
hemodynamic response estimation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">voxelwise_tutorials.delayer</span> <span class="kn">import</span> <span class="n">Delayer</span>
<span class="n">delayer</span> <span class="o">=</span> <span class="n">Delayer</span><span class="p">(</span><span class="n">delays</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>Finally, we use a ridge regression model. Ridge regression is a linear
regression with L2 regularization. The L2 regularization improves robustness
to correlated features and improves generalization performance. The L2
regularization is controlled by a hyperparameter <code class="docutils literal notranslate"><span class="pre">alpha</span></code> that needs to be
tuned for each dataset. This regularization hyperparameter is usually
selected over a grid search with cross-validation, selecting the
hyperparameter that maximizes the predictive performances on the validation
set. See the previous example for more details about ridge regression and
hyperparameter selection.</p>
<p>For computational reasons, when the number of features is larger than the
number of samples, it is more efficient to solve ridge regression using the
(equivalent) dual formulation <span id="id63">[<a class="reference internal" href="vem_tutorials_merged_for_colab_model_fitting.html#id166" title="C. Saunders, A. Gammerman, and V. Vovk. Ridge regression learning algorithm in dual variables. 1998.">Saunders <em>et al.</em>, 1998</a>]</span>. This dual formulation is equivalent to
kernel ridge regression with a linear kernel. Here, we have 3600 training
samples, and 1705 * 4 = 6820 features (we multiply by 4 since we use 4 time
delays), therefore it is more efficient to use kernel ridge regression.</p>
<p>With one target, we could directly use the pipeline in <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code>’s
<code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code>, to select the optimal regularization hyperparameter
(<code class="docutils literal notranslate"><span class="pre">alpha</span></code>) over cross-validation. However, <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> can only
optimize a single score across all voxels (targets). Thus, in the
multiple-target case, <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> can only optimize (for example) the
mean score over targets. Here, we want to find a different optimal
hyperparameter per target/voxel, so we use the package <a class="reference external" href="https://github.com/gallantlab/himalaya">himalaya</a> which implements a
<code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> compatible estimator <code class="docutils literal notranslate"><span class="pre">KernelRidgeCV</span></code>, with hyperparameter
selection independently on each target.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">himalaya.kernel_ridge</span> <span class="kn">import</span> <span class="n">KernelRidgeCV</span>
</pre></div>
</div>
</div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">himalaya</span></code> implements different computational backends,
including two backends that use GPU for faster computations. The two
available GPU backends are “torch_cuda” and “cupy”. (Each backend is only
available if you installed the corresponding package with CUDA enabled. Check
the <code class="docutils literal notranslate"><span class="pre">pytorch</span></code>/<code class="docutils literal notranslate"><span class="pre">cupy</span></code> documentation for install instructions.)</p>
<p>Here we use the “torch_cuda” backend, but if the import fails we continue
with the default “numpy” backend. The “numpy” backend is expected to be
slower since it only uses the CPU.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">himalaya.backend</span> <span class="kn">import</span> <span class="n">set_backend</span>
<span class="n">backend</span> <span class="o">=</span> <span class="n">set_backend</span><span class="p">(</span><span class="s2">&quot;torch_cuda&quot;</span><span class="p">,</span> <span class="n">on_error</span><span class="o">=</span><span class="s2">&quot;warn&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">backend</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>To speed up model fitting on GPU, we use single precision float numbers.
(This step probably does not change significantly the performances on non-GPU
backends.)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Since the scale of the regularization hyperparameter <code class="docutils literal notranslate"><span class="pre">alpha</span></code> is unknown, we
use a large logarithmic range, and we will check after the fit that best
hyperparameters are not all on one range edge.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">alphas</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We also indicate some batch sizes to limit the GPU memory.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">kernel_ridge_cv</span> <span class="o">=</span> <span class="n">KernelRidgeCV</span><span class="p">(</span>
    <span class="n">alphas</span><span class="o">=</span><span class="n">alphas</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span>
    <span class="n">solver_params</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">n_targets_batch</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">n_alphas_batch</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                       <span class="n">n_targets_batch_refit</span><span class="o">=</span><span class="mi">100</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>Finally, we use a <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> <code class="docutils literal notranslate"><span class="pre">Pipeline</span></code> to link the different steps
together. A <code class="docutils literal notranslate"><span class="pre">Pipeline</span></code> can be used as a regular estimator, calling
<code class="docutils literal notranslate"><span class="pre">pipeline.fit</span></code>, <code class="docutils literal notranslate"><span class="pre">pipeline.predict</span></code>, etc. Using a <code class="docutils literal notranslate"><span class="pre">Pipeline</span></code> can be
useful to clarify the different steps, avoid cross-validation mistakes, or
automatically cache intermediate results. See the <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code>
<a class="reference external" href="https://scikit-learn.org/stable/modules/compose.html">documentation</a> for
more information.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
    <span class="n">scaler</span><span class="p">,</span>
    <span class="n">delayer</span><span class="p">,</span>
    <span class="n">kernel_ridge_cv</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We can display the <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> pipeline with an HTML diagram.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">set_config</span>
<span class="n">set_config</span><span class="p">(</span><span class="n">display</span><span class="o">=</span><span class="s1">&#39;diagram&#39;</span><span class="p">)</span>  <span class="c1"># requires scikit-learn 0.23</span>
<span class="n">pipeline</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="fit-the-model">
<h2>Fit the model<a class="headerlink" href="#fit-the-model" title="Link to this heading">#</a></h2>
<p>We fit on the training set..</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">_</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>..and score on the test set. Here the scores are the <span class="math notranslate nohighlight">\(R^2\)</span> scores, with
values in <span class="math notranslate nohighlight">\(]-\infty, 1]\)</span>. A value of <span class="math notranslate nohighlight">\(1\)</span> means the predictions
are perfect.</p>
<p>Note that since <code class="docutils literal notranslate"><span class="pre">himalaya</span></code> is implementing multiple-targets
models, the <code class="docutils literal notranslate"><span class="pre">score</span></code> method differs from <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> API and returns
one score per target/voxel.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scores</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;(n_voxels,) =&quot;</span><span class="p">,</span> <span class="n">scores</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>If we fit the model on GPU, scores are returned on GPU using an array object
specific to the backend we used (such as a <code class="docutils literal notranslate"><span class="pre">torch.Tensor</span></code>). Thus, we need to
move them into <code class="docutils literal notranslate"><span class="pre">numpy</span></code> arrays on CPU, to be able to use them for example in
a <code class="docutils literal notranslate"><span class="pre">matplotlib</span></code> figure.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scores</span> <span class="o">=</span> <span class="n">backend</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="plot-the-model-prediction-accuracy">
<h2>Plot the model prediction accuracy<a class="headerlink" href="#plot-the-model-prediction-accuracy" title="Link to this heading">#</a></h2>
<p>To visualize the model prediction accuracy, we can plot it for each voxel on
a flattened surface of the brain. To do so, we use a mapper that is specific
to the each subject’s brain. (Check previous example to see how to use the
mapper to Freesurfer average surface.)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">voxelwise_tutorials.viz</span> <span class="kn">import</span> <span class="n">plot_flatmap_from_mapper</span>

<span class="n">mapper_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">directory</span><span class="p">,</span> <span class="s2">&quot;mappers&quot;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">subject</span><span class="si">}</span><span class="s2">_mappers.hdf&quot;</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">plot_flatmap_from_mapper</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">mapper_file</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mf">0.4</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>We can see that the “wordnet” features successfully predict part of the
measured brain activity, with <span class="math notranslate nohighlight">\(R^2\)</span> scores as high as 0.4. Note that
these scores are generalization scores, since they are computed on a test set
that was not used during model fitting. Since we fitted a model independently
in each voxel, we can inspect the generalization performances at the best
available spatial resolution: individual voxels.</p>
<p>The best-predicted voxels are located in visual semantic areas like EBA, or
FFA. This is expected since the wordnet features encode semantic information
about the visual stimulus. For more discussions about these results, we refer
the reader to the original publication <span id="id64">[<a class="reference internal" href="../../pages/voxelwise_modeling.html#id14" title="A. G. Huth, S. Nishimoto, A. T. Vu, and J. L. Gallant. A continuous semantic space describes the representation of thousands of object and action categories across the human brain. Neuron, 76(6):1210–1224, 2012.">Huth <em>et al.</em>, 2012</a>]</span>.</p>
</section>
<section id="plot-the-selected-hyperparameters">
<h2>Plot the selected hyperparameters<a class="headerlink" href="#plot-the-selected-hyperparameters" title="Link to this heading">#</a></h2>
<p>Since the scale of alphas is unknown, we plot the optimal alphas selected by
the solver over cross-validation. This plot is helpful to refine the alpha
grid if the range is too small or too large.</p>
<p>Note that some voxels might be at the maximum regularization value in the
grid search. These are voxels where the model has no predictive power, thus
the optimal regularization parameter is large to lead to a prediction equal
to zero. We do not need to extend the alpha range for these voxels.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">himalaya.viz</span> <span class="kn">import</span> <span class="n">plot_alphas_diagnostic</span>
<span class="n">best_alphas</span> <span class="o">=</span> <span class="n">backend</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">pipeline</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">best_alphas_</span><span class="p">)</span>
<span class="n">plot_alphas_diagnostic</span><span class="p">(</span><span class="n">best_alphas</span><span class="o">=</span><span class="n">best_alphas</span><span class="p">,</span> <span class="n">alphas</span><span class="o">=</span><span class="n">alphas</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="visualize-the-regression-coefficients">
<h2>Visualize the regression coefficients<a class="headerlink" href="#visualize-the-regression-coefficients" title="Link to this heading">#</a></h2>
<p>Here, we go back to the main model on all voxels. Since our model is linear,
we can use the (primal) regression coefficients to interpret the model. The
basic intuition is that the model will use larger coefficients on features
that have more predictive power.</p>
<p>Since we know the meaning of each feature, we can interpret the large
regression coefficients. In the case of wordnet features, we can even build a
graph that represents the features that are linked by a semantic
relationship.</p>
<p>We first get the (primal) ridge regression coefficients from the fitted
model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">primal_coef</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">get_primal_coef</span><span class="p">()</span>
<span class="n">primal_coef</span> <span class="o">=</span> <span class="n">backend</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">primal_coef</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;(n_delays * n_features, n_voxels) =&quot;</span><span class="p">,</span> <span class="n">primal_coef</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Because the ridge model allows a different regularization per voxel, the
regression coefficients may have very different scales. In turn, these
different scales can introduce a bias in the interpretation, focusing the
attention disproportionately on voxels fitted with the lowest alpha. To
address this issue, we rescale the regression coefficient to have a norm
equal to the square-root of the <span class="math notranslate nohighlight">\(R^2\)</span> scores. We found empirically that
this rescaling best matches results obtained with a regularization shared
across voxels. This rescaling also removes the need to select only best
performing voxels, because voxels with low prediction accuracies are rescaled
to have a low norm.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">primal_coef</span> <span class="o">/=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">primal_coef</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)[</span><span class="kc">None</span><span class="p">]</span>
<span class="n">primal_coef</span> <span class="o">*=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">scores</span><span class="p">))[</span><span class="kc">None</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Then, we aggregate the coefficients across the different delays.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># split the ridge coefficients per delays</span>
<span class="n">delayer</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">named_steps</span><span class="p">[</span><span class="s1">&#39;delayer&#39;</span><span class="p">]</span>
<span class="n">primal_coef_per_delay</span> <span class="o">=</span> <span class="n">delayer</span><span class="o">.</span><span class="n">reshape_by_delays</span><span class="p">(</span><span class="n">primal_coef</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;(n_delays, n_features, n_voxels) =&quot;</span><span class="p">,</span> <span class="n">primal_coef_per_delay</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">del</span> <span class="n">primal_coef</span>

<span class="c1"># average over delays</span>
<span class="n">average_coef</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">primal_coef_per_delay</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;(n_features, n_voxels) =&quot;</span><span class="p">,</span> <span class="n">average_coef</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">del</span> <span class="n">primal_coef_per_delay</span>
</pre></div>
</div>
</div>
</div>
<p>Even after averaging over delays, the coefficient matrix is still too large
to interpret it. Therefore, we use principal component analysis (PCA) to
reduce the dimensionality of the matrix.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>

<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">pca</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">average_coef</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
<span class="n">components</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">components_</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;(n_components, n_features) =&quot;</span><span class="p">,</span> <span class="n">components</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We can check the ratio of explained variance by each principal component.
We see that the first four components already explain a large part of the
coefficients variance.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;PCA explained variance =&quot;</span><span class="p">,</span> <span class="n">pca</span><span class="o">.</span><span class="n">explained_variance_ratio_</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Similarly to <span id="id65">Huth <em>et al.</em> [<a class="reference internal" href="../../pages/voxelwise_modeling.html#id14" title="A. G. Huth, S. Nishimoto, A. T. Vu, and J. L. Gallant. A continuous semantic space describes the representation of thousands of object and action categories across the human brain. Neuron, 76(6):1210–1224, 2012.">2012</a>]</span>, we correct the coefficients of features linked by a
semantic relationship. When building the wordnet features, if a frame was
labeled with <code class="docutils literal notranslate"><span class="pre">wolf</span></code>, the authors automatically added the semantically linked
categories <code class="docutils literal notranslate"><span class="pre">canine</span></code>, <code class="docutils literal notranslate"><span class="pre">carnivore</span></code>, <code class="docutils literal notranslate"><span class="pre">placental</span> <span class="pre">mammal</span></code>, <code class="docutils literal notranslate"><span class="pre">mammal</span></code>, <code class="docutils literal notranslate"><span class="pre">vertebrate</span></code>,
<code class="docutils literal notranslate"><span class="pre">chordate</span></code>, <code class="docutils literal notranslate"><span class="pre">organism</span></code>, and <code class="docutils literal notranslate"><span class="pre">whole</span></code>. The authors thus argue that the same
correction needs to be done on the coefficients.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">voxelwise_tutorials.wordnet</span> <span class="kn">import</span> <span class="n">load_wordnet</span>
<span class="kn">from</span> <span class="nn">voxelwise_tutorials.wordnet</span> <span class="kn">import</span> <span class="n">correct_coefficients</span>
<span class="n">_</span><span class="p">,</span> <span class="n">wordnet_categories</span> <span class="o">=</span> <span class="n">load_wordnet</span><span class="p">(</span><span class="n">directory</span><span class="o">=</span><span class="n">directory</span><span class="p">)</span>
<span class="n">components</span> <span class="o">=</span> <span class="n">correct_coefficients</span><span class="p">(</span><span class="n">components</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">wordnet_categories</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
<span class="n">components</span> <span class="o">-=</span> <span class="n">components</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span>
<span class="n">components</span> <span class="o">/=</span> <span class="n">components</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Finally, we plot the first principal component on the wordnet graph. In such
graph, edges indicate “is a” relationships (e.g. an <code class="docutils literal notranslate"><span class="pre">athlete</span></code> “is a”
<code class="docutils literal notranslate"><span class="pre">person</span></code>). Each marker represents a single noun (circle) or verb (square).
The area of each marker indicates the principal component magnitude, and the
color indicates the sign (red is positive, blue is negative).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">voxelwise_tutorials.wordnet</span> <span class="kn">import</span> <span class="n">plot_wordnet_graph</span>
<span class="kn">from</span> <span class="nn">voxelwise_tutorials.wordnet</span> <span class="kn">import</span> <span class="n">apply_cmap</span>

<span class="n">first_component</span> <span class="o">=</span> <span class="n">components</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">node_sizes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">first_component</span><span class="p">)</span>
<span class="n">node_colors</span> <span class="o">=</span> <span class="n">apply_cmap</span><span class="p">(</span><span class="n">first_component</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=-</span><span class="mi">2</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;coolwarm&#39;</span><span class="p">,</span>
                         <span class="n">n_colors</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="n">plot_wordnet_graph</span><span class="p">(</span><span class="n">node_colors</span><span class="o">=</span><span class="n">node_colors</span><span class="p">,</span> <span class="n">node_sizes</span><span class="o">=</span><span class="n">node_sizes</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>According to <span id="id66">Huth <em>et al.</em> [<a class="reference internal" href="../../pages/voxelwise_modeling.html#id14" title="A. G. Huth, S. Nishimoto, A. T. Vu, and J. L. Gallant. A continuous semantic space describes the representation of thousands of object and action categories across the human brain. Neuron, 76(6):1210–1224, 2012.">2012</a>]</span>, “this principal component distinguishes
between categories with high stimulus energy (e.g. moving objects like
<code class="docutils literal notranslate"><span class="pre">person</span></code> and <code class="docutils literal notranslate"><span class="pre">vehicle</span></code>) and those with low stimulus energy (e.g. stationary
objects like <code class="docutils literal notranslate"><span class="pre">sky</span></code> and <code class="docutils literal notranslate"><span class="pre">city</span></code>)”.</p>
<p>In this example, because we use only a single subject and we perform a
different voxel selection, our result is slightly different than in the
original publication. We also use a different regularization parameter in
each voxel, while in <span id="id67">Huth <em>et al.</em> [<a class="reference internal" href="../../pages/voxelwise_modeling.html#id14" title="A. G. Huth, S. Nishimoto, A. T. Vu, and J. L. Gallant. A continuous semantic space describes the representation of thousands of object and action categories across the human brain. Neuron, 76(6):1210–1224, 2012.">2012</a>]</span> all voxels had the same regularization parameter.
However, we do not aim at reproducing exactly the results of the original
publication, but we rather describe the general approach.</p>
<p>To project the principal component on the cortical surface, we first need to
use the fitted PCA to transform the primal weights of all voxels.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># transform with the fitted PCA</span>
<span class="n">average_coef_transformed</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">average_coef</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;(n_components, n_voxels) =&quot;</span><span class="p">,</span> <span class="n">average_coef_transformed</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">del</span> <span class="n">average_coef</span>

<span class="c1"># We make sure vmin = -vmax, so that the colormap is centered on 0.</span>
<span class="n">vmax</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">average_coef_transformed</span><span class="p">),</span> <span class="mf">99.9</span><span class="p">)</span>

<span class="c1"># plot the primal weights projected on the first principal component.</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">plot_flatmap_from_mapper</span><span class="p">(</span><span class="n">average_coef_transformed</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">mapper_file</span><span class="p">,</span>
                              <span class="n">vmin</span><span class="o">=-</span><span class="n">vmax</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="n">vmax</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;coolwarm&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>This flatmap shows in which brain regions the model has the largest
projection on the first component. Again, this result is different from the
one in <span id="id68">Huth <em>et al.</em> [<a class="reference internal" href="../../pages/voxelwise_modeling.html#id14" title="A. G. Huth, S. Nishimoto, A. T. Vu, and J. L. Gallant. A continuous semantic space describes the representation of thousands of object and action categories across the human brain. Neuron, 76(6):1210–1224, 2012.">2012</a>]</span>, and should only be considered as reproducing the general
approach.</p>
<p>Following the analyses in the original publication, we also plot the next three principal components on the
wordnet graph, mapping the three vectors to RGB colors.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">voxelwise_tutorials.wordnet</span> <span class="kn">import</span> <span class="n">scale_to_rgb_cube</span>

<span class="n">next_three_components</span> <span class="o">=</span> <span class="n">components</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">T</span>
<span class="n">node_sizes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">next_three_components</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">node_colors</span> <span class="o">=</span> <span class="n">scale_to_rgb_cube</span><span class="p">(</span><span class="n">next_three_components</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;(n_nodes, n_channels) =&quot;</span><span class="p">,</span> <span class="n">node_colors</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">plot_wordnet_graph</span><span class="p">(</span><span class="n">node_colors</span><span class="o">=</span><span class="n">node_colors</span><span class="p">,</span> <span class="n">node_sizes</span><span class="o">=</span><span class="n">node_sizes</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>According to <span id="id69">Huth <em>et al.</em> [<a class="reference internal" href="../../pages/voxelwise_modeling.html#id14" title="A. G. Huth, S. Nishimoto, A. T. Vu, and J. L. Gallant. A continuous semantic space describes the representation of thousands of object and action categories across the human brain. Neuron, 76(6):1210–1224, 2012.">2012</a>]</span>, “this graph shows that categories thought
to be semantically related (e.g. athletes and walking) are represented
similarly in the brain”.</p>
<p>Finally, we project these principal components on the cortical surface.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">voxelwise_tutorials.viz</span> <span class="kn">import</span> <span class="n">plot_3d_flatmap_from_mapper</span>

<span class="n">voxel_colors</span> <span class="o">=</span> <span class="n">scale_to_rgb_cube</span><span class="p">(</span><span class="n">average_coef_transformed</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">clip</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;(n_channels, n_voxels) =&quot;</span><span class="p">,</span> <span class="n">voxel_colors</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">plot_3d_flatmap_from_mapper</span><span class="p">(</span>
    <span class="n">voxel_colors</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">voxel_colors</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">voxel_colors</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> 
    <span class="n">mapper_file</span><span class="o">=</span><span class="n">mapper_file</span><span class="p">,</span> 
    <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">vmin2</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">vmax2</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">vmin3</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">vmax3</span><span class="o">=</span><span class="mi">1</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Again, our results are different from the ones in <span id="id70">Huth <em>et al.</em> [<a class="reference internal" href="../../pages/voxelwise_modeling.html#id14" title="A. G. Huth, S. Nishimoto, A. T. Vu, and J. L. Gallant. A continuous semantic space describes the representation of thousands of object and action categories across the human brain. Neuron, 76(6):1210–1224, 2012.">2012</a>]</span>, for the same reasons
mentioned earlier.</p>
</section>
<section id="id71">
<h2>References<a class="headerlink" href="#id71" title="Link to this heading">#</a></h2>
<div class="docutils container" id="id72">
<div role="list" class="citation-list">
<div class="citation" id="id87" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>DlTENEG22<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id111">1</a>,<a role="doc-backlink" href="#id139">2</a>,<a role="doc-backlink" href="#id145">3</a>)</span>
<p>T. Dupré la Tour, M. Eickenberg, A.O. Nunez-Elizalde, and J. L. Gallant. Feature-space selection with banded ridge regression. <em>NeuroImage</em>, 267:119728, 2022. <a class="reference external" href="https://doi.org/10.1016/j.neuroimage.2022.119728">doi:10.1016/j.neuroimage.2022.119728</a>.</p>
</div>
<div class="citation" id="id97" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>HTF09<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id61">1</a>,<a role="doc-backlink" href="#id62">2</a>)</span>
<p>Trevor Hastie, Robert Tibshirani, and Jerome Friedman. <em>The Elements of Statistical Learning</em>. Springer New York, 2009.</p>
</div>
<div class="citation" id="id94" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id29">HBT04</a><span class="fn-bracket">]</span></span>
<p>A. Hsu, A. Borst, and F. E. Theunissen. Quantifying variability in neural responses and its application for the validation of model predictions. <em>Network</em>, 2004.</p>
</div>
<div class="citation" id="id89" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id2">HNV+22</a><span class="fn-bracket">]</span></span>
<p>A. G. Huth, S. Nishimoto, A. T. Vu, T. Dupré la Tour, and J. L. Gallant. Gallant lab natural short clips 3t fMRI data. 2022. <a class="reference external" href="https://doi.org/10.12751/g-node.vy1zjd">doi:10.12751/g-node.vy1zjd</a>.</p>
</div>
<div class="citation" id="id76" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>HNVG12<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id1">1</a>,<a role="doc-backlink" href="#id58">2</a>,<a role="doc-backlink" href="#id60">3</a>,<a role="doc-backlink" href="#id64">4</a>,<a role="doc-backlink" href="#id65">5</a>,<a role="doc-backlink" href="#id66">6</a>,<a role="doc-backlink" href="#id67">7</a>,<a role="doc-backlink" href="#id68">8</a>,<a role="doc-backlink" href="#id69">9</a>,<a role="doc-backlink" href="#id70">10</a>)</span>
<p>A. G. Huth, S. Nishimoto, A. T. Vu, and J. L. Gallant. A continuous semantic space describes the representation of thousands of object and action categories across the human brain. <em>Neuron</em>, 76(6):1210–1224, 2012.</p>
</div>
<div class="citation" id="id75" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>NVN+11<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id103">1</a>,<a role="doc-backlink" href="#id104">2</a>,<a role="doc-backlink" href="#id110">3</a>)</span>
<p>S. Nishimoto, A. T. Vu, T. Naselaris, Y. Benjamini, B. Yu, and J. L. Gallant. Reconstructing visual experiences from brain activity evoked by natural movies. <em>Current Biology</em>, 21(19):1641–1646, 2011.</p>
</div>
<div class="citation" id="id84" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>NEHG19<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id111">1</a>,<a role="doc-backlink" href="#id139">2</a>,<a role="doc-backlink" href="#id145">3</a>)</span>
<p>A. O. Nunez-Elizalde, A. G. Huth, and J. L. Gallant. Voxelwise encoding models with non-spherical multivariate normal priors. <em>Neuroimage</em>, 197:482–492, 2019.</p>
</div>
<div class="citation" id="id93" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id29">SL02</a><span class="fn-bracket">]</span></span>
<p>M. Sahani and J. Linden. How linear are auditory cortical responses? <em>Adv. Neural Inf. Process. Syst.</em>, 2002.</p>
</div>
<div class="citation" id="id96" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id63">SGV98</a><span class="fn-bracket">]</span></span>
<p>C. Saunders, A. Gammerman, and V. Vovk. Ridge regression learning algorithm in dual variables. 1998.</p>
</div>
<div class="citation" id="id95" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id29">SHW+16</a><span class="fn-bracket">]</span></span>
<p>O. Schoppe, N. S. Harper, B. Willmore, A. King, and J. Schnupp. Measuring the performance of neural models. <em>Front. Comput. Neurosci.</em>, 2016.</p>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">reset</span> -f
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="visualize-the-hemodynamic-response">
<h1>Visualize the hemodynamic response<a class="headerlink" href="#visualize-the-hemodynamic-response" title="Link to this heading">#</a></h1>
<p>In this example, we describe how the hemodynamic response function was
estimated in the previous model. We fit the same ridge model as in the previous
example, and further describe the need to delay the features in time to account
for the delayed BOLD response.</p>
<p>Because of the temporal dynamics of neurovascular coupling, the recorded BOLD
signal is delayed in time with respect to the stimulus. To account for this
lag, we fit encoding models on delayed features. In this way, the linear
regression model weighs each delayed feature separately and recovers the shape
of the hemodynamic response function in each voxel separately. In turn, this
method (also known as a Finite Impulse Response model, or FIR) maximizes the
model prediction accuracy. With a repetition time of 2 seconds, we typically
use 4 delays <code class="docutils literal notranslate"><span class="pre">[1,</span> <span class="pre">2,</span> <span class="pre">3,</span> <span class="pre">4]</span></code> to cover the peak of the the hemodynamic response
function. However, the optimal number of delays can vary depending on the
experiment and the brain area of interest, so you should experiment with
different delays.</p>
<p>In this example, we show that a model without delays performs far worse than a
model with delays. We also show how to visualize the estimated hemodynamic
response function (HRF) from a model with delays.</p>
<section id="id98">
<h2>Path of the data directory<a class="headerlink" href="#id98" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">voxelwise_tutorials.io</span> <span class="kn">import</span> <span class="n">get_data_home</span>

<span class="n">directory</span> <span class="o">=</span> <span class="n">get_data_home</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="s2">&quot;shortclips&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">directory</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># modify to use another subject</span>
<span class="n">subject</span> <span class="o">=</span> <span class="s2">&quot;S01&quot;</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="id99">
<h2>Load the data<a class="headerlink" href="#id99" title="Link to this heading">#</a></h2>
<p>We first load and normalize the fMRI responses.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">zscore</span>
<span class="kn">from</span> <span class="nn">voxelwise_tutorials.io</span> <span class="kn">import</span> <span class="n">load_hdf5_array</span>
<span class="kn">from</span> <span class="nn">voxelwise_tutorials.utils</span> <span class="kn">import</span> <span class="n">zscore_runs</span>

<span class="n">file_name</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">directory</span><span class="p">,</span> <span class="s2">&quot;responses&quot;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">subject</span><span class="si">}</span><span class="s2">_responses.hdf&quot;</span><span class="p">)</span>
<span class="n">Y_train</span> <span class="o">=</span> <span class="n">load_hdf5_array</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="s2">&quot;Y_train&quot;</span><span class="p">)</span>
<span class="n">Y_test</span> <span class="o">=</span> <span class="n">load_hdf5_array</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="s2">&quot;Y_test&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;(n_samples_train, n_voxels) =&quot;</span><span class="p">,</span> <span class="n">Y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;(n_repeats, n_samples_test, n_voxels) =&quot;</span><span class="p">,</span> <span class="n">Y_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># indice of first sample of each run</span>
<span class="n">run_onsets</span> <span class="o">=</span> <span class="n">load_hdf5_array</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="s2">&quot;run_onsets&quot;</span><span class="p">)</span>

<span class="c1"># zscore each training run separately</span>
<span class="n">Y_train</span> <span class="o">=</span> <span class="n">zscore_runs</span><span class="p">(</span><span class="n">Y_train</span><span class="p">,</span> <span class="n">run_onsets</span><span class="p">)</span>
<span class="c1"># zscore each test run separately</span>
<span class="n">Y_test</span> <span class="o">=</span> <span class="n">zscore</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We average the test repeats, to remove the non-repeatable part of fMRI
responses, and normalize the average across repeats.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Y_test</span> <span class="o">=</span> <span class="n">Y_test</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">Y_test</span> <span class="o">=</span> <span class="n">zscore</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;(n_samples_test, n_voxels) =&quot;</span><span class="p">,</span> <span class="n">Y_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We fill potential NaN (not-a-number) values with zeros.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Y_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan_to_num</span><span class="p">(</span><span class="n">Y_train</span><span class="p">)</span>
<span class="n">Y_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan_to_num</span><span class="p">(</span><span class="n">Y_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Then, we load the semantic “wordnet” features.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">feature_space</span> <span class="o">=</span> <span class="s2">&quot;wordnet&quot;</span>

<span class="n">file_name</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">directory</span><span class="p">,</span> <span class="s2">&quot;features&quot;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">feature_space</span><span class="si">}</span><span class="s2">.hdf&quot;</span><span class="p">)</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">load_hdf5_array</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="s2">&quot;X_train&quot;</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">load_hdf5_array</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="s2">&quot;X_test&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;(n_samples_train, n_features) =&quot;</span><span class="p">,</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;(n_samples_test, n_features) =&quot;</span><span class="p">,</span> <span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="id100">
<h2>Define the cross-validation scheme<a class="headerlink" href="#id100" title="Link to this heading">#</a></h2>
<p>We define the same leave-one-run-out cross-validation split as in the
previous example.</p>
<p>We define a cross-validation splitter, compatible with <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> API.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">check_cv</span>
<span class="kn">from</span> <span class="nn">voxelwise_tutorials.utils</span> <span class="kn">import</span> <span class="n">generate_leave_one_run_out</span>

<span class="n">n_samples_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">cv</span> <span class="o">=</span> <span class="n">generate_leave_one_run_out</span><span class="p">(</span><span class="n">n_samples_train</span><span class="p">,</span> <span class="n">run_onsets</span><span class="p">)</span>
<span class="n">cv</span> <span class="o">=</span> <span class="n">check_cv</span><span class="p">(</span><span class="n">cv</span><span class="p">)</span>  <span class="c1"># copy the cross-validation splitter into a reusable list</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="id101">
<h2>Define the model<a class="headerlink" href="#id101" title="Link to this heading">#</a></h2>
<p>We define the same model as in the previous example. See the previous
example for more details about the model definition.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">voxelwise_tutorials.delayer</span> <span class="kn">import</span> <span class="n">Delayer</span>
<span class="kn">from</span> <span class="nn">himalaya.kernel_ridge</span> <span class="kn">import</span> <span class="n">KernelRidgeCV</span>
<span class="kn">from</span> <span class="nn">himalaya.ridge</span> <span class="kn">import</span> <span class="n">RidgeCV</span>
<span class="kn">from</span> <span class="nn">himalaya.backend</span> <span class="kn">import</span> <span class="n">set_backend</span>

<span class="n">backend</span> <span class="o">=</span> <span class="n">set_backend</span><span class="p">(</span><span class="s2">&quot;torch_cuda&quot;</span><span class="p">,</span> <span class="n">on_error</span><span class="o">=</span><span class="s2">&quot;warn&quot;</span><span class="p">)</span>

<span class="n">X_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>

<span class="n">alphas</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
    <span class="n">StandardScaler</span><span class="p">(</span><span class="n">with_mean</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">with_std</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
    <span class="n">Delayer</span><span class="p">(</span><span class="n">delays</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]),</span>
    <span class="n">KernelRidgeCV</span><span class="p">(</span>
        <span class="n">alphas</span><span class="o">=</span><span class="n">alphas</span><span class="p">,</span>
        <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span>
        <span class="n">solver_params</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
            <span class="n">n_targets_batch</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">n_alphas_batch</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_targets_batch_refit</span><span class="o">=</span><span class="mi">100</span>
        <span class="p">),</span>
    <span class="p">),</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">set_config</span>

<span class="n">set_config</span><span class="p">(</span><span class="n">display</span><span class="o">=</span><span class="s2">&quot;diagram&quot;</span><span class="p">)</span>  <span class="c1"># requires scikit-learn 0.23</span>
<span class="n">pipeline</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="id102">
<h2>Fit the model<a class="headerlink" href="#id102" title="Link to this heading">#</a></h2>
<p>We fit on the train set, and score on the test set.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>

<span class="n">scores</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">)</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">backend</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;(n_voxels,) =&quot;</span><span class="p">,</span> <span class="n">scores</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="understanding-delays">
<h2>Understanding delays<a class="headerlink" href="#understanding-delays" title="Link to this heading">#</a></h2>
<p>To have an intuitive understanding of what we accomplish by delaying the
features before model fitting, we will simulate one voxel and a single
feature. We will then create a <code class="docutils literal notranslate"><span class="pre">Delayer</span></code> object (which was used in the
previous pipeline) and visualize its effect on our single feature.</p>
<p>Let’s start by simulating the data. We assume a simple scenario in which an event in
our experiment occurred at <span class="math notranslate nohighlight">\(t = 20\)</span> seconds and lasted for 10 seconds. For each timepoint, our simulated feature
is a simple variable that indicates whether the event occurred or not.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">voxelwise_tutorials.delays_toy</span> <span class="kn">import</span> <span class="n">create_voxel_data</span>

<span class="c1"># simulate an activation pulse at 20 s for 10 s of duration</span>
<span class="n">simulated_X</span><span class="p">,</span> <span class="n">simulated_Y</span><span class="p">,</span> <span class="n">times</span> <span class="o">=</span> <span class="n">create_voxel_data</span><span class="p">(</span><span class="n">onset</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">duration</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We next plot the simulated data. In this toy example, we assumed a “canonical”
hemodynamic response function (HRF) (a double gamma function). This is an idealized
HRF that is often used in the literature to model the BOLD response. In practice,
however, the HRF can vary significantly across brain areas.</p>
<p>Because of the HRF, notice that even though the event occurred at <span class="math notranslate nohighlight">\(t = 20\)</span> seconds,
the BOLD response is delayed in time.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">voxelwise_tutorials.delays_toy</span> <span class="kn">import</span> <span class="n">plot_delays_toy</span>

<span class="n">plot_delays_toy</span><span class="p">(</span><span class="n">simulated_X</span><span class="p">,</span> <span class="n">simulated_Y</span><span class="p">,</span> <span class="n">times</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>We next create a <code class="docutils literal notranslate"><span class="pre">Delayer</span></code> object and use it to delay the simulated feature.
The effect of the delayer is clear: it creates multiple
copies of the original feature shifted forward in time by how many samples we
requested (in this case, from 0 to 4 samples, which correspond to 0, 2, 4, 6,
and 8 s in time with a 2 s TR).</p>
<p>When these delayed features are used to fit a voxelwise encoding model, the
brain response <span class="math notranslate nohighlight">\(y\)</span> at time <span class="math notranslate nohighlight">\(t\)</span> is simultaneously modeled by the
feature <span class="math notranslate nohighlight">\(x\)</span> at times <span class="math notranslate nohighlight">\(t-0, t-2, t-4, t-6, t-8\)</span>. For example, the time sample highlighted
in the plot below (<span class="math notranslate nohighlight">\(t = 30\)</span> seconds) is modeled by the features at
<span class="math notranslate nohighlight">\(t = 30, 28, 26, 24, 22\)</span> seconds.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># create a delayer object and delay the features</span>
<span class="n">delayer</span> <span class="o">=</span> <span class="n">Delayer</span><span class="p">(</span><span class="n">delays</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="n">simulated_X_delayed</span> <span class="o">=</span> <span class="n">delayer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">simulated_X</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">])</span>

<span class="c1"># plot the simulated data and highlight t = 30</span>
<span class="n">plot_delays_toy</span><span class="p">(</span><span class="n">simulated_X_delayed</span><span class="p">,</span> <span class="n">simulated_Y</span><span class="p">,</span> <span class="n">times</span><span class="p">,</span> <span class="n">highlight</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>This simple example shows how the delayed features take into account of the HRF.
This approach is often referred to as a “finite impulse response” (FIR) model.
By delaying the features, the regression model learns the weights for each voxel
separately. Therefore, the FIR approach is able to adapt to the shape of the HRF in each
voxel, without assuming a fixed canonical HRF shape.
As we will see in the remaining of this notebook, this approach improves model
prediction accuracy significantly.</p>
</section>
<section id="compare-with-a-model-without-delays">
<h2>Compare with a model without delays<a class="headerlink" href="#compare-with-a-model-without-delays" title="Link to this heading">#</a></h2>
<p>We define here another model without feature delays (i.e. no <code class="docutils literal notranslate"><span class="pre">Delayer</span></code>).
Because the BOLD signal is inherently slow due to the dynamics of
neuro-vascular coupling, this model is unlikely to perform well.</p>
<p>Note that if we remove the feature delays, we will have more fMRI samples
(3600) than number of features (1705). In this case, running a kernel version
of ridge regression is computationally suboptimal. Thus, to create a model
without delays we are using <code class="docutils literal notranslate"><span class="pre">RidgeCV</span></code> instead of <code class="docutils literal notranslate"><span class="pre">KernelRidgeCV</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pipeline_no_delay</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
    <span class="n">StandardScaler</span><span class="p">(</span><span class="n">with_mean</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">with_std</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
    <span class="n">RidgeCV</span><span class="p">(</span>
        <span class="n">alphas</span><span class="o">=</span><span class="n">alphas</span><span class="p">,</span>
        <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span>
        <span class="n">solver</span><span class="o">=</span><span class="s2">&quot;svd&quot;</span><span class="p">,</span>
        <span class="n">solver_params</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
            <span class="n">n_targets_batch</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">n_alphas_batch</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_targets_batch_refit</span><span class="o">=</span><span class="mi">100</span>
        <span class="p">),</span>
    <span class="p">),</span>
<span class="p">)</span>
<span class="n">pipeline_no_delay</span>
</pre></div>
</div>
</div>
</div>
<p>We fit and score the model as the previous one.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pipeline_no_delay</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>
<span class="n">scores_no_delay</span> <span class="o">=</span> <span class="n">pipeline_no_delay</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">)</span>
<span class="n">scores_no_delay</span> <span class="o">=</span> <span class="n">backend</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">scores_no_delay</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;(n_voxels,) =&quot;</span><span class="p">,</span> <span class="n">scores_no_delay</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Then, we plot the comparison of model prediction accuracies with a 2D
histogram. All ~70k voxels are represented in this histogram, where the
diagonal corresponds to identical prediction accuracy for both models. A
distribution deviating from the diagonal means that one model has better
prediction accuracy than the other.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">voxelwise_tutorials.viz</span> <span class="kn">import</span> <span class="n">plot_hist2d</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">plot_hist2d</span><span class="p">(</span><span class="n">scores_no_delay</span><span class="p">,</span> <span class="n">scores</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span>
    <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Generalization R2 scores&quot;</span><span class="p">,</span>
    <span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;model without delays&quot;</span><span class="p">,</span>
    <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;model with delays&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>We see that the model with delays performs much better than the model without
delays. This can be seen in voxels with scores above 0. The distribution
of scores below zero is not very informative, since it corresponds to voxels
with poor predictive performance anyway, and it only shows which model is
overfitting the most.</p>
</section>
<section id="visualize-the-hrf">
<h2>Visualize the HRF<a class="headerlink" href="#visualize-the-hrf" title="Link to this heading">#</a></h2>
<p>We just saw that delays are necessary to model BOLD responses. Here we show
how the fitted ridge regression weights follow the hemodynamic response
function (HRF).</p>
<p>Fitting a kernel ridge regression results in a set of coefficients called the
“dual” coefficients <span class="math notranslate nohighlight">\(w\)</span>. These coefficients differ from the “primal”
coefficients <span class="math notranslate nohighlight">\(\beta\)</span> obtained with a ridge regression, but the primal
coefficients can be computed from the dual coefficients using the training
features <span class="math notranslate nohighlight">\(X\)</span>:</p>
<div class="amsmath math notranslate nohighlight" id="equation-39563ad7-7612-485a-9726-89521fdc5be5">
<span class="eqno">()<a class="headerlink" href="#equation-39563ad7-7612-485a-9726-89521fdc5be5" title="Permalink to this equation">#</a></span>\[\begin{align}\beta = X^\top w\end{align}\]</div>
<p>To better visualize the HRF, we will refit a model with more delays, but only
on a selection of voxels to speed up the computations.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># pick the 10 best voxels</span>
<span class="n">voxel_selection</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">scores</span><span class="p">)[</span><span class="o">-</span><span class="mi">10</span><span class="p">:]</span>

<span class="c1"># define a pipeline with more delays</span>
<span class="n">pipeline_more_delays</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
    <span class="n">StandardScaler</span><span class="p">(</span><span class="n">with_mean</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">with_std</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
    <span class="n">Delayer</span><span class="p">(</span><span class="n">delays</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]),</span>
    <span class="n">KernelRidgeCV</span><span class="p">(</span>
        <span class="n">alphas</span><span class="o">=</span><span class="n">alphas</span><span class="p">,</span>
        <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span>
        <span class="n">solver_params</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
            <span class="n">n_targets_batch</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">n_alphas_batch</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_targets_batch_refit</span><span class="o">=</span><span class="mi">100</span>
        <span class="p">),</span>
    <span class="p">),</span>
<span class="p">)</span>

<span class="n">pipeline_more_delays</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">[:,</span> <span class="n">voxel_selection</span><span class="p">])</span>

<span class="c1"># get the (primal) ridge regression coefficients</span>
<span class="n">primal_coef</span> <span class="o">=</span> <span class="n">pipeline_more_delays</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">get_primal_coef</span><span class="p">()</span>
<span class="n">primal_coef</span> <span class="o">=</span> <span class="n">backend</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">primal_coef</span><span class="p">)</span>

<span class="c1"># split the ridge coefficients per delays</span>
<span class="n">delayer</span> <span class="o">=</span> <span class="n">pipeline_more_delays</span><span class="o">.</span><span class="n">named_steps</span><span class="p">[</span><span class="s2">&quot;delayer&quot;</span><span class="p">]</span>
<span class="n">primal_coef_per_delay</span> <span class="o">=</span> <span class="n">delayer</span><span class="o">.</span><span class="n">reshape_by_delays</span><span class="p">(</span><span class="n">primal_coef</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;(n_delays, n_features, n_voxels) =&quot;</span><span class="p">,</span> <span class="n">primal_coef_per_delay</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># select the feature with the largest coefficients for each voxel</span>
<span class="n">feature_selection</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">primal_coef_per_delay</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">primal_coef_selection</span> <span class="o">=</span> <span class="n">primal_coef_per_delay</span><span class="p">[</span>
    <span class="p">:,</span> <span class="n">feature_selection</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">voxel_selection</span><span class="p">))</span>
<span class="p">]</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">delayer</span><span class="o">.</span><span class="n">delays</span><span class="p">,</span> <span class="n">primal_coef_selection</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Delays&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">delayer</span><span class="o">.</span><span class="n">delays</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Ridge coefficients&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Largest feature for the </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">voxel_selection</span><span class="p">)</span><span class="si">}</span><span class="s2"> best voxels&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>We see that the hemodynamic response function (HRF) is captured in the model
weights. Note that in this dataset, the brain responses are recorded every
two seconds.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">reset</span> -f
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="fit-a-voxelwise-encoding-model-with-motion-energy-features">
<h1>Fit a voxelwise encoding model with motion-energy features<a class="headerlink" href="#fit-a-voxelwise-encoding-model-with-motion-energy-features" title="Link to this heading">#</a></h1>
<p>In this example, we model the fMRI responses with motion-energy features
extracted from the movie stimulus. The model is a regularized linear regression
model.</p>
<p>This tutorial reproduces part of the analysis described in <span id="id103">Nishimoto <em>et al.</em> [<a class="reference internal" href="../../pages/voxelwise_modeling.html#id13" title="S. Nishimoto, A. T. Vu, T. Naselaris, Y. Benjamini, B. Yu, and J. L. Gallant. Reconstructing visual experiences from brain activity evoked by natural movies. Current Biology, 21(19):1641–1646, 2011.">2011</a>]</span>. See the original publication for more details about the experiment, the
motion-energy features, along with more results and more discussions.</p>
<p><em>Motion-energy features:</em> Motion-energy features result from filtering a video
stimulus with spatio-temporal Gabor filters. A pyramid of filters is used to
compute the motion-energy features at multiple spatial and temporal scales.
Motion-energy features were introduced in <span id="id104">Nishimoto <em>et al.</em> [<a class="reference internal" href="../../pages/voxelwise_modeling.html#id13" title="S. Nishimoto, A. T. Vu, T. Naselaris, Y. Benjamini, B. Yu, and J. L. Gallant. Reconstructing visual experiences from brain activity evoked by natural movies. Current Biology, 21(19):1641–1646, 2011.">2011</a>]</span>. The downloaded
dataset contains the pre-computed motion-energy features for the movie stimulus used
in the experiment. You can see how to extract these motion-energy features in the
<a class="reference internal" href="07_extract_motion_energy.html"><span class="std std-doc">Extract motion-energy features</span></a> tutorial.</p>
<p><em>Summary:</em> As in the previous example, we first concatenate the features with
multiple delays, to account for the slow hemodynamic response. A linear
regression model then weights each delayed feature with a different weight, to
build a predictive model of BOLD activity. Again, the linear regression is
regularized to improve robustness to correlated features and to improve
generalization. The optimal regularization hyperparameter is selected
independently on each voxel over a grid-search with cross-validation. Finally,
the model generalization performance is evaluated on a held-out test set,
comparing the model predictions with the ground-truth fMRI responses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>It should take less than 5 minutes to run the model fitting in this tutorial on a GPU. If you are using a CPU, it may take longer.</p>
</div>
<section id="id105">
<h2>Path of the data directory<a class="headerlink" href="#id105" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">voxelwise_tutorials.io</span> <span class="kn">import</span> <span class="n">get_data_home</span>
<span class="n">directory</span> <span class="o">=</span> <span class="n">get_data_home</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="s2">&quot;shortclips&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">directory</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># modify to use another subject</span>
<span class="n">subject</span> <span class="o">=</span> <span class="s2">&quot;S01&quot;</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="id106">
<h2>Load the data<a class="headerlink" href="#id106" title="Link to this heading">#</a></h2>
<p>We first load and normalize the fMRI responses.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">zscore</span>
<span class="kn">from</span> <span class="nn">voxelwise_tutorials.io</span> <span class="kn">import</span> <span class="n">load_hdf5_array</span>
<span class="kn">from</span> <span class="nn">voxelwise_tutorials.utils</span> <span class="kn">import</span> <span class="n">zscore_runs</span>

<span class="n">file_name</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">directory</span><span class="p">,</span> <span class="s2">&quot;responses&quot;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">subject</span><span class="si">}</span><span class="s2">_responses.hdf&quot;</span><span class="p">)</span>
<span class="n">Y_train</span> <span class="o">=</span> <span class="n">load_hdf5_array</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="s2">&quot;Y_train&quot;</span><span class="p">)</span>
<span class="n">Y_test</span> <span class="o">=</span> <span class="n">load_hdf5_array</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="s2">&quot;Y_test&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;(n_samples_train, n_voxels) =&quot;</span><span class="p">,</span> <span class="n">Y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;(n_repeats, n_samples_test, n_voxels) =&quot;</span><span class="p">,</span> <span class="n">Y_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># indice of first sample of each run</span>
<span class="n">run_onsets</span> <span class="o">=</span> <span class="n">load_hdf5_array</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="s2">&quot;run_onsets&quot;</span><span class="p">)</span>

<span class="c1"># zscore each training run separately</span>
<span class="n">Y_train</span> <span class="o">=</span> <span class="n">zscore_runs</span><span class="p">(</span><span class="n">Y_train</span><span class="p">,</span> <span class="n">run_onsets</span><span class="p">)</span>
<span class="c1"># zscore each test run separately</span>
<span class="n">Y_test</span> <span class="o">=</span> <span class="n">zscore</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We average the test repeats, to remove the non-repeatable part of fMRI
responses, and normalize the average across repeats.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Y_test</span> <span class="o">=</span> <span class="n">Y_test</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">Y_test</span> <span class="o">=</span> <span class="n">zscore</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;(n_samples_test, n_voxels) =&quot;</span><span class="p">,</span> <span class="n">Y_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We fill potential NaN (not-a-number) values with zeros.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Y_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan_to_num</span><span class="p">(</span><span class="n">Y_train</span><span class="p">)</span>
<span class="n">Y_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan_to_num</span><span class="p">(</span><span class="n">Y_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Then we load the precomputed “motion-energy” features.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">feature_space</span> <span class="o">=</span> <span class="s2">&quot;motion_energy&quot;</span>
<span class="n">file_name</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">directory</span><span class="p">,</span> <span class="s2">&quot;features&quot;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">feature_space</span><span class="si">}</span><span class="s2">.hdf&quot;</span><span class="p">)</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">load_hdf5_array</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="s2">&quot;X_train&quot;</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">load_hdf5_array</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="s2">&quot;X_test&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;(n_samples_train, n_features) =&quot;</span><span class="p">,</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;(n_samples_test, n_features) =&quot;</span><span class="p">,</span> <span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="id107">
<h2>Define the cross-validation scheme<a class="headerlink" href="#id107" title="Link to this heading">#</a></h2>
<p>We define the same leave-one-run-out cross-validation split as in the
previous example.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">check_cv</span>
<span class="kn">from</span> <span class="nn">voxelwise_tutorials.utils</span> <span class="kn">import</span> <span class="n">generate_leave_one_run_out</span>

<span class="c1"># indice of first sample of each run</span>
<span class="n">run_onsets</span> <span class="o">=</span> <span class="n">load_hdf5_array</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="s2">&quot;run_onsets&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">run_onsets</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We define a cross-validation splitter, compatible with <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> API.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_samples_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">cv</span> <span class="o">=</span> <span class="n">generate_leave_one_run_out</span><span class="p">(</span><span class="n">n_samples_train</span><span class="p">,</span> <span class="n">run_onsets</span><span class="p">)</span>
<span class="n">cv</span> <span class="o">=</span> <span class="n">check_cv</span><span class="p">(</span><span class="n">cv</span><span class="p">)</span>  <span class="c1"># copy the cross-validation splitter into a reusable list</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="id108">
<h2>Define the model<a class="headerlink" href="#id108" title="Link to this heading">#</a></h2>
<p>We define the same model as in the previous example. See the previous
example for more details about the model definition.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">voxelwise_tutorials.delayer</span> <span class="kn">import</span> <span class="n">Delayer</span>
<span class="kn">from</span> <span class="nn">himalaya.kernel_ridge</span> <span class="kn">import</span> <span class="n">KernelRidgeCV</span>
<span class="kn">from</span> <span class="nn">himalaya.backend</span> <span class="kn">import</span> <span class="n">set_backend</span>
<span class="n">backend</span> <span class="o">=</span> <span class="n">set_backend</span><span class="p">(</span><span class="s2">&quot;torch_cuda&quot;</span><span class="p">,</span> <span class="n">on_error</span><span class="o">=</span><span class="s2">&quot;warn&quot;</span><span class="p">)</span>

<span class="n">X_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>

<span class="n">alphas</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
    <span class="n">StandardScaler</span><span class="p">(</span><span class="n">with_mean</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">with_std</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
    <span class="n">Delayer</span><span class="p">(</span><span class="n">delays</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]),</span>
    <span class="n">KernelRidgeCV</span><span class="p">(</span>
        <span class="n">alphas</span><span class="o">=</span><span class="n">alphas</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span>
        <span class="n">solver_params</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">n_targets_batch</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">n_alphas_batch</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                           <span class="n">n_targets_batch_refit</span><span class="o">=</span><span class="mi">100</span><span class="p">)),</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">set_config</span>
<span class="n">set_config</span><span class="p">(</span><span class="n">display</span><span class="o">=</span><span class="s1">&#39;diagram&#39;</span><span class="p">)</span>  <span class="c1"># requires scikit-learn 0.23</span>
<span class="n">pipeline</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="id109">
<h2>Fit the model<a class="headerlink" href="#id109" title="Link to this heading">#</a></h2>
<p>We fit on the train set, and score on the test set.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>

<span class="n">scores_motion_energy</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">)</span>
<span class="n">scores_motion_energy</span> <span class="o">=</span> <span class="n">backend</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">scores_motion_energy</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;(n_voxels,) =&quot;</span><span class="p">,</span> <span class="n">scores_motion_energy</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="plot-the-model-performances">
<h2>Plot the model performances<a class="headerlink" href="#plot-the-model-performances" title="Link to this heading">#</a></h2>
<p>The performances are computed using the <span class="math notranslate nohighlight">\(R^2\)</span> scores.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">voxelwise_tutorials.viz</span> <span class="kn">import</span> <span class="n">plot_flatmap_from_mapper</span>

<span class="n">mapper_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">directory</span><span class="p">,</span> <span class="s2">&quot;mappers&quot;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">subject</span><span class="si">}</span><span class="s2">_mappers.hdf&quot;</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">plot_flatmap_from_mapper</span><span class="p">(</span><span class="n">scores_motion_energy</span><span class="p">,</span> <span class="n">mapper_file</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                              <span class="n">vmax</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>The motion-energy features lead to large generalization scores in the
early visual cortex (V1, V2, V3, …). For more discussions about these
results, we refer the reader to the original publication <span id="id110">[<a class="reference internal" href="../../pages/voxelwise_modeling.html#id13" title="S. Nishimoto, A. T. Vu, T. Naselaris, Y. Benjamini, B. Yu, and J. L. Gallant. Reconstructing visual experiences from brain activity evoked by natural movies. Current Biology, 21(19):1641–1646, 2011.">Nishimoto <em>et al.</em>, 2011</a>]</span>.</p>
</section>
<section id="compare-with-the-wordnet-model">
<h2>Compare with the wordnet model<a class="headerlink" href="#compare-with-the-wordnet-model" title="Link to this heading">#</a></h2>
<p>Interestingly, the motion-energy model performs well in different brain
regions than the semantic “wordnet” model fitted in the previous example. To
compare the two models, we first need to fit again the wordnet model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">feature_space</span> <span class="o">=</span> <span class="s2">&quot;wordnet&quot;</span>
<span class="n">file_name</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">directory</span><span class="p">,</span> <span class="s2">&quot;features&quot;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">feature_space</span><span class="si">}</span><span class="s2">.hdf&quot;</span><span class="p">)</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">load_hdf5_array</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="s2">&quot;X_train&quot;</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">load_hdf5_array</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="s2">&quot;X_test&quot;</span><span class="p">)</span>

<span class="n">X_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We can create an unfitted copy of the pipeline with the <code class="docutils literal notranslate"><span class="pre">clone</span></code> function,
or simply call fit again if we do not need to reuse the previous model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="kc">False</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <span class="n">clone</span>
    <span class="n">pipeline_wordnet</span> <span class="o">=</span> <span class="n">clone</span><span class="p">(</span><span class="n">pipeline</span><span class="p">)</span>
    <span class="n">pipeline_wordnet</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>
<span class="n">scores_wordnet</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">)</span>
<span class="n">scores_wordnet</span> <span class="o">=</span> <span class="n">backend</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">scores_wordnet</span><span class="p">)</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">plot_flatmap_from_mapper</span><span class="p">(</span><span class="n">scores_wordnet</span><span class="p">,</span> <span class="n">mapper_file</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                              <span class="n">vmax</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>We can also plot the comparison of model prediction accuracies with a 2D
histogram. All ~70k voxels are represented in this histogram, where the
diagonal corresponds to identical prediction accuracy for both models. A
distribution deviating from the diagonal means that one model has better
predictive performance than the other.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">voxelwise_tutorials.viz</span> <span class="kn">import</span> <span class="n">plot_hist2d</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">plot_hist2d</span><span class="p">(</span><span class="n">scores_wordnet</span><span class="p">,</span> <span class="n">scores_motion_energy</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s1">&#39;Generalization R2 scores&#39;</span><span class="p">,</span> <span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;semantic wordnet model&#39;</span><span class="p">,</span>
       <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;motion energy model&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Interestingly, the well predicted voxels are different in the two models.
To further describe these differences, we can plot both performances on the
same flatmap, using a 2D colormap.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">voxelwise_tutorials.viz</span> <span class="kn">import</span> <span class="n">plot_2d_flatmap_from_mapper</span>

<span class="n">mapper_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">directory</span><span class="p">,</span> <span class="s2">&quot;mappers&quot;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">subject</span><span class="si">}</span><span class="s2">_mappers.hdf&quot;</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">plot_2d_flatmap_from_mapper</span><span class="p">(</span><span class="n">scores_wordnet</span><span class="p">,</span> <span class="n">scores_motion_energy</span><span class="p">,</span>
                                 <span class="n">mapper_file</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">vmin2</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                                 <span class="n">vmax2</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label_1</span><span class="o">=</span><span class="s2">&quot;wordnet&quot;</span><span class="p">,</span>
                                 <span class="n">label_2</span><span class="o">=</span><span class="s2">&quot;motion energy&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>The blue regions are well predicted by the motion-energy features, the orange
regions are well predicted by the wordnet features, and the white regions are
well predicted by both feature spaces.</p>
<p>A large part of the visual semantic areas are not only well predicted by the
wordnet features, but also by the motion-energy features, as indicated by the
white color. Since these two features spaces encode quite different
information, two interpretations are possible. In the first interpretation,
the two feature spaces encode complementary information, and could be used
jointly to further increase the generalization performance. In the second
interpretation, both feature spaces encode the same information, because of
spurious stimulus correlations. For example, imagine that the visual stimulus
contained faces that appeared consistetly in the same portion of the visual
field. In this case, position in the visual field would be perfectly
correlated with the “face” semantic category. Thus, motion-energy features
could predict responses in face-responsive areas without encoding any
semantic information.</p>
<p>To better disentangle the two feature spaces, we developed a joint model
called <strong>banded ridge regression</strong> <span id="id111">[<a class="reference internal" href="../../pages/voxelwise_modeling.html#id25" title="T. Dupré la Tour, M. Eickenberg, A.O. Nunez-Elizalde, and J. L. Gallant. Feature-space selection with banded ridge regression. NeuroImage, 267:119728, 2022. doi:10.1016/j.neuroimage.2022.119728.">Dupré la Tour <em>et al.</em>, 2022</a>, <a class="reference internal" href="../../pages/voxelwise_modeling.html#id22" title="A. O. Nunez-Elizalde, A. G. Huth, and J. L. Gallant. Voxelwise encoding models with non-spherical multivariate normal priors. Neuroimage, 197:482–492, 2019.">Nunez-Elizalde <em>et al.</em>, 2019</a>]</span>, which fits multiple feature spaces
simultaneously with optimal regularization for each feature space. This model
is described in the next example.</p>
</section>
<section id="id112">
<h2>References<a class="headerlink" href="#id112" title="Link to this heading">#</a></h2>
<div class="docutils container" id="id113">
<div role="list" class="citation-list">
<div class="citation" id="id128" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>DlTENEG22<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id111">1</a>,<a role="doc-backlink" href="#id139">2</a>,<a role="doc-backlink" href="#id145">3</a>)</span>
<p>T. Dupré la Tour, M. Eickenberg, A.O. Nunez-Elizalde, and J. L. Gallant. Feature-space selection with banded ridge regression. <em>NeuroImage</em>, 267:119728, 2022. <a class="reference external" href="https://doi.org/10.1016/j.neuroimage.2022.119728">doi:10.1016/j.neuroimage.2022.119728</a>.</p>
</div>
<div class="citation" id="id138" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>HTF09<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id61">1</a>,<a role="doc-backlink" href="#id62">2</a>)</span>
<p>Trevor Hastie, Robert Tibshirani, and Jerome Friedman. <em>The Elements of Statistical Learning</em>. Springer New York, 2009.</p>
</div>
<div class="citation" id="id135" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id29">HBT04</a><span class="fn-bracket">]</span></span>
<p>A. Hsu, A. Borst, and F. E. Theunissen. Quantifying variability in neural responses and its application for the validation of model predictions. <em>Network</em>, 2004.</p>
</div>
<div class="citation" id="id130" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id2">HNV+22</a><span class="fn-bracket">]</span></span>
<p>A. G. Huth, S. Nishimoto, A. T. Vu, T. Dupré la Tour, and J. L. Gallant. Gallant lab natural short clips 3t fMRI data. 2022. <a class="reference external" href="https://doi.org/10.12751/g-node.vy1zjd">doi:10.12751/g-node.vy1zjd</a>.</p>
</div>
<div class="citation" id="id117" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>HNVG12<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id1">1</a>,<a role="doc-backlink" href="#id58">2</a>,<a role="doc-backlink" href="#id60">3</a>,<a role="doc-backlink" href="#id64">4</a>,<a role="doc-backlink" href="#id65">5</a>,<a role="doc-backlink" href="#id66">6</a>,<a role="doc-backlink" href="#id67">7</a>,<a role="doc-backlink" href="#id68">8</a>,<a role="doc-backlink" href="#id69">9</a>,<a role="doc-backlink" href="#id70">10</a>)</span>
<p>A. G. Huth, S. Nishimoto, A. T. Vu, and J. L. Gallant. A continuous semantic space describes the representation of thousands of object and action categories across the human brain. <em>Neuron</em>, 76(6):1210–1224, 2012.</p>
</div>
<div class="citation" id="id116" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>NVN+11<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id103">1</a>,<a role="doc-backlink" href="#id104">2</a>,<a role="doc-backlink" href="#id110">3</a>)</span>
<p>S. Nishimoto, A. T. Vu, T. Naselaris, Y. Benjamini, B. Yu, and J. L. Gallant. Reconstructing visual experiences from brain activity evoked by natural movies. <em>Current Biology</em>, 21(19):1641–1646, 2011.</p>
</div>
<div class="citation" id="id125" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>NEHG19<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id111">1</a>,<a role="doc-backlink" href="#id139">2</a>,<a role="doc-backlink" href="#id145">3</a>)</span>
<p>A. O. Nunez-Elizalde, A. G. Huth, and J. L. Gallant. Voxelwise encoding models with non-spherical multivariate normal priors. <em>Neuroimage</em>, 197:482–492, 2019.</p>
</div>
<div class="citation" id="id134" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id29">SL02</a><span class="fn-bracket">]</span></span>
<p>M. Sahani and J. Linden. How linear are auditory cortical responses? <em>Adv. Neural Inf. Process. Syst.</em>, 2002.</p>
</div>
<div class="citation" id="id137" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id63">SGV98</a><span class="fn-bracket">]</span></span>
<p>C. Saunders, A. Gammerman, and V. Vovk. Ridge regression learning algorithm in dual variables. 1998.</p>
</div>
<div class="citation" id="id136" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id29">SHW+16</a><span class="fn-bracket">]</span></span>
<p>O. Schoppe, N. S. Harper, B. Willmore, A. King, and J. Schnupp. Measuring the performance of neural models. <em>Front. Comput. Neurosci.</em>, 2016.</p>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">reset</span> -f
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="fit-a-voxelwise-encoding-model-with-both-wordnet-and-motion-energy-features">
<h1>Fit a voxelwise encoding model with both WordNet and motion-energy features<a class="headerlink" href="#fit-a-voxelwise-encoding-model-with-both-wordnet-and-motion-energy-features" title="Link to this heading">#</a></h1>
<p>In this example, we model the fMRI responses with a <em>banded ridge regression</em>
with two different feature spaces: motion energy and wordnet categories.</p>
<p><em>Banded ridge regression:</em> Since the relative scaling of both feature spaces is
unknown, we use two regularization hyperparameters (one per feature space) in a
model called banded ridge regression <span id="id139">[<a class="reference internal" href="../../pages/voxelwise_modeling.html#id25" title="T. Dupré la Tour, M. Eickenberg, A.O. Nunez-Elizalde, and J. L. Gallant. Feature-space selection with banded ridge regression. NeuroImage, 267:119728, 2022. doi:10.1016/j.neuroimage.2022.119728.">Dupré la Tour <em>et al.</em>, 2022</a>, <a class="reference internal" href="../../pages/voxelwise_modeling.html#id22" title="A. O. Nunez-Elizalde, A. G. Huth, and J. L. Gallant. Voxelwise encoding models with non-spherical multivariate normal priors. Neuroimage, 197:482–492, 2019.">Nunez-Elizalde <em>et al.</em>, 2019</a>]</span>.
Just like with ridge regression, we optimize the hyperparameters over cross-validation.
An efficient implementation of this model is available in the
<a class="reference external" href="https://github.com/gallantlab/himalaya">himalaya</a> package.</p>
<div class="warning admonition">
<p class="admonition-title">Long running time on a CPU!</p>
<p>This example is more computationally intensive than the previous examples.
With a GPU backend, model fitting takes around 6 minutes.
With a CPU backend, it can take more than an hour.</p>
</div>
<section id="id140">
<h2>Path of the data directory<a class="headerlink" href="#id140" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">voxelwise_tutorials.io</span> <span class="kn">import</span> <span class="n">get_data_home</span>
<span class="n">directory</span> <span class="o">=</span> <span class="n">get_data_home</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="s2">&quot;shortclips&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">directory</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># modify to use another subject</span>
<span class="n">subject</span> <span class="o">=</span> <span class="s2">&quot;S01&quot;</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="id141">
<h2>Load the data<a class="headerlink" href="#id141" title="Link to this heading">#</a></h2>
<p>As in the previous examples, we first load the fMRI responses, which are our
regression targets. We then normalize the data independently for each run.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">zscore</span>
<span class="kn">from</span> <span class="nn">voxelwise_tutorials.io</span> <span class="kn">import</span> <span class="n">load_hdf5_array</span>
<span class="kn">from</span> <span class="nn">voxelwise_tutorials.utils</span> <span class="kn">import</span> <span class="n">zscore_runs</span>

<span class="n">file_name</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">directory</span><span class="p">,</span> <span class="s2">&quot;responses&quot;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">subject</span><span class="si">}</span><span class="s2">_responses.hdf&quot;</span><span class="p">)</span>
<span class="n">Y_train</span> <span class="o">=</span> <span class="n">load_hdf5_array</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="s2">&quot;Y_train&quot;</span><span class="p">)</span>
<span class="n">Y_test</span> <span class="o">=</span> <span class="n">load_hdf5_array</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="s2">&quot;Y_test&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;(n_samples_train, n_voxels) =&quot;</span><span class="p">,</span> <span class="n">Y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;(n_repeats, n_samples_test, n_voxels) =&quot;</span><span class="p">,</span> <span class="n">Y_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># indice of first sample of each run</span>
<span class="n">run_onsets</span> <span class="o">=</span> <span class="n">load_hdf5_array</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="s2">&quot;run_onsets&quot;</span><span class="p">)</span>

<span class="c1"># zscore each training run separately</span>
<span class="n">Y_train</span> <span class="o">=</span> <span class="n">zscore_runs</span><span class="p">(</span><span class="n">Y_train</span><span class="p">,</span> <span class="n">run_onsets</span><span class="p">)</span>
<span class="c1"># zscore each test run separately</span>
<span class="n">Y_test</span> <span class="o">=</span> <span class="n">zscore</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We also compute the explainable variance, to exclude voxels with low
explainable variance from the fit, and speed up the model fitting.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">voxelwise_tutorials.utils</span> <span class="kn">import</span> <span class="n">explainable_variance</span>
<span class="n">ev</span> <span class="o">=</span> <span class="n">explainable_variance</span><span class="p">(</span><span class="n">Y_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;(n_voxels,) =&quot;</span><span class="p">,</span> <span class="n">ev</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">mask</span> <span class="o">=</span> <span class="n">ev</span> <span class="o">&gt;</span> <span class="mf">0.1</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;(n_voxels_mask,) =&quot;</span><span class="p">,</span> <span class="n">ev</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We average the test repeats, to remove the non-repeatable part of fMRI
responses, and normalize the averaged data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Y_test</span> <span class="o">=</span> <span class="n">Y_test</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">Y_test</span> <span class="o">=</span> <span class="n">zscore</span><span class="p">(</span><span class="n">Y_test</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;(n_samples_test, n_voxels) =&quot;</span><span class="p">,</span> <span class="n">Y_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We fill potential NaN (not-a-number) values with zeros.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Y_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan_to_num</span><span class="p">(</span><span class="n">Y_train</span><span class="p">)</span>
<span class="n">Y_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan_to_num</span><span class="p">(</span><span class="n">Y_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>And we make sure the targets are centered.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Y_train</span> <span class="o">-=</span> <span class="n">Y_train</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">Y_test</span> <span class="o">-=</span> <span class="n">Y_test</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Then we load both feature spaces, that are going to be used for the
linear regression model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">feature_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;wordnet&quot;</span><span class="p">,</span> <span class="s2">&quot;motion_energy&quot;</span><span class="p">]</span>

<span class="n">Xs_train</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">Xs_test</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">n_features_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">feature_space</span> <span class="ow">in</span> <span class="n">feature_names</span><span class="p">:</span>
    <span class="n">file_name</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">directory</span><span class="p">,</span> <span class="s2">&quot;features&quot;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">feature_space</span><span class="si">}</span><span class="s2">.hdf&quot;</span><span class="p">)</span>
    <span class="n">Xi_train</span> <span class="o">=</span> <span class="n">load_hdf5_array</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="s2">&quot;X_train&quot;</span><span class="p">)</span>
    <span class="n">Xi_test</span> <span class="o">=</span> <span class="n">load_hdf5_array</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="s2">&quot;X_test&quot;</span><span class="p">)</span>

    <span class="n">Xs_train</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Xi_train</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">))</span>
    <span class="n">Xs_test</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Xi_test</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">))</span>
    <span class="n">n_features_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Xi_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

<span class="c1"># concatenate the feature spaces</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">Xs_train</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">Xs_test</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;(n_samples_train, n_features_total) =&quot;</span><span class="p">,</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;(n_samples_test, n_features_total) =&quot;</span><span class="p">,</span> <span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;[n_features_wordnet, n_features_motion_energy] =&quot;</span><span class="p">,</span> <span class="n">n_features_list</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="id142">
<h2>Define the cross-validation scheme<a class="headerlink" href="#id142" title="Link to this heading">#</a></h2>
<p>We define again a leave-one-run-out cross-validation split scheme.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">check_cv</span>
<span class="kn">from</span> <span class="nn">voxelwise_tutorials.utils</span> <span class="kn">import</span> <span class="n">generate_leave_one_run_out</span>

<span class="c1"># indice of first sample of each run</span>
<span class="n">run_onsets</span> <span class="o">=</span> <span class="n">load_hdf5_array</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="s2">&quot;run_onsets&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">run_onsets</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We define a cross-validation splitter, compatible with <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> API.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_samples_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">cv</span> <span class="o">=</span> <span class="n">generate_leave_one_run_out</span><span class="p">(</span><span class="n">n_samples_train</span><span class="p">,</span> <span class="n">run_onsets</span><span class="p">)</span>
<span class="n">cv</span> <span class="o">=</span> <span class="n">check_cv</span><span class="p">(</span><span class="n">cv</span><span class="p">)</span>  <span class="c1"># copy the cross-validation splitter into a reusable list</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="id143">
<h2>Define the model<a class="headerlink" href="#id143" title="Link to this heading">#</a></h2>
<p>The model pipeline contains similar steps than the pipeline from previous
examples. We remove the mean of each feature with a <code class="docutils literal notranslate"><span class="pre">StandardScaler</span></code>,
and add delays with a <code class="docutils literal notranslate"><span class="pre">Delayer</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">voxelwise_tutorials.delayer</span> <span class="kn">import</span> <span class="n">Delayer</span>
<span class="kn">from</span> <span class="nn">himalaya.backend</span> <span class="kn">import</span> <span class="n">set_backend</span>
<span class="n">backend</span> <span class="o">=</span> <span class="n">set_backend</span><span class="p">(</span><span class="s2">&quot;torch_cuda&quot;</span><span class="p">,</span> <span class="n">on_error</span><span class="o">=</span><span class="s2">&quot;warn&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>To fit the banded ridge model, we use <code class="docutils literal notranslate"><span class="pre">himalaya</span></code>’s
<code class="docutils literal notranslate"><span class="pre">MultipleKernelRidgeCV</span></code> model, with a separate linear kernel per feature
space. Similarly to <code class="docutils literal notranslate"><span class="pre">KernelRidgeCV</span></code>, the model optimizes the
hyperparameters over cross-validation. However, while <code class="docutils literal notranslate"><span class="pre">KernelRidgeCV</span></code> has
to optimize only one hyperparameter (<code class="docutils literal notranslate"><span class="pre">alpha</span></code>), <code class="docutils literal notranslate"><span class="pre">MultipleKernelRidgeCV</span></code>
has to optimize <code class="docutils literal notranslate"><span class="pre">m</span></code> hyperparameters, where <code class="docutils literal notranslate"><span class="pre">m</span></code> is the number of feature
spaces (here <code class="docutils literal notranslate"><span class="pre">m</span> <span class="pre">=</span> <span class="pre">2</span></code>). To do so, the model implements two different
solvers, one using hyperparameter random search, and one using hyperparameter
gradient descent. For large number of targets, we recommend using the
random-search solver.</p>
<p>The class takes a number of common parameters during initialization, such as
<code class="docutils literal notranslate"><span class="pre">kernels</span></code>, or <code class="docutils literal notranslate"><span class="pre">solver</span></code>. Since the solver parameters vary depending on the
solver used, they are passed as a <code class="docutils literal notranslate"><span class="pre">solver_params</span></code> dictionary.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">himalaya.kernel_ridge</span> <span class="kn">import</span> <span class="n">MultipleKernelRidgeCV</span>

<span class="c1"># Here we will use the &quot;random_search&quot; solver.</span>
<span class="n">solver</span> <span class="o">=</span> <span class="s2">&quot;random_search&quot;</span>

<span class="c1"># We can check its specific parameters in the function docstring:</span>
<span class="n">solver_function</span> <span class="o">=</span> <span class="n">MultipleKernelRidgeCV</span><span class="o">.</span><span class="n">ALL_SOLVERS</span><span class="p">[</span><span class="n">solver</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Docstring of the function </span><span class="si">%s</span><span class="s2">:&quot;</span> <span class="o">%</span> <span class="n">solver_function</span><span class="o">.</span><span class="vm">__name__</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">solver_function</span><span class="o">.</span><span class="vm">__doc__</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The hyperparameter random-search solver separates the hyperparameters into a
shared regularization <code class="docutils literal notranslate"><span class="pre">alpha</span></code> and a vector of positive kernel weights which
sum to one. This separation of hyperparameters allows to explore efficiently
a large grid of values for <code class="docutils literal notranslate"><span class="pre">alpha</span></code> for each sampled kernel weights vector.</p>
<p>We use <code class="docutils literal notranslate"><span class="pre">n_iter=20</span></code> random-search iterations to have a reasonably fast example. To
have better results, especially for larger number of feature spaces, one
might need more iterations. (Note that there is currently no stopping
criterion in the random-search method.)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_iter</span> <span class="o">=</span> <span class="mi">20</span>

<span class="n">alphas</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Batch parameters, used to reduce the necessary GPU memory. A larger value
will be a bit faster, but the solver might crash if it is out of memory.
Optimal values depend on the size of your dataset.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_targets_batch</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">n_alphas_batch</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">n_targets_batch_refit</span> <span class="o">=</span> <span class="mi">200</span>
</pre></div>
</div>
</div>
</div>
<p>We put all these parameters in a dictionary <code class="docutils literal notranslate"><span class="pre">solver_params</span></code>, and define
the main estimator <code class="docutils literal notranslate"><span class="pre">MultipleKernelRidgeCV</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">solver_params</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">n_iter</span><span class="o">=</span><span class="n">n_iter</span><span class="p">,</span> <span class="n">alphas</span><span class="o">=</span><span class="n">alphas</span><span class="p">,</span>
                     <span class="n">n_targets_batch</span><span class="o">=</span><span class="n">n_targets_batch</span><span class="p">,</span>
                     <span class="n">n_alphas_batch</span><span class="o">=</span><span class="n">n_alphas_batch</span><span class="p">,</span>
                     <span class="n">n_targets_batch_refit</span><span class="o">=</span><span class="n">n_targets_batch_refit</span><span class="p">)</span>

<span class="n">mkr_model</span> <span class="o">=</span> <span class="n">MultipleKernelRidgeCV</span><span class="p">(</span><span class="n">kernels</span><span class="o">=</span><span class="s2">&quot;precomputed&quot;</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="n">solver</span><span class="p">,</span>
                                  <span class="n">solver_params</span><span class="o">=</span><span class="n">solver_params</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We need a bit more work than in previous examples before defining the full
pipeline, since the banded ridge model requires <code class="docutils literal notranslate"><span class="pre">multiple</span></code> precomputed
kernels, one for each feature space. To compute them, we use the
<code class="docutils literal notranslate"><span class="pre">ColumnKernelizer</span></code>, which can create multiple kernels from different
column of your features array. <code class="docutils literal notranslate"><span class="pre">ColumnKernelizer</span></code> works similarly to
<code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code>’s <code class="docutils literal notranslate"><span class="pre">ColumnTransformer</span></code>, but instead of returning a
concatenation of transformed features, it returns a stack of kernels,
as required in <code class="docutils literal notranslate"><span class="pre">MultipleKernelRidgeCV(kernels=&quot;precomputed&quot;)</span></code>.</p>
<p>First, we create a different <code class="docutils literal notranslate"><span class="pre">Kernelizer</span></code> for each feature space.
Here we use a linear kernel for all feature spaces, but <code class="docutils literal notranslate"><span class="pre">ColumnKernelizer</span></code>
accepts any <code class="docutils literal notranslate"><span class="pre">Kernelizer</span></code>, or <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> <code class="docutils literal notranslate"><span class="pre">Pipeline</span></code> ending with a
<code class="docutils literal notranslate"><span class="pre">Kernelizer</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">himalaya.kernel_ridge</span> <span class="kn">import</span> <span class="n">Kernelizer</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">set_config</span>
<span class="n">set_config</span><span class="p">(</span><span class="n">display</span><span class="o">=</span><span class="s1">&#39;diagram&#39;</span><span class="p">)</span>  <span class="c1"># requires scikit-learn 0.23</span>

<span class="n">preprocess_pipeline</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
    <span class="n">StandardScaler</span><span class="p">(</span><span class="n">with_mean</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">with_std</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
    <span class="n">Delayer</span><span class="p">(</span><span class="n">delays</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]),</span>
    <span class="n">Kernelizer</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">),</span>
<span class="p">)</span>
<span class="n">preprocess_pipeline</span>
</pre></div>
</div>
</div>
</div>
<p>The column kernelizer applies a different pipeline on each selection of
features, here defined with <code class="docutils literal notranslate"><span class="pre">slices</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">himalaya.kernel_ridge</span> <span class="kn">import</span> <span class="n">ColumnKernelizer</span>

<span class="c1"># Find the start and end of each feature space in the concatenated ``X_train``.</span>
<span class="n">start_and_end</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([[</span><span class="mi">0</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">n_features_list</span><span class="p">)])</span>
<span class="n">slices</span> <span class="o">=</span> <span class="p">[</span>
    <span class="nb">slice</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">start</span><span class="p">,</span> <span class="n">end</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">start_and_end</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">start_and_end</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
<span class="p">]</span>
<span class="n">slices</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">kernelizers_tuples</span> <span class="o">=</span> <span class="p">[(</span><span class="n">name</span><span class="p">,</span> <span class="n">preprocess_pipeline</span><span class="p">,</span> <span class="n">slice_</span><span class="p">)</span>
                      <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">slice_</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">feature_names</span><span class="p">,</span> <span class="n">slices</span><span class="p">)]</span>
<span class="n">column_kernelizer</span> <span class="o">=</span> <span class="n">ColumnKernelizer</span><span class="p">(</span><span class="n">kernelizers_tuples</span><span class="p">)</span>
<span class="n">column_kernelizer</span>

<span class="c1"># (Note that ``ColumnKernelizer`` has a parameter ``n_jobs`` to parallelize</span>
<span class="c1"># each ``Kernelizer``, yet such parallelism does not work with GPU arrays.)</span>
</pre></div>
</div>
</div>
</div>
<p>Then we can define the model pipeline.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pipeline</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
    <span class="n">column_kernelizer</span><span class="p">,</span>
    <span class="n">mkr_model</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">pipeline</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="id144">
<h2>Fit the model<a class="headerlink" href="#id144" title="Link to this heading">#</a></h2>
<p>We fit on the train set, and score on the test set.</p>
<p>To speed up the fit and to limit the memory peaks, we only fit on
voxels with explainable variance above 0.1. If your GPU has sufficient memory, you can
avoid masking the data and fit the model on all voxels. Note also that this masking is
performed here only for the purposes of the tutorial, and it should not be performed
for an actual analysis.</p>
<p>With a GPU backend, the fitting of this model takes around 6 minutes. With a
CPU backend, it can last 10 times more.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">[:,</span> <span class="n">mask</span><span class="p">])</span>

<span class="n">scores_mask</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">[:,</span> <span class="n">mask</span><span class="p">])</span>
<span class="n">scores_mask</span> <span class="o">=</span> <span class="n">backend</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">scores_mask</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;(n_voxels_mask,) =&quot;</span><span class="p">,</span> <span class="n">scores_mask</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># Then we extend the scores to all voxels, giving a score of zero to unfitted</span>
<span class="c1"># voxels.</span>
<span class="n">n_voxels</span> <span class="o">=</span> <span class="n">Y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_voxels</span><span class="p">)</span>
<span class="n">scores</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span> <span class="o">=</span> <span class="n">scores_mask</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;(n_voxels,) =&quot;</span><span class="p">,</span> <span class="n">scores</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="compare-with-a-ridge-model">
<h2>Compare with a ridge model<a class="headerlink" href="#compare-with-a-ridge-model" title="Link to this heading">#</a></h2>
<p>We can compare with a baseline model, which does not use one hyperparameter
per feature space, but instead shares the same hyperparameter for all feature
spaces.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">himalaya.kernel_ridge</span> <span class="kn">import</span> <span class="n">KernelRidgeCV</span>

<span class="n">pipeline_baseline</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
    <span class="n">StandardScaler</span><span class="p">(</span><span class="n">with_mean</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">with_std</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
    <span class="n">Delayer</span><span class="p">(</span><span class="n">delays</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]),</span>
    <span class="n">KernelRidgeCV</span><span class="p">(</span>
        <span class="n">alphas</span><span class="o">=</span><span class="n">alphas</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span>
        <span class="n">solver_params</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">n_targets_batch</span><span class="o">=</span><span class="n">n_targets_batch</span><span class="p">,</span>
                           <span class="n">n_alphas_batch</span><span class="o">=</span><span class="n">n_alphas_batch</span><span class="p">,</span>
                           <span class="n">n_targets_batch_refit</span><span class="o">=</span><span class="n">n_targets_batch_refit</span><span class="p">)),</span>
<span class="p">)</span>
<span class="n">pipeline_baseline</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pipeline_baseline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">[:,</span> <span class="n">mask</span><span class="p">])</span>
<span class="n">scores_baseline_mask</span> <span class="o">=</span> <span class="n">pipeline_baseline</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">Y_test</span><span class="p">[:,</span> <span class="n">mask</span><span class="p">])</span>
<span class="n">scores_baseline_mask</span> <span class="o">=</span> <span class="n">backend</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">scores_baseline_mask</span><span class="p">)</span>

<span class="c1"># extend to unfitted voxels</span>
<span class="n">n_voxels</span> <span class="o">=</span> <span class="n">Y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">scores_baseline</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_voxels</span><span class="p">)</span>
<span class="n">scores_baseline</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span> <span class="o">=</span> <span class="n">scores_baseline_mask</span>
</pre></div>
</div>
</div>
</div>
<p>Here we plot the comparison of model prediction accuracies with a 2D
histogram. All 70k voxels are represented in this histogram, where the
diagonal corresponds to identical model prediction accuracy for both models.
A distribution deviating from the diagonal means that one model has better
predictive performance than the other.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">voxelwise_tutorials.viz</span> <span class="kn">import</span> <span class="n">plot_hist2d</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">plot_hist2d</span><span class="p">(</span><span class="n">scores_baseline</span><span class="p">,</span> <span class="n">scores</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s1">&#39;Generalization R2 scores&#39;</span><span class="p">,</span> <span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;KernelRidgeCV&#39;</span><span class="p">,</span>
       <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;MultipleKernelRidgeCV&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>We see that the banded ridge model (<code class="docutils literal notranslate"><span class="pre">MultipleKernelRidgeCV</span></code>) outperforms
the ridge model (<code class="docutils literal notranslate"><span class="pre">KernelRidegeCV</span></code>). Indeed, banded ridge regression is able
to find the optimal scalings of each feature space, independently on each
voxel. Banded ridge regression is thus able to perform a soft selection
between the available feature spaces, based on the cross-validation
performances.</p>
</section>
<section id="plot-the-banded-ridge-split">
<h2>Plot the banded ridge split<a class="headerlink" href="#plot-the-banded-ridge-split" title="Link to this heading">#</a></h2>
<p>On top of better prediction accuracy, banded ridge regression also gives a
way to disentangle the contribution of the two feature spaces. To do so, we
take the kernel weights and the ridge (dual) weights corresponding to each
feature space, and use them to compute the prediction from each feature space
separately.</p>
<div class="amsmath math notranslate nohighlight" id="equation-6307f697-fe60-4382-acf9-0d3650b08be7">
<span class="eqno">()<a class="headerlink" href="#equation-6307f697-fe60-4382-acf9-0d3650b08be7" title="Permalink to this equation">#</a></span>\[\begin{align}\hat{y} = \sum_i^m \hat{y}_i = \sum_i^m \gamma_i K_i \hat{w}\end{align}\]</div>
<p>Then, we use these split predictions to compute split <span class="math notranslate nohighlight">\(\tilde{R}^2_i\)</span>
scores. These scores are corrected so that their sum is equal to the
<span class="math notranslate nohighlight">\(R^2\)</span> score of the full prediction <span class="math notranslate nohighlight">\(\hat{y}\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">himalaya.scoring</span> <span class="kn">import</span> <span class="n">r2_score_split</span>

<span class="n">Y_test_pred_split</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">split_scores_mask</span> <span class="o">=</span> <span class="n">r2_score_split</span><span class="p">(</span><span class="n">Y_test</span><span class="p">[:,</span> <span class="n">mask</span><span class="p">],</span> <span class="n">Y_test_pred_split</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;(n_kernels, n_samples_test, n_voxels_mask) =&quot;</span><span class="p">,</span> <span class="n">Y_test_pred_split</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;(n_kernels, n_voxels_mask) =&quot;</span><span class="p">,</span> <span class="n">split_scores_mask</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># extend to unfitted voxels</span>
<span class="n">n_kernels</span> <span class="o">=</span> <span class="n">split_scores_mask</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">n_voxels</span> <span class="o">=</span> <span class="n">Y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">split_scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_kernels</span><span class="p">,</span> <span class="n">n_voxels</span><span class="p">))</span>
<span class="n">split_scores</span><span class="p">[:,</span> <span class="n">mask</span><span class="p">]</span> <span class="o">=</span> <span class="n">backend</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">split_scores_mask</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;(n_kernels, n_voxels) =&quot;</span><span class="p">,</span> <span class="n">split_scores</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We can then plot the split scores on a flatmap with a 2D colormap.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">voxelwise_tutorials.viz</span> <span class="kn">import</span> <span class="n">plot_2d_flatmap_from_mapper</span>

<span class="n">mapper_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">directory</span><span class="p">,</span> <span class="s2">&quot;mappers&quot;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">subject</span><span class="si">}</span><span class="s2">_mappers.hdf&quot;</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">plot_2d_flatmap_from_mapper</span><span class="p">(</span><span class="n">split_scores</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">split_scores</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                                 <span class="n">mapper_file</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">vmin2</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                                 <span class="n">vmax2</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label_1</span><span class="o">=</span><span class="n">feature_names</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                                 <span class="n">label_2</span><span class="o">=</span><span class="n">feature_names</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>The blue regions are better predicted by the motion-energy features, the
orange regions are better predicted by the wordnet features, and the white
regions are well predicted by both feature spaces.</p>
<p>Compared to the last figure of the previous example, we see that most white
regions have been replaced by either blue or orange regions. The banded ridge
regression disentangled the two feature spaces in voxels where both feature
spaces had good prediction accuracy (see previous example). For example,
motion-energy features predict brain activity in early visual cortex, while
wordnet features predict in semantic visual areas. For more discussions about
these results, we refer the reader to the publications describing the banded ridge
regression approach <span id="id145">[<a class="reference internal" href="../../pages/voxelwise_modeling.html#id25" title="T. Dupré la Tour, M. Eickenberg, A.O. Nunez-Elizalde, and J. L. Gallant. Feature-space selection with banded ridge regression. NeuroImage, 267:119728, 2022. doi:10.1016/j.neuroimage.2022.119728.">Dupré la Tour <em>et al.</em>, 2022</a>, <a class="reference internal" href="../../pages/voxelwise_modeling.html#id22" title="A. O. Nunez-Elizalde, A. G. Huth, and J. L. Gallant. Voxelwise encoding models with non-spherical multivariate normal priors. Neuroimage, 197:482–492, 2019.">Nunez-Elizalde <em>et al.</em>, 2019</a>]</span>.</p>
</section>
<section id="id146">
<h2>References<a class="headerlink" href="#id146" title="Link to this heading">#</a></h2>
<div class="docutils container" id="id147">
<div role="list" class="citation-list">
<div class="citation" id="id162" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>DlTENEG22<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id111">1</a>,<a role="doc-backlink" href="#id139">2</a>,<a role="doc-backlink" href="#id145">3</a>)</span>
<p>T. Dupré la Tour, M. Eickenberg, A.O. Nunez-Elizalde, and J. L. Gallant. Feature-space selection with banded ridge regression. <em>NeuroImage</em>, 267:119728, 2022. <a class="reference external" href="https://doi.org/10.1016/j.neuroimage.2022.119728">doi:10.1016/j.neuroimage.2022.119728</a>.</p>
</div>
<div class="citation" id="id172" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>HTF09<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id61">1</a>,<a role="doc-backlink" href="#id62">2</a>)</span>
<p>Trevor Hastie, Robert Tibshirani, and Jerome Friedman. <em>The Elements of Statistical Learning</em>. Springer New York, 2009.</p>
</div>
<div class="citation" id="id169" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id29">HBT04</a><span class="fn-bracket">]</span></span>
<p>A. Hsu, A. Borst, and F. E. Theunissen. Quantifying variability in neural responses and its application for the validation of model predictions. <em>Network</em>, 2004.</p>
</div>
<div class="citation" id="id164" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id2">HNV+22</a><span class="fn-bracket">]</span></span>
<p>A. G. Huth, S. Nishimoto, A. T. Vu, T. Dupré la Tour, and J. L. Gallant. Gallant lab natural short clips 3t fMRI data. 2022. <a class="reference external" href="https://doi.org/10.12751/g-node.vy1zjd">doi:10.12751/g-node.vy1zjd</a>.</p>
</div>
<div class="citation" id="id151" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>HNVG12<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id1">1</a>,<a role="doc-backlink" href="#id58">2</a>,<a role="doc-backlink" href="#id60">3</a>,<a role="doc-backlink" href="#id64">4</a>,<a role="doc-backlink" href="#id65">5</a>,<a role="doc-backlink" href="#id66">6</a>,<a role="doc-backlink" href="#id67">7</a>,<a role="doc-backlink" href="#id68">8</a>,<a role="doc-backlink" href="#id69">9</a>,<a role="doc-backlink" href="#id70">10</a>)</span>
<p>A. G. Huth, S. Nishimoto, A. T. Vu, and J. L. Gallant. A continuous semantic space describes the representation of thousands of object and action categories across the human brain. <em>Neuron</em>, 76(6):1210–1224, 2012.</p>
</div>
<div class="citation" id="id150" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>NVN+11<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id103">1</a>,<a role="doc-backlink" href="#id104">2</a>,<a role="doc-backlink" href="#id110">3</a>)</span>
<p>S. Nishimoto, A. T. Vu, T. Naselaris, Y. Benjamini, B. Yu, and J. L. Gallant. Reconstructing visual experiences from brain activity evoked by natural movies. <em>Current Biology</em>, 21(19):1641–1646, 2011.</p>
</div>
<div class="citation" id="id159" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>NEHG19<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id111">1</a>,<a role="doc-backlink" href="#id139">2</a>,<a role="doc-backlink" href="#id145">3</a>)</span>
<p>A. O. Nunez-Elizalde, A. G. Huth, and J. L. Gallant. Voxelwise encoding models with non-spherical multivariate normal priors. <em>Neuroimage</em>, 197:482–492, 2019.</p>
</div>
<div class="citation" id="id168" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id29">SL02</a><span class="fn-bracket">]</span></span>
<p>M. Sahani and J. Linden. How linear are auditory cortical responses? <em>Adv. Neural Inf. Process. Syst.</em>, 2002.</p>
</div>
<div class="citation" id="id171" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id63">SGV98</a><span class="fn-bracket">]</span></span>
<p>C. Saunders, A. Gammerman, and V. Vovk. Ridge regression learning algorithm in dual variables. 1998.</p>
</div>
<div class="citation" id="id170" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id29">SHW+16</a><span class="fn-bracket">]</span></span>
<p>O. Schoppe, N. S. Harper, B. Willmore, A. King, and J. Schnupp. Measuring the performance of neural models. <em>Front. Comput. Neurosci.</em>, 2016.</p>
</div>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./notebooks/shortclips"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Setup Google Colab</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#change-runtime-to-use-a-gpu">Change runtime to use a GPU</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#install-all-required-dependencies">Install all required dependencies</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#download-the-data-set">Download the data set</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cite-this-data-set">Cite this data set</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#download">Download</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references">References</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#compute-the-explainable-variance">Compute the explainable variance</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#path-of-the-data-directory">Path of the data directory</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id30">Compute the explainable variance</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#map-to-subject-flatmap">Map to subject flatmap</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#map-to-fsaverage">Map to “fsaverage”</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id31">References</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#understand-ridge-regression-and-hyperparameter-selection">Understand ridge regression and hyperparameter selection</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ordinary-least-squares-ols">Ordinary least squares (OLS)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ridge-regression">Ridge regression</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hyperparameter-selection">Hyperparameter selection</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#fit-a-voxelwise-encoding-model-with-wordnet-features">Fit a voxelwise encoding model with WordNet features</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id59">Path of the data directory</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#load-the-data">Load the data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#define-the-cross-validation-scheme">Define the cross-validation scheme</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#define-the-model">Define the model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fit-the-model">Fit the model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#plot-the-model-prediction-accuracy">Plot the model prediction accuracy</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#plot-the-selected-hyperparameters">Plot the selected hyperparameters</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#visualize-the-regression-coefficients">Visualize the regression coefficients</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id71">References</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#visualize-the-hemodynamic-response">Visualize the hemodynamic response</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id98">Path of the data directory</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id99">Load the data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id100">Define the cross-validation scheme</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id101">Define the model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id102">Fit the model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#understanding-delays">Understanding delays</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#compare-with-a-model-without-delays">Compare with a model without delays</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#visualize-the-hrf">Visualize the HRF</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#fit-a-voxelwise-encoding-model-with-motion-energy-features">Fit a voxelwise encoding model with motion-energy features</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id105">Path of the data directory</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id106">Load the data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id107">Define the cross-validation scheme</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id108">Define the model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id109">Fit the model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#plot-the-model-performances">Plot the model performances</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#compare-with-the-wordnet-model">Compare with the wordnet model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id112">References</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#fit-a-voxelwise-encoding-model-with-both-wordnet-and-motion-energy-features">Fit a voxelwise encoding model with both WordNet and motion-energy features</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id140">Path of the data directory</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id141">Load the data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id142">Define the cross-validation scheme</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id143">Define the model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id144">Fit the model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#compare-with-a-ridge-model">Compare with a ridge model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#plot-the-banded-ridge-split">Plot the banded ridge split</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id146">References</a></li>
</ul>
</li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Tom Dupré la Tour, Matteo Visconti di Oleggio Castello, Jack L. Gallant
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>